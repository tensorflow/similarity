{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will train an mnist model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "from absl import app, flags\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten, Input,\n",
    "                                     MaxPooling2D, Reshape, UpSampling2D, Lambda)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tabulate\n",
    "from tensorflow_similarity.api.engine.preprocessing import Preprocessing\n",
    "from tensorflow_similarity.api.engine.simhash import SimHash\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen is reusable\n",
    "(x_train, y_train), (original_x_test, original_y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# initilize datagen\n",
    "datagen = ImageDataGenerator(\n",
    "  rotation_range=40,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  fill_mode='nearest')\n",
    "\n",
    "datagen.fit(x_train[..., np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative datapath to the downloaded mnist dataset.\n",
    "DEFAULT_MNIST_DATA_PATH = \"./mnist.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist_data(data_path, num_augment=8):\n",
    "    \"\"\" Returns the mnist data.\n",
    "    \n",
    "    Opens the data file specified by the argument, read each\n",
    "    line and puts 20% of the data into the testing set.\n",
    "    \n",
    "    Args:\n",
    "        data_path: A string that points to the cached mnist\n",
    "            dataset.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple that contains three elements. The first element\n",
    "        is a tuple that contains data used for training and\n",
    "        the second element is a tuple that contains data used\n",
    "        for testing. The third element is a tuple that contains\n",
    "        the target data. All three tuples have the same\n",
    "        structure, they contains two elements. The first\n",
    "        element contains a dictionary for the specs of mnist data\n",
    "        (in 2d np array), the second element contains\n",
    "        an np array of labels of class.\n",
    "    \"\"\"\n",
    "    \n",
    "    (x_train, y_train), (x_test_raw, y_test_raw) = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "    \n",
    "    x_train = x_train[..., np.newaxis]\n",
    "    \n",
    "    # train on only even digits and not odd digits\n",
    "    filtered_x_train = []\n",
    "    filtered_y_train = []\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        if y % 2 == 0:\n",
    "            filtered_x_train.append(x)\n",
    "            filtered_y_train.append(y)\n",
    "\n",
    "    x_train = np.array(filtered_x_train)\n",
    "    y_train = np.array(filtered_y_train)\n",
    "\n",
    "    x_tests = []\n",
    "    y_tests = []\n",
    "\n",
    "    x_targets = []\n",
    "    y_targets = []\n",
    "\n",
    "    seen = set()\n",
    "    for x, y in zip(x_test_raw, y_test_raw):\n",
    "        if y not in seen:\n",
    "            seen.add(y)\n",
    "            x_targets.append(x[..., np.newaxis])\n",
    "            y_targets.append(y)\n",
    "        else:\n",
    "            x_tests.append(x[..., np.newaxis])\n",
    "            y_tests.append(y)\n",
    "\n",
    "    if num_augment > 0:\n",
    "        print(\"performing data augmentation\")\n",
    "        batch_size = 64 * 4\n",
    "        new_x_train = np.zeros((len(x_train) * num_augment, 28, 28, 1))\n",
    "        new_y_train = np.zeros(len(new_x_train))\n",
    "\n",
    "        num_steps = int(len(new_x_train) / batch_size)\n",
    "\n",
    "        image_generator = datagen.flow(x=x_train, y=y_train, batch_size=batch_size)\n",
    "\n",
    "\n",
    "        # pbar that we want to update\n",
    "        pbar = tqdm(total=len(new_x_train))\n",
    "        idx = 0\n",
    "        while idx < len(new_x_train):\n",
    "            x_train_batch, y_train_batch = next(image_generator)\n",
    "\n",
    "            batch_size = len(x_train_batch)\n",
    "            batch_size = min(batch_size, len(new_x_train) - idx)\n",
    "            new_x_train[idx:idx+batch_size] = x_train_batch\n",
    "            new_y_train[idx:idx+batch_size] = y_train_batch\n",
    "\n",
    "            idx += batch_size\n",
    "            pbar.update(batch_size)\n",
    "\n",
    "        x_train = new_x_train\n",
    "        y_train = new_y_train\n",
    "        \n",
    "    return (({\n",
    "        \"example\": np.array(x_train) / 255.0\n",
    "    }, np.array(y_train)), ({\n",
    "        \"example\": np.array(x_tests) / 255.0\n",
    "    }, np.array(y_tests)), ({\n",
    "        \"example\": np.array(x_targets) / 255.0\n",
    "    }, np.array(y_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"A simple tower model for mnist dataset.\n",
    "    \n",
    "    Returns:\n",
    "        model: A tensorflow model.\n",
    "    \"\"\"\n",
    "    \n",
    "    i = Input(shape=(28, 28, 1), name=\"example\")\n",
    "    o = Conv2D(\n",
    "        32,\n",
    "        kernel_size=(5, 5),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        input_shape=(28, 28, 1))(i)\n",
    "    o = Conv2D(\n",
    "        32,\n",
    "        kernel_size=(5, 5),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        input_shape=(28, 28, 1))(o)\n",
    "    o = MaxPooling2D(pool_size=(2, 2))(o)\n",
    "    o = Dropout(.25)(o)\n",
    "\n",
    "    o = Conv2D(64, (3, 3), padding='same', activation='relu')(o)\n",
    "    o = Conv2D(64, (3, 3), padding='same', activation='relu')(o)\n",
    "    o = MaxPooling2D(pool_size=(2, 2))(o)\n",
    "    o = Dropout(.25)(o)\n",
    "\n",
    "    o = Flatten()(o)\n",
    "    o = Dense(256, activation=\"relu\")(o)\n",
    "    o = Dropout(.25)(o)\n",
    "    o = Dense(100)(o)\n",
    "    o = Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name=\"l2_norm\")(o)\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mnist_example(data, model, strategy, augment, autoencoder, epochs, prewarm_epochs):\n",
    "    \"\"\"An example usage of tf.similarity with tensorboard callback.\n",
    "\n",
    "    This basic similarity run will first unpackage training,\n",
    "    testing, and target data from the arguments and then construct a\n",
    "    simple moirai model, fit the model with training data, then\n",
    "    evaluate our model with training and testing datasets.\n",
    "\n",
    "    Args:\n",
    "        data: Sets, contains training, testing, and target datasets.\n",
    "        model: tf.Model, the tower model to fit into moirai.\n",
    "        strategy: String, specify the strategy to use for mining triplets.\n",
    "        agument: Boolean, indicates whether we want to augment our data.\n",
    "        epochs: Integer, number of epochs to fit our moirai model.\n",
    "        prewarm_epochs: Integer, number of prewarm epochs for our moirai model.\n",
    "\n",
    "    Returns:\n",
    "        metrics: Dictionary, containing metrics performed on the\n",
    "            testing dataset. The key is the name of the metric and the\n",
    "            value is the np array of the metric values.\n",
    "    \"\"\"\n",
    "        \n",
    "    (x_train, y_train), (x_test, y_test), (x_targets, y_targets) = data\n",
    "\n",
    "    moirai = SimHash(\n",
    "        model,\n",
    "        strategy=strategy,\n",
    "        optimizer=Adam(lr=.001))\n",
    "    \n",
    "    moirai.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        prewarm_epochs=prewarm_epochs if autoencoder else 0,\n",
    "        epochs=epochs)\n",
    "    \n",
    "    moirai.save('augmented_mnist_model.h5')\n",
    "\n",
    "    metrics = moirai.evaluate(x_test, y_test, x_targets, y_targets)\n",
    "    return metrics, moirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing data augmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734f3f86eb424e0086d844df26c17813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=235936), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"triplet_loss\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_example (InputLayer)     [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "anchor_idx (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neg_example (InputLayer)        [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neg_idx (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_example (InputLayer)        [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_idx (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 [(None, 1), (None, 1 910660      anchor_example[0][0]             \n",
      "                                                                 anchor_idx[0][0]                 \n",
      "                                                                 neg_example[0][0]                \n",
      "                                                                 neg_idx[0][0]                    \n",
      "                                                                 pos_example[0][0]                \n",
      "                                                                 pos_idx[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "anchor_idx_out (Rename)         (None, 1)            0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "neg_idx_out (Rename)            (None, 1)            0           model_2[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "pos_idx_out (Rename)            (None, 1)            0           model_2[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "triplets (Rename)               (None, 1)            0           model_2[1][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "meta_is_hard (Rename)           (None, 1)            0           model_2[1][4]                    \n",
      "__________________________________________________________________________________________________\n",
      "hard_tuple (Rename)             (None, 1)            0           model_2[1][5]                    \n",
      "==================================================================================================\n",
      "Total params: 910,660\n",
      "Trainable params: 910,660\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "1844/1844 [==============================] - 435s 236ms/step - loss: 0.0615 - triplets_loss: 0.0615 - hard_tuple_fraction: 0.2995\n",
      "\n",
      "Epoch 2/5\n",
      "1844/1844 [==============================] - 434s 235ms/step - loss: 0.0109 - triplets_loss: 0.0109 - hard_tuple_fraction: 0.0518\n",
      "Epoch 3/5\n",
      "1844/1844 [==============================] - 433s 235ms/step - loss: 0.0084 - triplets_loss: 0.0084 - hard_tuple_fraction: 0.0398\n",
      "Epoch 4/5\n",
      "1844/1844 [==============================] - 433s 235ms/step - loss: 0.0070 - triplets_loss: 0.0070 - hard_tuple_fraction: 0.0331\n",
      "Epoch 5/5\n",
      "1844/1844 [==============================] - 436s 236ms/step - loss: 0.0062 - triplets_loss: 0.0062 - hard_tuple_fraction: 0.0296\n"
     ]
    }
   ],
   "source": [
    "data = read_mnist_data(DEFAULT_MNIST_DATA_PATH)\n",
    "tower_model = model_fn()\n",
    "# Strategy we want to use.\n",
    "strategy = \"triplet_loss\"\n",
    "# Whether we want to augment our data.\n",
    "augment = False\n",
    "# Whether or not we want to use auxillary autoencoder task.\n",
    "autoencoder = False\n",
    "# Number of epochs\n",
    "epochs = 5\n",
    "# Number of prewarm epochs\n",
    "prewarm_epochs = 0\n",
    "\n",
    "test_metrics, similar_model = run_mnist_example(data, tower_model, strategy, augment, autoencoder, epochs, prewarm_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

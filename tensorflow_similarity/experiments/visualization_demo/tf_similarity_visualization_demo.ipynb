{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gh94tmvOlGgo"
   },
   "source": [
    "# tf.Similarity Visualization Demo: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ST8JbEUrldut"
   },
   "source": [
    "## Background\n",
    "\n",
    "**tf.similarity**\n",
    "\n",
    "TensorFlow Similarity (tf.similarity) is a soon-to-be open-sourced package for tensorflow that makes training and deploying similarity models easier. More information about tensorflow similarity can be found on its [design doc](https://docs.google.com/document/d/1fEUrWd-XGIHeUoerPPazpKtZVeceBGgyXAuvY41Y2xc/edit#) and [user guide](https://docs.google.com/document/d/1Cx6E1o5o-0wEngNtKhYr1OaKRwKPZAiwRZWyhQJLOc8/edit).\n",
    "\n",
    "**MNIST** \n",
    "\n",
    "**Data Type:** Images, handwritten-digits, black-and-white\n",
    "\n",
    "**Number of Classes:** 10\n",
    "\n",
    "**Description:** Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. This is also the dataset that has been used [Embedding Learner Experiments](https://docs.google.com/document/d/1J8miO0KEu9tjPTeWSubtItPAIAgJ9SGbHKJFwGuzIxI/edit#). This can make it easy to understand how to apply zero/one/few shots learning as we can remove either odds/evens digits samples during time and then in validation/test time test if our models is able to recognize the removed digits. Some research papers used MNIST as benchmark but this dataset may be too simple.\n",
    "[Tf.similarity MNIST experiment](https://security-and-privacy-group-research.googlesource.com/similarity/+/refs/heads/master/moirai/experiments/mnist/).\n",
    "\n",
    "**Single-shot learning**\n",
    "\n",
    "Single-shot learning refers to a type of machine learning problem where we only have a few examples of labeled data. Therefore during training time we only provide a few labeled examples to our models and at test time trying to classify, or find the most similar, unlabeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qZW2jZCEoCTi"
   },
   "source": [
    "## Setup and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1573086003518,
     "user": {
      "displayName": "Shun Lin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC5DnnaOPhEdRpBX0cdhMYO47XtEZQtme3dDNTo=s64",
      "userId": "01442682183887753261"
     },
     "user_tz": 480
    },
    "id": "fmWLjafkkbOR",
    "outputId": "4089127d-6093-4c2b-db61-65a437384832"
   },
   "outputs": [],
   "source": [
    "# this block will not be necessary soon\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following lines to install the required packages\n",
    "# !pip install umap-learn\n",
    "# !pip install plotly\n",
    "# !pip install altair\n",
    "# !pip install MulticoreTSNE\n",
    "# !pip install -U altair vega_datasets notebook vega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "al1FLq0uoO2C"
   },
   "source": [
    "### Download TSNE-CUDA for embedding visualization as Tensorboard Embedding Projector does not work in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14238,
     "status": "ok",
     "timestamp": 1573086017426,
     "user": {
      "displayName": "Shun Lin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC5DnnaOPhEdRpBX0cdhMYO47XtEZQtme3dDNTo=s64",
      "userId": "01442682183887753261"
     },
     "user_tz": 480
    },
    "id": "HNkeMldGoGUr",
    "outputId": "fca7ddb1-b99b-4dd8-a915-de606f43de56"
   },
   "outputs": [],
   "source": [
    "# download and unpack tsnecuda from anaconda.org\n",
    "\n",
    "# uncomment this cell if running on colab, other wise run this in command line\n",
    "'''\n",
    "!wget https://anaconda.org/CannyLab/tsnecuda/2.1.0/download/linux-64/tsnecuda-2.1.0-cuda100.tar.bz2\n",
    "!tar xvjf tsnecuda-2.1.0-cuda100.tar.bz2\n",
    "!cp -r site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
    "\n",
    "# create a symbolic link between the downloaded libfaiss.so file and the location python's looking at\n",
    "\n",
    "!echo $LD_LIBRARY_PATH \n",
    "# this is probably /usr/lib64-nvidia\n",
    "\n",
    "!ln -s /content/lib/libfaiss.so $LD_LIBRARY_PATH/libfaiss.so\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten,\n",
    "                                     Input, MaxPooling2D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJ_Z9ty6o585"
   },
   "source": [
    "### Tensorflow similarity imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wMKM4k3o374"
   },
   "outputs": [],
   "source": [
    "from tensorflow_similarity.api.engine.preprocessing import Preprocessing\n",
    "from tensorflow_similarity.api.engine.simhash import SimHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import altair as alt\n",
    "\n",
    "# enable us to visualize more than 5,000 items for Altair\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# do not need the below line for colab\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7VO4A3EpNDw"
   },
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZraUQ4ypJnY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def read_mnist_data(zero_shot=False, collapse=True):\n",
    "    \"\"\" Returns the mnist data.\n",
    "    \n",
    "    Opens the data file specified by the argument, read each\n",
    "    line and puts 20% of the data into the testing set.\n",
    "    \n",
    "    Args:\n",
    "        data_path: A string that points to the cached mnist\n",
    "            dataset.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple that contains three elements. The first element\n",
    "        is a tuple that contains data used for training and\n",
    "        the second element is a tuple that contains data used\n",
    "        for testing. The third element is a tuple that contains\n",
    "        the target data. All three tuples have the same\n",
    "        structure, they contains two elements. The first\n",
    "        element contains a dictionary for the specs of mnist data\n",
    "        (in 2d np array), the second element contains\n",
    "        an np array of labels of class.\n",
    "    \"\"\"\n",
    "    \n",
    "    (x_train, y_train), (x_test_raw, y_test_raw) = mnist.load_data()\n",
    "    \n",
    "    \n",
    "    if zero_shot:\n",
    "        # train on only even digits and not odd digits\n",
    "        filtered_x_train = []\n",
    "        filtered_y_train = []\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            if y % 2 == 0:\n",
    "                filtered_x_train.append(x)\n",
    "                filtered_y_train.append(y)\n",
    "\n",
    "        x_train = filtered_x_train\n",
    "        y_train = filtered_y_train\n",
    "    elif collapse:\n",
    "        filtered_x_train = []\n",
    "        filtered_y_train = []\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            new_y = y % 5\n",
    "            filtered_x_train.append(x)\n",
    "            filtered_y_train.append(new_y)\n",
    "\n",
    "        x_train = filtered_x_train\n",
    "        y_train = filtered_y_train\n",
    "    \n",
    "        \n",
    "\n",
    "    x_tests = []\n",
    "    y_tests = []\n",
    "\n",
    "    x_targets = []\n",
    "    y_targets = []\n",
    "\n",
    "    test_dicts = defaultdict(list)\n",
    "    for x, y in zip(x_test_raw, y_test_raw):\n",
    "        test_dicts[y].append(np.array(x).flatten())\n",
    "        \n",
    "    for label in test_dicts:\n",
    "        label_test_raw = np.array(test_dicts[label])\n",
    "        \n",
    "        # find mediod for each label\n",
    "        distances = pairwise_distances(label_test_raw, label_test_raw)\n",
    "        med_idx = np.argmin(distances.sum(axis=0))\n",
    "        med = label_test_raw[med_idx]\n",
    "        x_targets.append(med.reshape((28,28)))\n",
    "        y_targets.append(label)\n",
    "        label_test_raw = np.delete(label_test_raw, med_idx, axis=0)\n",
    "        x_tests.extend(label_test_raw.reshape((len(label_test_raw), 28, 28)))\n",
    "        labels = [label] * len(label_test_raw)\n",
    "        y_tests.extend(labels)\n",
    "        \n",
    "\n",
    "    return (({\n",
    "        \"example\": np.array(x_train)\n",
    "    }, np.array(y_train)), ({\n",
    "        \"example\": np.array(x_tests)\n",
    "    }, np.array(y_tests)), ({\n",
    "        \"example\": np.array(x_targets)\n",
    "    }, np.array(y_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFu_nbebpW5H"
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"A simple tower model for mnist dataset.\n",
    "    \n",
    "    Returns:\n",
    "        model: A tensorflow model.\n",
    "    \"\"\"\n",
    "    \n",
    "    i = Input(shape=(28, 28, 1), name=\"example\")\n",
    "    o = Conv2D(\n",
    "        32,\n",
    "        kernel_size=(5, 5),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        input_shape=(28, 28, 1))(i)\n",
    "    o = Conv2D(\n",
    "        32,\n",
    "        kernel_size=(5, 5),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        input_shape=(28, 28, 1))(i)\n",
    "    o = MaxPooling2D(pool_size=(2, 2))(o)\n",
    "    o = Dropout(.25)(o)\n",
    "\n",
    "    o = Conv2D(64, (3, 3), padding='same', activation='relu')(o)\n",
    "    o = Conv2D(64, (3, 3), padding='same', activation='relu')(o)\n",
    "    o = MaxPooling2D(pool_size=(2, 2))(o)\n",
    "    o = Dropout(.25)(o)\n",
    "\n",
    "    o = Flatten()(o)\n",
    "    o = Dense(256, activation=\"relu\")(o)\n",
    "    o = Dropout(.25)(o)\n",
    "    o = Dense(32)(o)\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8k9RN9qgpYPJ"
   },
   "outputs": [],
   "source": [
    "class Normalize(Preprocessing):\n",
    "    \"\"\"A Preprocessing class that normalize the MNIST example inputs.\"\"\"\n",
    "    \n",
    "    def preprocess(self, img):\n",
    "        \"\"\"Normalized and reshape the input images.\"\"\"\n",
    "        \n",
    "        normed = img[\"example\"] / 255.0\n",
    "        normed = normed.reshape((28, 28, 1))\n",
    "        out = {\"example\": normed}\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Elbb-YWlpb_n"
   },
   "outputs": [],
   "source": [
    "def run_mnist_example(data, model, strategy, epochs):\n",
    "    \"\"\"An example usage of tf.similarity.\n",
    "\n",
    "    This basic similarity run will first unpackage training,\n",
    "    testing, and target data from the arguments and then construct a\n",
    "    simple moirai model, fit the model with training data, then\n",
    "    evaluate our model with training and testing datasets.\n",
    "\n",
    "    Args:\n",
    "        data: Sets, contains training, testing, and target datasets.\n",
    "        model: tf.Model, the tower model to fit into moirai.\n",
    "        strategy: String, specify the strategy to use for mining triplets.\n",
    "        epochs: Integer, number of epochs to fit our moirai model.\n",
    "\n",
    "    Returns:\n",
    "        tf_similarity_model: tf.similarity Model instance\n",
    "    \"\"\"\n",
    "        \n",
    "    (x_train, y_train), (x_test, y_test), (x_targets, y_targets) = data\n",
    "\n",
    "    tf_similarity_model = SimHash(\n",
    "        model,\n",
    "        preprocessing=Normalize(),\n",
    "        strategy=strategy,\n",
    "        optimizer=Adam(lr=.001))\n",
    "    \n",
    "    tf_similarity_model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs)\n",
    "\n",
    "    return tf_similarity_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embeddings for test and target dataset when we only train on even digits (zero-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Parameters for tensorflow similarity model\n",
    "data = read_mnist_data(zero_shot=True)\n",
    "model = model_fn()\n",
    "# Strategy we want to use.\n",
    "strategy = \"triplet_loss\" #@param [\"triplet_loss\", \"quadruplet_loss\", \"stable_quadruplet_loss\"]\n",
    "# Number of epochs\n",
    "epochs = 2 #@param {type:\"integer\"}\n",
    "\n",
    "similarity_model = run_mnist_example(data, model, strategy, epochs)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), (x_targets, y_targets) = data\n",
    "zero_shot_test_embeddings = similarity_model.predict(x_test)\n",
    "zero_shot_targets_embeddings = similarity_model.predict(x_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this cell in Ipython Notebook, not on Colab\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nC0uUI_znvnf"
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KurGKHZ9oIKU"
   },
   "source": [
    "### Read in MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPo3EL_Zn2r4"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), (x_targets, y_targets) = read_mnist_data()\n",
    "# the value inside x_test's example key is our images\n",
    "images = x_test[\"example\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pypAo9i7queA"
   },
   "source": [
    "### Import Visualization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_similarity.visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization for Zero Shot on MNIST\n",
    "\n",
    "In the below visualizations, we are visualize how well we did on clustering the odd digits given that we only train on even digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Confusion Matrix of nearest neighbor search trained using tf similarity\"\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "figure = plot_confusion_matrix(zero_shot_test_embeddings, y_test, zero_shot_targets_embeddings, y_targets, title, classes=classes)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"2D Embedding Projector of NMIST dataset\"\n",
    "figure = plot_embedding_projector(zero_shot_test_embeddings, y_test, title=title)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Nearest neighbors of targets trained using tf similarity\"\n",
    "N = 5\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "figure = plot_nearest_neighbors(zero_shot_test_embeddings, y_test, zero_shot_targets_embeddings, y_targets, x_test[\"example\"], x_targets[\"example\"], title, N, classes=classes)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Nearest neighbors table of targets trained using tf similarity\"\n",
    "N = 8\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "figure = plot_nearest_neighbors_table(zero_shot_test_embeddings, y_test, zero_shot_targets_embeddings, y_targets, title, N, classes=classes)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Distance histogram of neareast neighbor search trained using tf similarity\"\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "figure = plot_distance_histograms(zero_shot_test_embeddings, y_test, zero_shot_targets_embeddings, y_targets, title, classes=classes)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title = \"Violin plots of distances trained using tf similarity\"\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "interactive = False\n",
    "figure = plot_distance_violins(zero_shot_test_embeddings, y_test, zero_shot_targets_embeddings, y_targets, title, interactive=interactive, classes=classes)\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:colab_notebook_py3",
    "kind": "private"
   },
   "name": "tf_similarity_demo_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

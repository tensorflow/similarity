{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 The TensorFlow Similarity Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Similarity Self-Supervised Learning Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/similarity/blob/master/examples/unsupervised_hello_world.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/similarity/blob/master/examples/unsupervised_hello_world.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow Similarity](https://github.com/tensorflow/similarity) is a python package focused on making similarity learning and self-supervised learning quick and easy.\n",
    "\n",
    "![self_supervised_overview.png](https://raw.githubusercontent.com/tensorflow/similarity/master/assets/images/self_supervised_overview.png)\n",
    "\n",
    "Self-supervised learning is an approach to pre-training models using unlabeled data. This approach drastically increases accuracy when you have very few labeled examples but a lot of unlabelled data. The key insight is that you can train a self-supervised model to learn data representations by contrasting multiple augmented views of the same example. These learned representations capture data invariants, e.g., object translation, color jitter, noise, etc. Training a simple linear classifier on top of the frozen representations is easier and requires fewer labels because the pre-trained model already produces meaningful and generally useful features. Overall, self-supervised pre-training learns representations which are more [generic](https://arxiv.org/abs/2110.00528) and [robust](https://arxiv.org/abs/1902.01889) than other approaches to augmented training and pre-training. \n",
    "\n",
    "Tensorflow Similarity provides a set of network architectures, losses, and data augmentations that are common across a number of self-supervised learning techniques. The Tensorflow Similarity package attempts to provide a consistent terminology across these techniques; however, this leads to slightly different naming conventions, as many papers use different terms to describe the same components. \n",
    "\n",
    "The main terms used by Tensorflow Similarity are:\n",
    "\n",
    "* **View**: A view represents an augmented example.\n",
    "\n",
    "* **Backbone**: Refers to the model that learns the **Representation** that we will use for downstream tasks.\n",
    "\n",
    "* **Projector**: Is an MLP model that projects the backbone representation of a view to an **Embedding** that is contrasted with other views using a specialized contrastive loss.\n",
    "\n",
    "* **Predictor**: Is an optional MLP model that is used, in conjunction with gradient stopping, in some recent architectures to further improve the representation quality.\n",
    "\n",
    "* **Stop Gradient**: Is used by some algorithms to ensure that we only propagate the update from the main view and not the contrasting view.\n",
    "\n",
    "\n",
    "![contrastive_model_terms.png](https://raw.githubusercontent.com/tensorflow/similarity/master/assets/images/contrastive_model_terms.png)\n",
    "\n",
    "\n",
    "### Notebook goal\n",
    "\n",
    "This notebook demonstrates how to use Tensorflow Similarity to boost classification accuracy by pre-training a ResNet18 model using contrastive learning on the cifar10 dataset. As you will see, the pre-trained model achieves about ~1.8x the accuracy of the model trained without pre-training. For example, **using SimSiam pre-training, you can achieve 87%-91% accuracy versus 50% accuracy when training the same architecture from scratch**.\n",
    "\n",
    "To do this, this notebook walks through how to:\n",
    "\n",
    "1. Create a `tf.data.Dataset` that will generate two augmented views for each example in a batch.\n",
    "\n",
    "2. Create basic versions of **Backbone**, **Projector**, and **Predictor** networks to construct the `ContrastiveModel()`\n",
    "\n",
    "3. Train a `ContrastiveModel()` using one of the following contrastive learning algorithms: [SimCLR](https://arxiv.org/abs/2002.05709), [SimSiam](https://arxiv.org/abs/2011.10566), and [Barlow Twins](https://arxiv.org/abs/2103.03230).\n",
    "\n",
    "4. Compare the classification performance of the pre-trained model versus a model trained from scratch.\n",
    "\n",
    "\n",
    "### Things to try\n",
    "\n",
    "You can explore the following things that will affect the model performance:\n",
    "- Try different self-supervised learning algorithms.\n",
    "- Pre-train on a different dataset, e.g., cifar100.\n",
    "- Restrict supervised training to use a subset of the data, e.g., 100 labels per class.\n",
    "- Use a larger embedding by increasing the size of the projection and predictor layers.\n",
    "- Try using different augmentation profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# INFO messages are not printed.\n",
    "# This must be run before loading other modules.\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# install TF addons if needed\n",
    "try:\n",
    "    import tensorflow_addons as tfa  # main package\n",
    "except ModuleNotFoundError:\n",
    "    %pip install tensorflow-addons\n",
    "    import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install TF similarity if needed\n",
    "try:\n",
    "    import tensorflow_similarity as tfsim  # main package\n",
    "except ModuleNotFoundError:\n",
    "    %pip install tensorflow_similarity\n",
    "    import tensorflow_similarity as tfsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfsim.utils.tf_cap_memory()  # Avoid GPU memory blow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out any old model state.\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.12.0\n",
      "TensorFlow Similarity 0.18.0.dev8\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"TensorFlow Similarity\", tfsim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preperation\n",
    "\n",
    "The following section:\n",
    "* Loads the [CIFAR10](https://www.tensorflow.org/datasets/catalog/cifar10) data from tensorflow datasets.\n",
    "* Creates the train, val, test, and query/index splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"tfsim_contrastive_model\")\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_PATH.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load The Raw Data\n",
    "\n",
    "We are going to load the [CIFAR10](https://www.tensorflow.org/datasets/catalog/cifar10) dataset. This dataset is often used in the self-supervised papers, enabling us to reproduce the published results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x_raw_train, y_raw_train), (x_test, y_test)), ds_info = tfds.load(\n",
    "    \"cifar10\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    batch_size=-1,\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Splits\n",
    "The TensorFlow Datasets' [CIFAR10](https://www.tensorflow.org/datasets/catalog/cifar10) dataset provides a test and train split. \n",
    "* **Train**: Used for self-supervised pre-training and for training the classifiers.\n",
    "* **Test**: Reserved for the classifier evaluation.\n",
    "\n",
    "However, we are going to partition the train data into the following additional splits:\n",
    "\n",
    "* **Validation**: Data used for validation metrics during the pre-training phase. \n",
    "* **Query and Index**: Data used to compute matching metrics. The query data is used to retrieve the nearest indexed examples.\n",
    "\n",
    "In particular, the Query and Index split allows us to track the matching classification performance during training. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE </b> An increasing match accuracy is a strong indication that the model is learning useful features, however, it does require that we have labeled data. If a dataset only has a small number of labeled examples, they can be passed as the query and index to help monitor the potential matching classification performance during training.</div> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the indicies for query, index, val, and train splits\n",
    "query_idxs, index_idxs, val_idxs, train_idxs = [], [], [], []\n",
    "for cid in range(ds_info.features[\"label\"].num_classes):\n",
    "    idxs = tf.random.shuffle(tf.where(y_raw_train == cid))\n",
    "    idxs = tf.reshape(idxs, (-1,))\n",
    "    query_idxs.extend(idxs[:200])  # 200 query examples per class\n",
    "    index_idxs.extend(idxs[200:400])  # 200 index examples per class\n",
    "    val_idxs.extend(idxs[400:500])  # 100 validation examples per class\n",
    "    train_idxs.extend(idxs[500:])  # The remaining are used for training\n",
    "\n",
    "random.shuffle(query_idxs)\n",
    "random.shuffle(index_idxs)\n",
    "random.shuffle(val_idxs)\n",
    "random.shuffle(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split(idxs: list) -> tuple:\n",
    "    x, y = [], []\n",
    "    for idx in idxs:\n",
    "        x.append(x_raw_train[int(idx)])\n",
    "        y.append(y_raw_train[int(idx)])\n",
    "    return tf.convert_to_tensor(np.array(x)), tf.convert_to_tensor(np.array(y))\n",
    "\n",
    "\n",
    "x_query, y_query = create_split(query_idxs)\n",
    "x_index, y_index = create_split(index_idxs)\n",
    "x_val, y_val = create_split(val_idxs)\n",
    "x_train, y_train = create_split(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Examples            Labels\n",
      "-----  ------------------  --------\n",
      "train  (45000, 32, 32, 3)  (45000,)\n",
      "val    (1000, 32, 32, 3)   (1000,)\n",
      "query  (2000, 32, 32, 3)   (2000,)\n",
      "index  (2000, 32, 32, 3)   (2000,)\n",
      "test   (10000, 32, 32, 3)  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tabulate(\n",
    "        [\n",
    "            [\"train\", x_train.shape, y_train.shape],\n",
    "            [\"val\", x_val.shape, y_val.shape],\n",
    "            [\"query\", x_query.shape, y_query.shape],\n",
    "            [\"index\", x_index.shape, y_index.shape],\n",
    "            [\"test\", x_test.shape, y_test.shape],\n",
    "        ],\n",
    "        headers=[\"Examples\", \"Labels\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Training Setup\n",
    "\n",
    "This following section:\n",
    "* Sets the training parameters used for building the different architectures.\n",
    "* Creates a train and test tf.data.Dataset.\n",
    "* Visualizes the pairs of augmented views from a single batch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Supervised Algorithm Selection\n",
    "[TensorFlow Similarity](https://github.com/tensorflow/similarity) currently supports three different self-supervised models.\n",
    "* [SimCLR](http://arxiv.org/abs/2002.05709): Only requires the Backbone and the projector and uses a contrastive cross-entropy loss.\n",
    "* [SimSiam](https://arxiv.org/abs/2011.10566): Requires the Backbone, projector, and predictor and only compares the cosine distance between augmented views from the same example.\n",
    "* [Barlow Twins](https://arxiv.org/abs/2103.03230): Only requires the Backbone and the projector and uses a loss that compares the feature covariance instead of contrasting the views.\n",
    "* [VicReg](https://arxiv.org/abs/2105.04906): Only requires the Backbone and projector and uses a loss that enforces the learned representations to be invariant to random augmentations while preserving the covariance and variance information.\n",
    "\n",
    "The `ALGORITHM` parameter is used throughout this notebook to set up the various architectures and the parameters defined below are set up to reproduce the results published in the papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM = \"simsiam\"  # @param [\"barlow\", \"simsiam\", \"simclr\", \"vicreg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_IMG_SIZE = 32\n",
    "BATCH_SIZE = 512\n",
    "PRE_TRAIN_EPOCHS = 800\n",
    "PRE_TRAIN_STEPS_PER_EPOCH = len(x_train) // BATCH_SIZE\n",
    "VAL_STEPS_PER_EPOCH = 20\n",
    "WEIGHT_DECAY = 5e-4\n",
    "DIM = 2048  # The layer size for the projector and predictor models.\n",
    "WARMUP_LR = 0.0\n",
    "WARMUP_STEPS = 0\n",
    "TEMPERATURE = None\n",
    "\n",
    "if ALGORITHM == \"simsiam\":\n",
    "    INIT_LR = 3e-2 * int(BATCH_SIZE / 256)\n",
    "elif ALGORITHM == \"barlow\":\n",
    "    INIT_LR = 1e-3  # Initial LR for the learning rate schedule.\n",
    "    WARMUP_STEPS = 1000\n",
    "elif ALGORITHM == \"simclr\":\n",
    "    INIT_LR = 1e-3  # Initial LR for the learning rate schedule, see section B.1 in the paper.\n",
    "    TEMPERATURE = 0.5  # Tuned for CIFAR10, see section B.9 in the paper.\n",
    "elif ALGORITHM == \"vicreg\":\n",
    "    INIT_LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Augmented View Configuration\n",
    "\n",
    "Self-supervised networks require at least two augmented \"views\" of each example. This can be created using a DataSet and an augmentation function. The DataSet treats each example in the batch as its own class and then the augment function produces two separate views for each example. \n",
    "\n",
    "This means the resulting batch will yield tuples containing the two views, i.e., `Tuple[(BATCH_SIZE, 32, 32, 3), (BATCH_SIZE, 32, 32, 3)]`. TODO make this clearer, \"each example in the batch is of this type\"\n",
    "\n",
    "TensorFlow Similarity provides several random augmentation functions, and here we combine augmenters from the simCLR module to replicate the augmentations used in simsiam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_scaling(img):\n",
    "    return tf.keras.applications.imagenet_utils.preprocess_input(img, data_format=None, mode=\"torch\")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def simsiam_augmenter(img, blur=True, area_range=(0.2, 1.0)):\n",
    "    \"\"\"SimSiam augmenter.\n",
    "\n",
    "    The SimSiam augmentations are based on the SimCLR augmentations, but have\n",
    "    some important differences.\n",
    "    * The crop area lower bound is 20% instead of 8%.\n",
    "    * The color jitter and grayscale are applied separately instead of together.\n",
    "    * The color jitter ranges are much smaller.\n",
    "    * Blur is not applied for the cifar10 dataset.\n",
    "\n",
    "    args:\n",
    "        img: Single image tensor of shape (H, W, C)\n",
    "        blur: If true, apply blur. Should be disabled for cifar10.\n",
    "        area_range: The upper and lower bound of the random crop percentage.\n",
    "\n",
    "    returns:\n",
    "        A single image tensor of shape (H, W, C) with values between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "    # random resize and crop. Increase the size before we crop.\n",
    "    img = tfsim.augmenters.augmentation_utils.cropping.crop_and_resize(\n",
    "        img, CIFAR_IMG_SIZE, CIFAR_IMG_SIZE, area_range=area_range\n",
    "    )\n",
    "\n",
    "    # The following transforms expect the data to be [0, 1]\n",
    "    img /= 255.0\n",
    "\n",
    "    # random color jitter\n",
    "    def _jitter_transform(x):\n",
    "        return tfsim.augmenters.augmentation_utils.color_jitter.color_jitter_rand(\n",
    "            x,\n",
    "            np.random.uniform(0.0, 0.4),\n",
    "            np.random.uniform(0.0, 0.4),\n",
    "            np.random.uniform(0.0, 0.4),\n",
    "            np.random.uniform(0.0, 0.1),\n",
    "            \"multiplicative\",\n",
    "        )\n",
    "\n",
    "    img = tfsim.augmenters.augmentation_utils.random_apply.random_apply(_jitter_transform, p=0.8, x=img)\n",
    "\n",
    "    # # random grayscale\n",
    "    def _grascayle_transform(x):\n",
    "        return tfsim.augmenters.augmentation_utils.color_jitter.to_grayscale(x)\n",
    "\n",
    "    img = tfsim.augmenters.augmentation_utils.random_apply.random_apply(_grascayle_transform, p=0.2, x=img)\n",
    "\n",
    "    # optional random gaussian blur\n",
    "    if blur:\n",
    "        img = tfsim.augmenters.augmentation_utils.blur.random_blur(img, p=0.5)\n",
    "\n",
    "    # random horizontal flip\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "\n",
    "    # scale the data back to [0, 255]\n",
    "    img = img * 255.0\n",
    "    img = tf.clip_by_value(img, 0.0, 255.0)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def process(img):\n",
    "    view1 = simsiam_augmenter(img, blur=False)\n",
    "    view1 = img_scaling(view1)\n",
    "    view2 = simsiam_augmenter(img, blur=False)\n",
    "    view2 = img_scaling(view2)\n",
    "    return (view1, view2)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.shuffle(1024)\n",
    "train_ds = train_ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(x_val)\n",
    "val_ds = val_ds.repeat()\n",
    "val_ds = val_ds.shuffle(1024)\n",
    "val_ds = val_ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Augmentations\n",
    "\n",
    "The following cell plots the pairs of augmented views side by side. This can be a useful sanity check as many augmentation functions are set up for the larger ImageNet examples and can be overly aggressive for smaller images found in CIFAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_imgs = next(train_ds.as_numpy_iterator())\n",
    "max_pixel = np.max([display_imgs[0].max(), display_imgs[1].max()])\n",
    "min_pixel = np.min([display_imgs[0].min(), display_imgs[1].min()])\n",
    "\n",
    "tfsim.visualization.visualize_views(\n",
    "    views=display_imgs,\n",
    "    num_imgs=16,\n",
    "    views_per_col=8,\n",
    "    max_pixel_value=max_pixel,\n",
    "    min_pixel_value=min_pixel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrastive Model Setup\n",
    " \n",
    "The following section creates the sub-models used by the different algorithms. There are various architectures for building self-supervised models which may include some of the following:\n",
    "* **Backbone**: This is the base model and is typically an existing architecture like ResNet or EfficientNet.\n",
    "* **Projector**: This is a small multi-layer Neural Net and provides the embedding features at the end of training.\n",
    "* **Predictor**: This model is used by BYOL and SimSiam and provides an additional small multi-layer Neural Net.\n",
    " \n",
    "Typically, the projector and predictor networks are only 2 or 3 layers with batch normalization. While some [papers](https://arxiv.org/abs/2010.10241) claim that batch normalization is not required, the [SimSiam paper](https://arxiv.org/abs/2011.10566) shows empirically that the batch normalization is critical to prevent the model from collapsing to a degenerate solution.\n",
    " \n",
    "Additionally, many papers show a single `encoder` block, but this often contains both the `Backbone` and the `Projector` network.\n",
    " \n",
    "![contrastive_loss_functions.png](https://raw.githubusercontent.com/tensorflow/similarity/master/assets/images/contrastive_loss_functions.png)\n",
    " \n",
    "The diagram above shows three self-supervised architectures supported by TensorFlow Similarity. As you can see, they all share a common structure:\n",
    "* Processing multiple views of the same example.\n",
    "* Using a backbone model for learning the representation output. \n",
    "* Using a projector for the embedding output.\n",
    "* Additionally, note that the loss is symmetric, so we compute it twice during each step. First for view 1 and then a second time for view 2. These two losses are then summed up to compute the final aggregate loss.\n",
    " \n",
    "However, there are some key differences including:\n",
    " \n",
    "* The loss is different in each of the three architectures.\n",
    "    * SimCLR uses a contrastive cross-entropy loss where each example's pair of augmented views should be close to 1 and all other views should be close to zero. Including the negative examples in the loss is part of the reason that SimCLR benefits from larger batch sizes.\n",
    "    * SimSiam only compares the cosine distance between the pairs of augmented views. This means there are no negative examples in the loss, and consequently, the batch size can be much smaller.\n",
    "    * Barlow Twins attempts to learn the cross-correlation between the embedding features, where similar feature activations between two views will produce small values along the diagonal and a positive penalty is applied for positive or negative off-diagonal correlations. In this way the diagonal represents features that are invariant to augmented views, while the off-diagonal values encourage the features to be independent of each other.\n",
    "* The SimSiam architecture requires an additional Predictor network.\n",
    "* The SimSiam architecture also uses a stop-gradient to ensure that we only flow the gradient from the target view.\n",
    " \n",
    " \n",
    "TensorFlow Similarity offers a common set of modules to construct the common parts, and implement the parts which are specific to popular self-supervised algorithms on top of it. Attempting to offer flexibility to add your own algorithm or reuse proven architectures that the results we have reproduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Backbone Model\n",
    "\n",
    "The backbone uses a custom version of ResNet18 in order to reproduce the SimSiam CIFAR10 results.\n",
    " \n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> The ResNet models provided in `tf.keras.applications` use larger `[(1x1), (3x3), (1x1)]` blocks that can't be used to reproduce the SimSiam CIFAR10 results. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet18sim\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " resnet18 (Functional)       (None, 4, 4, 512)         11182784  \n",
      "                                                                 \n",
      " avg_pool (GlobalAveragePool  (None, 512)              0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,182,784\n",
      "Trainable params: 11,173,056\n",
      "Non-trainable params: 9,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_backbone(img_size, activation=\"relu\", preproc_mode=\"torch\"):\n",
    "    input_shape = (img_size, img_size, 3)\n",
    "\n",
    "    backbone = tfsim.architectures.ResNet18Sim(\n",
    "        input_shape,\n",
    "        include_top=False,  # Take the pooling layer as the output.\n",
    "        pooling=\"avg\",\n",
    "    )\n",
    "    return backbone\n",
    "\n",
    "\n",
    "backbone = get_backbone(CIFAR_IMG_SIZE)\n",
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projector Model\n",
    " \n",
    "This MLP is common to all the self-supervised models and is typically a stack of 3 layers of the same size. However, SimSiam only uses 2 layers for the smaller CIFAR images. Having too much capacity in the models can make it difficult for the loss to stabilize and converge.\n",
    " \n",
    "Additionally, the SimSiam paper found that disabling the center and scale parameters can lead to a small boost in the final loss.\n",
    " \n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> This is the model output that is returned by `ContrastiveModel.predict()` and represents the distance based embedding. This embedding can be used for the KNN lookups and matching classification metrics. However, when using the pre-train model for downstream tasks, only the `ContrastiveModel.backbone` is used. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "projector = None  # Passing None will automatically build the default projector.\n",
    "\n",
    "# Uncomment to build a custom projector.\n",
    "# def get_projector(input_dim, dim, activation=\"relu\", num_layers: int = 3):\n",
    "#     inputs = tf.keras.layers.Input((input_dim,), name=\"projector_input\")\n",
    "#     x = inputs\n",
    "\n",
    "#     for i in range(num_layers - 1):\n",
    "#         x = tf.keras.layers.Dense(\n",
    "#             dim,\n",
    "#             use_bias=False,\n",
    "#             kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "#             name=f\"projector_layer_{i}\",\n",
    "#         )(x)\n",
    "#         x = tf.keras.layers.BatchNormalization(epsilon=1.001e-5, name=f\"batch_normalization_{i}\")(x)\n",
    "#         x = tf.keras.layers.Activation(activation, name=f\"{activation}_activation_{i}\")(x)\n",
    "#     x = tf.keras.layers.Dense(\n",
    "#         dim,\n",
    "#         use_bias=False,\n",
    "#         kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "#         name=\"projector_output\",\n",
    "#     )(x)\n",
    "#     x = tf.keras.layers.BatchNormalization(\n",
    "#         epsilon=1.001e-5,\n",
    "#         center=False,  # Page:5, Paragraph:2 of SimSiam paper\n",
    "#         scale=False,  # Page:5, Paragraph:2 of SimSiam paper\n",
    "#         name=f\"batch_normalization_ouput\",\n",
    "#     )(x)\n",
    "#     # Metric Logging layer. Monitors the std of the layer activations.\n",
    "#     # Degnerate solutions colapse to 0 while valid solutions will move\n",
    "#     # towards something like 0.0220. The actual number will depend on the layer size.\n",
    "#     o = tfsim.layers.ActivationStdLoggingLayer(name=\"proj_std\")(x)\n",
    "#     projector = tf.keras.Model(inputs, o, name=\"projector\")\n",
    "#     return projector\n",
    "\n",
    "# projector = get_projector(input_dim=backbone.output.shape[-1], dim=DIM, num_layers=2)\n",
    "# projector.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor model\n",
    "\n",
    "The predictor model is used by [BYOL](https://arxiv.org/abs/2006.07733) and [SimSiam](https://arxiv.org/abs/2011.10566), and is an additional 2 layer MLP containing a bottleneck in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = None  # Passing None will automatically build the default predictor.\n",
    "\n",
    "# Uncomment to build a custom predictor.\n",
    "# def get_predictor(input_dim, hidden_dim=512, activation=\"relu\"):\n",
    "#     inputs = tf.keras.layers.Input(shape=(input_dim,), name=\"predictor_input\")\n",
    "#     x = inputs\n",
    "\n",
    "#     x = tf.keras.layers.Dense(\n",
    "#         hidden_dim,\n",
    "#         use_bias=False,\n",
    "#         kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "#         name=\"predictor_layer_0\",\n",
    "#     )(x)\n",
    "#     x = tf.keras.layers.BatchNormalization(epsilon=1.001e-5, name=\"batch_normalization_0\")(x)\n",
    "#     x = tf.keras.layers.Activation(activation, name=f\"{activation}_activation_0\")(x)\n",
    "\n",
    "#     x = tf.keras.layers.Dense(\n",
    "#         input_dim,\n",
    "#         kernel_initializer=tf.keras.initializers.LecunUniform(),\n",
    "#         name=\"predictor_output\",\n",
    "#     )(x)\n",
    "#     # Metric Logging layer. Monitors the std of the layer activations.\n",
    "#     # Degnerate solutions colapse to 0 while valid solutions will move\n",
    "#     # towards something like 0.0220. The actual number will depend on the layer size.\n",
    "#     o = tfsim.layers.ActivationStdLoggingLayer(name=\"pred_std\")(x)\n",
    "#     predictor = tf.keras.Model(inputs, o, name=\"predictor\")\n",
    "#     return predictor\n",
    "\n",
    "\n",
    "# predictor = get_predictor(input_dim=DIM, hidden_dim=512)\n",
    "# predictor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Self-Supervised Algorithms\n",
    " \n",
    "The following section builds the `ContrastiveModel` based on the `ALGORITHM` set at the start of the Notebook.\n",
    " \n",
    "The model training is very sensitive to the learning rate decay and weight decay.\n",
    "* **SimSiam**: Requires using SGD with weight decay from TF Addons. Adding weight decay as a kernel_regularizer doesn't seem to be able to reproduce the published results in the paper.\n",
    "* **Barlow Twins**: We can use LAMB and avoid the need for the learning rate schedule. Lamb is similar to the LARS optimizer used in the Barlow paper, but includes the use of ADAM. Alternatively, we can use SGD but the optimizer requires a warm up period, otherwise the loss explodes.\n",
    "* **SimCLR**: We can also use LAMB as the original paper uses LARS. However, LAMB seems to require smaller learning rates than shown for LARS in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_model = tfsim.models.create_contrastive_model(\n",
    "    backbone=backbone,\n",
    "    projector=projector,\n",
    "    predictor=predictor,\n",
    "    algorithm=ALGORITHM,\n",
    "    name=ALGORITHM,\n",
    ")\n",
    "\n",
    "if ALGORITHM == \"simsiam\":\n",
    "    loss = tfsim.losses.SimSiamLoss(projection_type=\"cosine_distance\", name=ALGORITHM)\n",
    "    lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=INIT_LR,\n",
    "        decay_steps=PRE_TRAIN_EPOCHS * PRE_TRAIN_STEPS_PER_EPOCH,\n",
    "    )\n",
    "    wd_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=WEIGHT_DECAY,\n",
    "        decay_steps=PRE_TRAIN_EPOCHS * PRE_TRAIN_STEPS_PER_EPOCH,\n",
    "    )\n",
    "    optimizer = tfa.optimizers.SGDW(learning_rate=lr_decayed_fn, weight_decay=wd_decayed_fn, momentum=0.9)\n",
    "elif ALGORITHM == \"barlow\":\n",
    "    loss = tfsim.losses.Barlow(name=ALGORITHM)\n",
    "    optimizer = tfa.optimizers.LAMB(learning_rate=INIT_LR)\n",
    "elif ALGORITHM == \"simclr\":\n",
    "    loss = tfsim.losses.SimCLRLoss(name=ALGORITHM, temperature=TEMPERATURE)\n",
    "    optimizer = tfa.optimizers.LAMB(learning_rate=INIT_LR)\n",
    "elif ALGORITHM == \"vicreg\":\n",
    "    loss = tfsim.losses.VicReg(name=ALGORITHM)\n",
    "    optimizer = tfa.optimizers.LAMB(learning_rate=INIT_LR)\n",
    "else:\n",
    "    raise ValueError(f\"{ALGORITHM} is not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "We track the training using several callbacks.\n",
    "\n",
    "* **EvalCallback** creates an index at the end of each epoch and provides a proxy for the nearest neighbor matching classification using `binary_accuracy`.\n",
    "* **TensordBoard** and **ModelCheckpoint** are provided for tracking the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logging enable in tfsim_contrastive_model/models/logs/simsiam_1693374514.0196445/index\n"
     ]
    }
   ],
   "source": [
    "log_dir = DATA_PATH / \"models\" / \"logs\" / f\"{loss.name}_{time.time()}\"\n",
    "chkpt_dir = DATA_PATH / \"models\" / \"checkpoints\" / f\"{loss.name}_{time.time()}\"\n",
    "\n",
    "\n",
    "evb = tfsim.callbacks.EvalCallback(\n",
    "    img_scaling(tf.cast(x_query, tf.float32)),\n",
    "    y_query,\n",
    "    img_scaling(tf.cast(x_index, tf.float32)),\n",
    "    y_index,\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    k=1,\n",
    "    tb_logdir=log_dir,\n",
    ")\n",
    "tbc = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq=100,\n",
    ")\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=chkpt_dir,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training\n",
    " \n",
    "The model training provides a number of metrics.\n",
    "- **loss**: This represents the total loss over the contrastive batch. Separate contrastive and regularization losses will also be shown if there are trainable variables in the model layers.\n",
    "- **proj_std and pred_std**: These are added as metric logging layers in the model and show the std of the activations of the final layer in the projector or predictor models.\n",
    "- **binary_accuracy**: This is the nearest neighbor matching classification accuracy. A new index is built at the end of each epoch and the accuracy is computed using the query and index examples.\n",
    " \n",
    "**Notes: Move this to the evaluation section in the paper.**\n",
    "- SGDW or LAMB seems to be required to prevent the loss from becoming unstable.\n",
    "- Per layer kernel_regularization with weight decay doesn't work.\n",
    "- The kernel initialization seems very critical. Smaller, uniform initialization schemes like Lecunn seem to work best.\n",
    "- The projector is a more stable output for the KNN match metrics. The predictor output is typically worse and higher variance.\n",
    "- The LR and weight decay schedule seem important. The loss becomes unstable if the updates are too large later in training.\n",
    "- Too much capacity in the combined model and the training won't converge... same goes for too little capacity.\n",
    "- Augmentation is critical, but too much augmentation and the model won't converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 05:48:44.369623: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.38GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-30 05:48:44.407745: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.38GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/87 [..............................] - ETA: 19:46 - loss: 1.0021 - projector_loss: 0.5010 - proj_std: 0.0438 - pred_std: 0.0370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 05:48:48.593058: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.38GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-30 05:48:48.618247: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.38GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 40s 301ms/step - loss: 0.4997 - projector_loss: 0.2498 - proj_std: 0.0395 - pred_std: 0.0336 - val_loss: 0.1342 - val_projector_loss: 0.0671 - val_proj_std: 0.0202 - val_pred_std: 0.0154 - binary_accuracy: 0.2120\n",
      "Epoch 2/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.2892 - projector_loss: 0.1446 - proj_std: 0.0401 - pred_std: 0.0375 - val_loss: 0.1246 - val_projector_loss: 0.0623 - val_proj_std: 0.0261 - val_pred_std: 0.0222 - binary_accuracy: 0.2375\n",
      "Epoch 3/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.2475 - projector_loss: 0.1238 - proj_std: 0.0404 - pred_std: 0.0386 - val_loss: 0.1035 - val_projector_loss: 0.0517 - val_proj_std: 0.0256 - val_pred_std: 0.0223 - binary_accuracy: 0.2485\n",
      "Epoch 4/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.2301 - projector_loss: 0.1151 - proj_std: 0.0405 - pred_std: 0.0387 - val_loss: 0.1044 - val_projector_loss: 0.0522 - val_proj_std: 0.0272 - val_pred_std: 0.0249 - binary_accuracy: 0.2495\n",
      "Epoch 5/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.2213 - projector_loss: 0.1106 - proj_std: 0.0407 - pred_std: 0.0391 - val_loss: 0.1176 - val_projector_loss: 0.0588 - val_proj_std: 0.0290 - val_pred_std: 0.0269 - binary_accuracy: 0.2545\n",
      "Epoch 6/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.2170 - projector_loss: 0.1085 - proj_std: 0.0409 - pred_std: 0.0394 - val_loss: 0.1152 - val_projector_loss: 0.0576 - val_proj_std: 0.0297 - val_pred_std: 0.0277 - binary_accuracy: 0.2500\n",
      "Epoch 7/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.2192 - projector_loss: 0.1096 - proj_std: 0.0412 - pred_std: 0.0398 - val_loss: 0.0775 - val_projector_loss: 0.0388 - val_proj_std: 0.0248 - val_pred_std: 0.0227 - binary_accuracy: 0.2495\n",
      "Epoch 8/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.2179 - projector_loss: 0.1090 - proj_std: 0.0416 - pred_std: 0.0404 - val_loss: 0.1061 - val_projector_loss: 0.0531 - val_proj_std: 0.0280 - val_pred_std: 0.0256 - binary_accuracy: 0.2625\n",
      "Epoch 9/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.2310 - projector_loss: 0.1155 - proj_std: 0.0425 - pred_std: 0.0414 - val_loss: 0.1319 - val_projector_loss: 0.0660 - val_proj_std: 0.0315 - val_pred_std: 0.0297 - binary_accuracy: 0.2780\n",
      "Epoch 10/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.2177 - projector_loss: 0.1088 - proj_std: 0.0422 - pred_std: 0.0412 - val_loss: 0.1095 - val_projector_loss: 0.0547 - val_proj_std: 0.0295 - val_pred_std: 0.0278 - binary_accuracy: 0.2750\n",
      "Epoch 11/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.2136 - projector_loss: 0.1068 - proj_std: 0.0427 - pred_std: 0.0418 - val_loss: 0.1055 - val_projector_loss: 0.0527 - val_proj_std: 0.0294 - val_pred_std: 0.0278 - binary_accuracy: 0.3165\n",
      "Epoch 12/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.2151 - projector_loss: 0.1076 - proj_std: 0.0428 - pred_std: 0.0421 - val_loss: 0.1485 - val_projector_loss: 0.0743 - val_proj_std: 0.0344 - val_pred_std: 0.0329 - binary_accuracy: 0.2910\n",
      "Epoch 13/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.2013 - projector_loss: 0.1007 - proj_std: 0.0427 - pred_std: 0.0420 - val_loss: 0.0744 - val_projector_loss: 0.0372 - val_proj_std: 0.0247 - val_pred_std: 0.0235 - binary_accuracy: 0.3080\n",
      "Epoch 14/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1977 - projector_loss: 0.0988 - proj_std: 0.0429 - pred_std: 0.0423 - val_loss: 0.0958 - val_projector_loss: 0.0479 - val_proj_std: 0.0290 - val_pred_std: 0.0282 - binary_accuracy: 0.3215\n",
      "Epoch 15/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1941 - projector_loss: 0.0970 - proj_std: 0.0430 - pred_std: 0.0424 - val_loss: 0.0924 - val_projector_loss: 0.0462 - val_proj_std: 0.0276 - val_pred_std: 0.0264 - binary_accuracy: 0.3210\n",
      "Epoch 16/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1791 - projector_loss: 0.0896 - proj_std: 0.0429 - pred_std: 0.0423 - val_loss: 0.0782 - val_projector_loss: 0.0391 - val_proj_std: 0.0276 - val_pred_std: 0.0271 - binary_accuracy: 0.3315\n",
      "Epoch 17/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1797 - projector_loss: 0.0898 - proj_std: 0.0431 - pred_std: 0.0426 - val_loss: 0.0775 - val_projector_loss: 0.0387 - val_proj_std: 0.0266 - val_pred_std: 0.0255 - binary_accuracy: 0.3335\n",
      "Epoch 18/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1772 - projector_loss: 0.0886 - proj_std: 0.0433 - pred_std: 0.0428 - val_loss: 0.0825 - val_projector_loss: 0.0412 - val_proj_std: 0.0286 - val_pred_std: 0.0282 - binary_accuracy: 0.3345\n",
      "Epoch 19/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1787 - projector_loss: 0.0893 - proj_std: 0.0432 - pred_std: 0.0427 - val_loss: 0.1108 - val_projector_loss: 0.0554 - val_proj_std: 0.0316 - val_pred_std: 0.0308 - binary_accuracy: 0.3560\n",
      "Epoch 20/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1809 - projector_loss: 0.0905 - proj_std: 0.0432 - pred_std: 0.0427 - val_loss: 0.1105 - val_projector_loss: 0.0553 - val_proj_std: 0.0318 - val_pred_std: 0.0316 - binary_accuracy: 0.3535\n",
      "Epoch 21/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1892 - projector_loss: 0.0946 - proj_std: 0.0431 - pred_std: 0.0426 - val_loss: 0.0656 - val_projector_loss: 0.0328 - val_proj_std: 0.0224 - val_pred_std: 0.0216 - binary_accuracy: 0.3390\n",
      "Epoch 22/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1847 - projector_loss: 0.0923 - proj_std: 0.0433 - pred_std: 0.0428 - val_loss: 0.1344 - val_projector_loss: 0.0672 - val_proj_std: 0.0334 - val_pred_std: 0.0329 - binary_accuracy: 0.3325\n",
      "Epoch 23/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1758 - projector_loss: 0.0879 - proj_std: 0.0434 - pred_std: 0.0430 - val_loss: 0.1143 - val_projector_loss: 0.0572 - val_proj_std: 0.0324 - val_pred_std: 0.0318 - binary_accuracy: 0.3610\n",
      "Epoch 24/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1804 - projector_loss: 0.0902 - proj_std: 0.0436 - pred_std: 0.0432 - val_loss: 0.1351 - val_projector_loss: 0.0675 - val_proj_std: 0.0347 - val_pred_std: 0.0344 - binary_accuracy: 0.3970\n",
      "Epoch 25/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1861 - projector_loss: 0.0931 - proj_std: 0.0436 - pred_std: 0.0432 - val_loss: 0.1180 - val_projector_loss: 0.0590 - val_proj_std: 0.0308 - val_pred_std: 0.0304 - binary_accuracy: 0.4040\n",
      "Epoch 26/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1941 - projector_loss: 0.0971 - proj_std: 0.0435 - pred_std: 0.0430 - val_loss: 0.1150 - val_projector_loss: 0.0575 - val_proj_std: 0.0300 - val_pred_std: 0.0283 - binary_accuracy: 0.3840\n",
      "Epoch 27/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1902 - projector_loss: 0.0951 - proj_std: 0.0435 - pred_std: 0.0431 - val_loss: 0.1605 - val_projector_loss: 0.0803 - val_proj_std: 0.0360 - val_pred_std: 0.0367 - binary_accuracy: 0.3915\n",
      "Epoch 28/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1929 - projector_loss: 0.0965 - proj_std: 0.0436 - pred_std: 0.0432 - val_loss: 0.1525 - val_projector_loss: 0.0762 - val_proj_std: 0.0338 - val_pred_std: 0.0332 - binary_accuracy: 0.3980\n",
      "Epoch 29/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1922 - projector_loss: 0.0961 - proj_std: 0.0435 - pred_std: 0.0430 - val_loss: 0.1181 - val_projector_loss: 0.0590 - val_proj_std: 0.0293 - val_pred_std: 0.0285 - binary_accuracy: 0.3830\n",
      "Epoch 30/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1870 - projector_loss: 0.0935 - proj_std: 0.0434 - pred_std: 0.0429 - val_loss: 0.1061 - val_projector_loss: 0.0530 - val_proj_std: 0.0288 - val_pred_std: 0.0284 - binary_accuracy: 0.3980\n",
      "Epoch 31/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1908 - projector_loss: 0.0954 - proj_std: 0.0437 - pred_std: 0.0433 - val_loss: 0.1681 - val_projector_loss: 0.0841 - val_proj_std: 0.0334 - val_pred_std: 0.0341 - binary_accuracy: 0.4190\n",
      "Epoch 32/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1927 - projector_loss: 0.0964 - proj_std: 0.0436 - pred_std: 0.0431 - val_loss: 0.1188 - val_projector_loss: 0.0594 - val_proj_std: 0.0300 - val_pred_std: 0.0293 - binary_accuracy: 0.4410\n",
      "Epoch 33/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1857 - projector_loss: 0.0928 - proj_std: 0.0438 - pred_std: 0.0434 - val_loss: 0.1450 - val_projector_loss: 0.0725 - val_proj_std: 0.0354 - val_pred_std: 0.0345 - binary_accuracy: 0.4520\n",
      "Epoch 34/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1910 - projector_loss: 0.0955 - proj_std: 0.0437 - pred_std: 0.0434 - val_loss: 0.1554 - val_projector_loss: 0.0777 - val_proj_std: 0.0324 - val_pred_std: 0.0328 - binary_accuracy: 0.4125\n",
      "Epoch 35/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1916 - projector_loss: 0.0958 - proj_std: 0.0437 - pred_std: 0.0432 - val_loss: 0.1485 - val_projector_loss: 0.0743 - val_proj_std: 0.0350 - val_pred_std: 0.0339 - binary_accuracy: 0.4305\n",
      "Epoch 36/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1854 - projector_loss: 0.0927 - proj_std: 0.0438 - pred_std: 0.0434 - val_loss: 0.1759 - val_projector_loss: 0.0880 - val_proj_std: 0.0398 - val_pred_std: 0.0396 - binary_accuracy: 0.4550\n",
      "Epoch 37/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1862 - projector_loss: 0.0931 - proj_std: 0.0436 - pred_std: 0.0432 - val_loss: 0.1689 - val_projector_loss: 0.0844 - val_proj_std: 0.0372 - val_pred_std: 0.0365 - binary_accuracy: 0.4460\n",
      "Epoch 38/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1857 - projector_loss: 0.0929 - proj_std: 0.0438 - pred_std: 0.0434 - val_loss: 0.1626 - val_projector_loss: 0.0813 - val_proj_std: 0.0360 - val_pred_std: 0.0350 - binary_accuracy: 0.4400\n",
      "Epoch 39/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1806 - projector_loss: 0.0903 - proj_std: 0.0437 - pred_std: 0.0433 - val_loss: 0.1545 - val_projector_loss: 0.0772 - val_proj_std: 0.0362 - val_pred_std: 0.0355 - binary_accuracy: 0.4485\n",
      "Epoch 40/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1783 - projector_loss: 0.0892 - proj_std: 0.0435 - pred_std: 0.0431 - val_loss: 0.1703 - val_projector_loss: 0.0851 - val_proj_std: 0.0377 - val_pred_std: 0.0368 - binary_accuracy: 0.4660\n",
      "Epoch 41/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1770 - projector_loss: 0.0885 - proj_std: 0.0435 - pred_std: 0.0431 - val_loss: 0.1781 - val_projector_loss: 0.0890 - val_proj_std: 0.0393 - val_pred_std: 0.0404 - binary_accuracy: 0.4995\n",
      "Epoch 42/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1809 - projector_loss: 0.0904 - proj_std: 0.0435 - pred_std: 0.0431 - val_loss: 0.1891 - val_projector_loss: 0.0946 - val_proj_std: 0.0389 - val_pred_std: 0.0393 - binary_accuracy: 0.4725\n",
      "Epoch 43/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1753 - projector_loss: 0.0877 - proj_std: 0.0437 - pred_std: 0.0433 - val_loss: 0.1645 - val_projector_loss: 0.0823 - val_proj_std: 0.0390 - val_pred_std: 0.0394 - binary_accuracy: 0.4760\n",
      "Epoch 44/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1750 - projector_loss: 0.0875 - proj_std: 0.0433 - pred_std: 0.0429 - val_loss: 0.1952 - val_projector_loss: 0.0976 - val_proj_std: 0.0387 - val_pred_std: 0.0384 - binary_accuracy: 0.4665\n",
      "Epoch 45/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1707 - projector_loss: 0.0853 - proj_std: 0.0433 - pred_std: 0.0429 - val_loss: 0.1542 - val_projector_loss: 0.0771 - val_proj_std: 0.0359 - val_pred_std: 0.0349 - binary_accuracy: 0.4755\n",
      "Epoch 46/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1728 - projector_loss: 0.0864 - proj_std: 0.0434 - pred_std: 0.0430 - val_loss: 0.1616 - val_projector_loss: 0.0808 - val_proj_std: 0.0384 - val_pred_std: 0.0381 - binary_accuracy: 0.4670\n",
      "Epoch 47/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1687 - projector_loss: 0.0844 - proj_std: 0.0436 - pred_std: 0.0433 - val_loss: 0.1576 - val_projector_loss: 0.0788 - val_proj_std: 0.0374 - val_pred_std: 0.0372 - binary_accuracy: 0.4675\n",
      "Epoch 48/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1709 - projector_loss: 0.0855 - proj_std: 0.0436 - pred_std: 0.0433 - val_loss: 0.1722 - val_projector_loss: 0.0861 - val_proj_std: 0.0406 - val_pred_std: 0.0410 - binary_accuracy: 0.5045\n",
      "Epoch 49/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1671 - projector_loss: 0.0836 - proj_std: 0.0437 - pred_std: 0.0434 - val_loss: 0.1724 - val_projector_loss: 0.0862 - val_proj_std: 0.0389 - val_pred_std: 0.0383 - binary_accuracy: 0.4735\n",
      "Epoch 50/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1671 - projector_loss: 0.0836 - proj_std: 0.0435 - pred_std: 0.0432 - val_loss: 0.1683 - val_projector_loss: 0.0841 - val_proj_std: 0.0390 - val_pred_std: 0.0396 - binary_accuracy: 0.4955\n",
      "Epoch 51/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1616 - projector_loss: 0.0808 - proj_std: 0.0433 - pred_std: 0.0430 - val_loss: 0.1661 - val_projector_loss: 0.0830 - val_proj_std: 0.0389 - val_pred_std: 0.0386 - binary_accuracy: 0.5015\n",
      "Epoch 52/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1619 - projector_loss: 0.0810 - proj_std: 0.0434 - pred_std: 0.0430 - val_loss: 0.1531 - val_projector_loss: 0.0765 - val_proj_std: 0.0360 - val_pred_std: 0.0356 - binary_accuracy: 0.5020\n",
      "Epoch 53/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1655 - projector_loss: 0.0827 - proj_std: 0.0436 - pred_std: 0.0432 - val_loss: 0.1491 - val_projector_loss: 0.0745 - val_proj_std: 0.0367 - val_pred_std: 0.0365 - binary_accuracy: 0.5130\n",
      "Epoch 54/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1630 - projector_loss: 0.0815 - proj_std: 0.0437 - pred_std: 0.0434 - val_loss: 0.1661 - val_projector_loss: 0.0830 - val_proj_std: 0.0378 - val_pred_std: 0.0373 - binary_accuracy: 0.5100\n",
      "Epoch 55/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1630 - projector_loss: 0.0815 - proj_std: 0.0435 - pred_std: 0.0431 - val_loss: 0.1623 - val_projector_loss: 0.0812 - val_proj_std: 0.0384 - val_pred_std: 0.0385 - binary_accuracy: 0.5120\n",
      "Epoch 56/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1619 - projector_loss: 0.0810 - proj_std: 0.0438 - pred_std: 0.0434 - val_loss: 0.1508 - val_projector_loss: 0.0754 - val_proj_std: 0.0388 - val_pred_std: 0.0390 - binary_accuracy: 0.5005\n",
      "Epoch 57/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1588 - projector_loss: 0.0794 - proj_std: 0.0437 - pred_std: 0.0434 - val_loss: 0.1531 - val_projector_loss: 0.0765 - val_proj_std: 0.0395 - val_pred_std: 0.0391 - binary_accuracy: 0.5100\n",
      "Epoch 58/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1588 - projector_loss: 0.0794 - proj_std: 0.0437 - pred_std: 0.0434 - val_loss: 0.1575 - val_projector_loss: 0.0788 - val_proj_std: 0.0405 - val_pred_std: 0.0405 - binary_accuracy: 0.5295\n",
      "Epoch 59/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1616 - projector_loss: 0.0808 - proj_std: 0.0437 - pred_std: 0.0434 - val_loss: 0.1474 - val_projector_loss: 0.0737 - val_proj_std: 0.0395 - val_pred_std: 0.0395 - binary_accuracy: 0.5040\n",
      "Epoch 60/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1583 - projector_loss: 0.0791 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0395 - val_pred_std: 0.0392 - binary_accuracy: 0.5315\n",
      "Epoch 61/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1567 - projector_loss: 0.0783 - proj_std: 0.0439 - pred_std: 0.0436 - val_loss: 0.1534 - val_projector_loss: 0.0767 - val_proj_std: 0.0382 - val_pred_std: 0.0381 - binary_accuracy: 0.5075\n",
      "Epoch 62/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1570 - projector_loss: 0.0785 - proj_std: 0.0438 - pred_std: 0.0435 - val_loss: 0.1542 - val_projector_loss: 0.0771 - val_proj_std: 0.0405 - val_pred_std: 0.0407 - binary_accuracy: 0.5460\n",
      "Epoch 63/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1553 - projector_loss: 0.0776 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1455 - val_projector_loss: 0.0727 - val_proj_std: 0.0403 - val_pred_std: 0.0406 - binary_accuracy: 0.5545\n",
      "Epoch 64/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1553 - projector_loss: 0.0776 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1517 - val_projector_loss: 0.0758 - val_proj_std: 0.0405 - val_pred_std: 0.0407 - binary_accuracy: 0.5240\n",
      "Epoch 65/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1552 - projector_loss: 0.0776 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1463 - val_projector_loss: 0.0732 - val_proj_std: 0.0399 - val_pred_std: 0.0401 - binary_accuracy: 0.5440\n",
      "Epoch 66/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1542 - projector_loss: 0.0771 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1450 - val_projector_loss: 0.0725 - val_proj_std: 0.0409 - val_pred_std: 0.0410 - binary_accuracy: 0.5660\n",
      "Epoch 67/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1564 - projector_loss: 0.0782 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1369 - val_projector_loss: 0.0684 - val_proj_std: 0.0410 - val_pred_std: 0.0410 - binary_accuracy: 0.5580\n",
      "Epoch 68/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1539 - projector_loss: 0.0770 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1522 - val_projector_loss: 0.0761 - val_proj_std: 0.0418 - val_pred_std: 0.0419 - binary_accuracy: 0.5645\n",
      "Epoch 69/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1537 - projector_loss: 0.0769 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1522 - val_projector_loss: 0.0761 - val_proj_std: 0.0426 - val_pred_std: 0.0429 - binary_accuracy: 0.5640\n",
      "Epoch 70/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1556 - projector_loss: 0.0778 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1492 - val_projector_loss: 0.0746 - val_proj_std: 0.0416 - val_pred_std: 0.0419 - binary_accuracy: 0.5755\n",
      "Epoch 71/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1563 - projector_loss: 0.0781 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1627 - val_projector_loss: 0.0813 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.6160\n",
      "Epoch 72/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1568 - projector_loss: 0.0784 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1618 - val_projector_loss: 0.0809 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.5875\n",
      "Epoch 73/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1591 - projector_loss: 0.0795 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1507 - val_projector_loss: 0.0754 - val_proj_std: 0.0423 - val_pred_std: 0.0421 - binary_accuracy: 0.5940\n",
      "Epoch 74/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1564 - projector_loss: 0.0782 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1601 - val_projector_loss: 0.0801 - val_proj_std: 0.0424 - val_pred_std: 0.0425 - binary_accuracy: 0.5785\n",
      "Epoch 75/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1543 - projector_loss: 0.0772 - proj_std: 0.0441 - pred_std: 0.0438 - val_loss: 0.1703 - val_projector_loss: 0.0851 - val_proj_std: 0.0423 - val_pred_std: 0.0423 - binary_accuracy: 0.5635\n",
      "Epoch 76/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1560 - projector_loss: 0.0780 - proj_std: 0.0441 - pred_std: 0.0439 - val_loss: 0.1446 - val_projector_loss: 0.0723 - val_proj_std: 0.0410 - val_pred_std: 0.0410 - binary_accuracy: 0.5850\n",
      "Epoch 77/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1546 - projector_loss: 0.0773 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1647 - val_projector_loss: 0.0824 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.5620\n",
      "Epoch 78/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1545 - projector_loss: 0.0772 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1550 - val_projector_loss: 0.0775 - val_proj_std: 0.0418 - val_pred_std: 0.0420 - binary_accuracy: 0.5855\n",
      "Epoch 79/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1580 - projector_loss: 0.0790 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1619 - val_projector_loss: 0.0810 - val_proj_std: 0.0424 - val_pred_std: 0.0427 - binary_accuracy: 0.5855\n",
      "Epoch 80/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1583 - projector_loss: 0.0791 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1621 - val_projector_loss: 0.0810 - val_proj_std: 0.0409 - val_pred_std: 0.0405 - binary_accuracy: 0.5565\n",
      "Epoch 81/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1567 - projector_loss: 0.0783 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1491 - val_projector_loss: 0.0746 - val_proj_std: 0.0419 - val_pred_std: 0.0418 - binary_accuracy: 0.5890\n",
      "Epoch 82/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1513 - projector_loss: 0.0756 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1366 - val_projector_loss: 0.0683 - val_proj_std: 0.0410 - val_pred_std: 0.0411 - binary_accuracy: 0.5810\n",
      "Epoch 83/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1562 - projector_loss: 0.0781 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1568 - val_projector_loss: 0.0784 - val_proj_std: 0.0414 - val_pred_std: 0.0416 - binary_accuracy: 0.5965\n",
      "Epoch 84/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1545 - projector_loss: 0.0772 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1613 - val_projector_loss: 0.0807 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.6140\n",
      "Epoch 85/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1561 - projector_loss: 0.0780 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1561 - val_projector_loss: 0.0781 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6150\n",
      "Epoch 86/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1511 - projector_loss: 0.0755 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1600 - val_projector_loss: 0.0800 - val_proj_std: 0.0416 - val_pred_std: 0.0415 - binary_accuracy: 0.5975\n",
      "Epoch 87/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1530 - projector_loss: 0.0765 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1525 - val_projector_loss: 0.0763 - val_proj_std: 0.0420 - val_pred_std: 0.0418 - binary_accuracy: 0.6045\n",
      "Epoch 88/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1529 - projector_loss: 0.0764 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1649 - val_projector_loss: 0.0825 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.5990\n",
      "Epoch 89/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1525 - projector_loss: 0.0763 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1649 - val_projector_loss: 0.0825 - val_proj_std: 0.0427 - val_pred_std: 0.0428 - binary_accuracy: 0.6170\n",
      "Epoch 90/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1525 - projector_loss: 0.0763 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1581 - val_projector_loss: 0.0790 - val_proj_std: 0.0426 - val_pred_std: 0.0428 - binary_accuracy: 0.6040\n",
      "Epoch 91/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1534 - projector_loss: 0.0767 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1625 - val_projector_loss: 0.0813 - val_proj_std: 0.0413 - val_pred_std: 0.0410 - binary_accuracy: 0.6025\n",
      "Epoch 92/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1546 - projector_loss: 0.0773 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1558 - val_projector_loss: 0.0779 - val_proj_std: 0.0418 - val_pred_std: 0.0421 - binary_accuracy: 0.6100\n",
      "Epoch 93/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1557 - projector_loss: 0.0779 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1523 - val_projector_loss: 0.0762 - val_proj_std: 0.0422 - val_pred_std: 0.0423 - binary_accuracy: 0.6240\n",
      "Epoch 94/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1550 - projector_loss: 0.0775 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1587 - val_projector_loss: 0.0794 - val_proj_std: 0.0421 - val_pred_std: 0.0423 - binary_accuracy: 0.5975\n",
      "Epoch 95/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1517 - projector_loss: 0.0758 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1645 - val_projector_loss: 0.0823 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.6175\n",
      "Epoch 96/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1533 - projector_loss: 0.0766 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1688 - val_projector_loss: 0.0844 - val_proj_std: 0.0424 - val_pred_std: 0.0426 - binary_accuracy: 0.6115\n",
      "Epoch 97/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1500 - projector_loss: 0.0750 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1603 - val_projector_loss: 0.0801 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6205\n",
      "Epoch 98/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1522 - projector_loss: 0.0761 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1519 - val_projector_loss: 0.0760 - val_proj_std: 0.0417 - val_pred_std: 0.0420 - binary_accuracy: 0.6015\n",
      "Epoch 99/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1542 - projector_loss: 0.0771 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1595 - val_projector_loss: 0.0797 - val_proj_std: 0.0425 - val_pred_std: 0.0425 - binary_accuracy: 0.6435\n",
      "Epoch 100/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1518 - projector_loss: 0.0759 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1597 - val_projector_loss: 0.0798 - val_proj_std: 0.0430 - val_pred_std: 0.0431 - binary_accuracy: 0.6260\n",
      "Epoch 101/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1523 - projector_loss: 0.0762 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1718 - val_projector_loss: 0.0859 - val_proj_std: 0.0419 - val_pred_std: 0.0415 - binary_accuracy: 0.6185\n",
      "Epoch 102/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1521 - projector_loss: 0.0761 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1394 - val_projector_loss: 0.0697 - val_proj_std: 0.0420 - val_pred_std: 0.0418 - binary_accuracy: 0.6220\n",
      "Epoch 103/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1513 - projector_loss: 0.0757 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1554 - val_projector_loss: 0.0777 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.6230\n",
      "Epoch 104/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1496 - projector_loss: 0.0748 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1536 - val_projector_loss: 0.0768 - val_proj_std: 0.0426 - val_pred_std: 0.0424 - binary_accuracy: 0.6210\n",
      "Epoch 105/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1534 - projector_loss: 0.0767 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1591 - val_projector_loss: 0.0796 - val_proj_std: 0.0424 - val_pred_std: 0.0423 - binary_accuracy: 0.6315\n",
      "Epoch 106/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1512 - projector_loss: 0.0756 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1584 - val_projector_loss: 0.0792 - val_proj_std: 0.0421 - val_pred_std: 0.0423 - binary_accuracy: 0.6130\n",
      "Epoch 107/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1478 - projector_loss: 0.0739 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1530 - val_projector_loss: 0.0765 - val_proj_std: 0.0421 - val_pred_std: 0.0423 - binary_accuracy: 0.6390\n",
      "Epoch 108/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1482 - projector_loss: 0.0741 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1563 - val_projector_loss: 0.0782 - val_proj_std: 0.0421 - val_pred_std: 0.0423 - binary_accuracy: 0.6440\n",
      "Epoch 109/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1506 - projector_loss: 0.0753 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1581 - val_projector_loss: 0.0791 - val_proj_std: 0.0425 - val_pred_std: 0.0428 - binary_accuracy: 0.6345\n",
      "Epoch 110/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1515 - projector_loss: 0.0758 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1554 - val_projector_loss: 0.0777 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6340\n",
      "Epoch 111/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1499 - projector_loss: 0.0749 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1618 - val_projector_loss: 0.0809 - val_proj_std: 0.0424 - val_pred_std: 0.0425 - binary_accuracy: 0.6130\n",
      "Epoch 112/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1498 - projector_loss: 0.0749 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1533 - val_projector_loss: 0.0767 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.6055\n",
      "Epoch 113/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1516 - projector_loss: 0.0758 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1522 - val_projector_loss: 0.0761 - val_proj_std: 0.0422 - val_pred_std: 0.0423 - binary_accuracy: 0.6355\n",
      "Epoch 114/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1506 - projector_loss: 0.0753 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1487 - val_projector_loss: 0.0743 - val_proj_std: 0.0415 - val_pred_std: 0.0415 - binary_accuracy: 0.6190\n",
      "Epoch 115/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1512 - projector_loss: 0.0756 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1716 - val_projector_loss: 0.0858 - val_proj_std: 0.0429 - val_pred_std: 0.0430 - binary_accuracy: 0.6500\n",
      "Epoch 116/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1514 - projector_loss: 0.0757 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1589 - val_projector_loss: 0.0794 - val_proj_std: 0.0417 - val_pred_std: 0.0417 - binary_accuracy: 0.6100\n",
      "Epoch 117/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1504 - projector_loss: 0.0752 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1658 - val_projector_loss: 0.0829 - val_proj_std: 0.0423 - val_pred_std: 0.0420 - binary_accuracy: 0.6540\n",
      "Epoch 118/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1526 - projector_loss: 0.0763 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1567 - val_projector_loss: 0.0784 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.6415\n",
      "Epoch 119/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1480 - projector_loss: 0.0740 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1609 - val_projector_loss: 0.0804 - val_proj_std: 0.0421 - val_pred_std: 0.0424 - binary_accuracy: 0.6255\n",
      "Epoch 120/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1510 - projector_loss: 0.0755 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1590 - val_projector_loss: 0.0795 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.6545\n",
      "Epoch 121/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1494 - projector_loss: 0.0747 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1537 - val_projector_loss: 0.0769 - val_proj_std: 0.0421 - val_pred_std: 0.0423 - binary_accuracy: 0.6365\n",
      "Epoch 122/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1484 - projector_loss: 0.0742 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1610 - val_projector_loss: 0.0805 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.6340\n",
      "Epoch 123/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1483 - projector_loss: 0.0742 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1566 - val_projector_loss: 0.0783 - val_proj_std: 0.0420 - val_pred_std: 0.0422 - binary_accuracy: 0.6405\n",
      "Epoch 124/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1483 - projector_loss: 0.0741 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1575 - val_projector_loss: 0.0787 - val_proj_std: 0.0420 - val_pred_std: 0.0418 - binary_accuracy: 0.6645\n",
      "Epoch 125/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1489 - projector_loss: 0.0744 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1469 - val_projector_loss: 0.0734 - val_proj_std: 0.0414 - val_pred_std: 0.0412 - binary_accuracy: 0.6390\n",
      "Epoch 126/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1476 - projector_loss: 0.0738 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1527 - val_projector_loss: 0.0763 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.6580\n",
      "Epoch 127/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1488 - projector_loss: 0.0744 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1512 - val_projector_loss: 0.0756 - val_proj_std: 0.0429 - val_pred_std: 0.0431 - binary_accuracy: 0.6480\n",
      "Epoch 128/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1464 - projector_loss: 0.0732 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1671 - val_projector_loss: 0.0835 - val_proj_std: 0.0417 - val_pred_std: 0.0417 - binary_accuracy: 0.6455\n",
      "Epoch 129/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1512 - projector_loss: 0.0756 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1553 - val_projector_loss: 0.0776 - val_proj_std: 0.0424 - val_pred_std: 0.0422 - binary_accuracy: 0.6755\n",
      "Epoch 130/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1467 - projector_loss: 0.0734 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1610 - val_projector_loss: 0.0805 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6525\n",
      "Epoch 131/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1500 - projector_loss: 0.0750 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1587 - val_projector_loss: 0.0793 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6515\n",
      "Epoch 132/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1478 - projector_loss: 0.0739 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1589 - val_projector_loss: 0.0794 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.6680\n",
      "Epoch 133/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1472 - projector_loss: 0.0736 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1563 - val_projector_loss: 0.0781 - val_proj_std: 0.0422 - val_pred_std: 0.0423 - binary_accuracy: 0.6405\n",
      "Epoch 134/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1487 - projector_loss: 0.0744 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1574 - val_projector_loss: 0.0787 - val_proj_std: 0.0424 - val_pred_std: 0.0423 - binary_accuracy: 0.6675\n",
      "Epoch 135/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1488 - projector_loss: 0.0744 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1580 - val_projector_loss: 0.0790 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.6780\n",
      "Epoch 136/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1489 - projector_loss: 0.0745 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1604 - val_projector_loss: 0.0802 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6475\n",
      "Epoch 137/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1479 - projector_loss: 0.0739 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1491 - val_projector_loss: 0.0746 - val_proj_std: 0.0418 - val_pred_std: 0.0419 - binary_accuracy: 0.6555\n",
      "Epoch 138/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1472 - projector_loss: 0.0736 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1591 - val_projector_loss: 0.0795 - val_proj_std: 0.0425 - val_pred_std: 0.0427 - binary_accuracy: 0.6655\n",
      "Epoch 139/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1448 - projector_loss: 0.0724 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1558 - val_projector_loss: 0.0779 - val_proj_std: 0.0420 - val_pred_std: 0.0424 - binary_accuracy: 0.6625\n",
      "Epoch 140/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1456 - projector_loss: 0.0728 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1530 - val_projector_loss: 0.0765 - val_proj_std: 0.0424 - val_pred_std: 0.0425 - binary_accuracy: 0.6670\n",
      "Epoch 141/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1469 - projector_loss: 0.0734 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1639 - val_projector_loss: 0.0819 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.6795\n",
      "Epoch 142/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1482 - projector_loss: 0.0741 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1573 - val_projector_loss: 0.0786 - val_proj_std: 0.0423 - val_pred_std: 0.0422 - binary_accuracy: 0.6535\n",
      "Epoch 143/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1470 - projector_loss: 0.0735 - proj_std: 0.0440 - pred_std: 0.0437 - val_loss: 0.1722 - val_projector_loss: 0.0861 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.6570\n",
      "Epoch 144/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1450 - projector_loss: 0.0725 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1698 - val_projector_loss: 0.0849 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.6645\n",
      "Epoch 145/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1467 - projector_loss: 0.0734 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1535 - val_projector_loss: 0.0768 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6530\n",
      "Epoch 146/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1460 - projector_loss: 0.0730 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1548 - val_projector_loss: 0.0774 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6570\n",
      "Epoch 147/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1474 - projector_loss: 0.0737 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1684 - val_projector_loss: 0.0842 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6610\n",
      "Epoch 148/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1461 - projector_loss: 0.0730 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1591 - val_projector_loss: 0.0796 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.6655\n",
      "Epoch 149/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1444 - projector_loss: 0.0722 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1498 - val_projector_loss: 0.0749 - val_proj_std: 0.0421 - val_pred_std: 0.0419 - binary_accuracy: 0.6440\n",
      "Epoch 150/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1471 - projector_loss: 0.0736 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1636 - val_projector_loss: 0.0818 - val_proj_std: 0.0417 - val_pred_std: 0.0417 - binary_accuracy: 0.6355\n",
      "Epoch 151/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1466 - projector_loss: 0.0733 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1577 - val_projector_loss: 0.0789 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.6770\n",
      "Epoch 152/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1461 - projector_loss: 0.0731 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1585 - val_projector_loss: 0.0793 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6560\n",
      "Epoch 153/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1450 - projector_loss: 0.0725 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1567 - val_projector_loss: 0.0784 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6630\n",
      "Epoch 154/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1457 - projector_loss: 0.0728 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1644 - val_projector_loss: 0.0822 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6740\n",
      "Epoch 155/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1450 - projector_loss: 0.0725 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1575 - val_projector_loss: 0.0787 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.6770\n",
      "Epoch 156/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1444 - projector_loss: 0.0722 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1600 - val_projector_loss: 0.0800 - val_proj_std: 0.0423 - val_pred_std: 0.0424 - binary_accuracy: 0.6760\n",
      "Epoch 157/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1427 - projector_loss: 0.0713 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1529 - val_projector_loss: 0.0764 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.6790\n",
      "Epoch 158/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1440 - projector_loss: 0.0720 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1514 - val_projector_loss: 0.0757 - val_proj_std: 0.0416 - val_pred_std: 0.0414 - binary_accuracy: 0.6875\n",
      "Epoch 159/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1406 - projector_loss: 0.0703 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1435 - val_projector_loss: 0.0717 - val_proj_std: 0.0412 - val_pred_std: 0.0412 - binary_accuracy: 0.6730\n",
      "Epoch 160/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1436 - projector_loss: 0.0718 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1646 - val_projector_loss: 0.0823 - val_proj_std: 0.0423 - val_pred_std: 0.0422 - binary_accuracy: 0.7040\n",
      "Epoch 161/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1444 - projector_loss: 0.0722 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1613 - val_projector_loss: 0.0806 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.6810\n",
      "Epoch 162/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1420 - projector_loss: 0.0710 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1525 - val_projector_loss: 0.0763 - val_proj_std: 0.0424 - val_pred_std: 0.0423 - binary_accuracy: 0.6655\n",
      "Epoch 163/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1454 - projector_loss: 0.0727 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1550 - val_projector_loss: 0.0775 - val_proj_std: 0.0423 - val_pred_std: 0.0423 - binary_accuracy: 0.6640\n",
      "Epoch 164/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1446 - projector_loss: 0.0723 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1583 - val_projector_loss: 0.0792 - val_proj_std: 0.0425 - val_pred_std: 0.0425 - binary_accuracy: 0.6920\n",
      "Epoch 165/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1436 - projector_loss: 0.0718 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1554 - val_projector_loss: 0.0777 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.6915\n",
      "Epoch 166/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1431 - projector_loss: 0.0715 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1539 - val_projector_loss: 0.0770 - val_proj_std: 0.0416 - val_pred_std: 0.0418 - binary_accuracy: 0.6785\n",
      "Epoch 167/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1419 - projector_loss: 0.0710 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1565 - val_projector_loss: 0.0783 - val_proj_std: 0.0422 - val_pred_std: 0.0424 - binary_accuracy: 0.6965\n",
      "Epoch 168/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1461 - projector_loss: 0.0731 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1604 - val_projector_loss: 0.0802 - val_proj_std: 0.0414 - val_pred_std: 0.0415 - binary_accuracy: 0.6790\n",
      "Epoch 169/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1427 - projector_loss: 0.0713 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1516 - val_projector_loss: 0.0758 - val_proj_std: 0.0429 - val_pred_std: 0.0431 - binary_accuracy: 0.6910\n",
      "Epoch 170/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1426 - projector_loss: 0.0713 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1538 - val_projector_loss: 0.0769 - val_proj_std: 0.0418 - val_pred_std: 0.0420 - binary_accuracy: 0.6710\n",
      "Epoch 171/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1417 - projector_loss: 0.0709 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1605 - val_projector_loss: 0.0803 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.6950\n",
      "Epoch 172/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1448 - projector_loss: 0.0724 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1449 - val_projector_loss: 0.0725 - val_proj_std: 0.0419 - val_pred_std: 0.0416 - binary_accuracy: 0.6720\n",
      "Epoch 173/800\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 0.1429 - projector_loss: 0.0714 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1574 - val_projector_loss: 0.0787 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.6775\n",
      "Epoch 174/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1447 - projector_loss: 0.0723 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1559 - val_projector_loss: 0.0779 - val_proj_std: 0.0423 - val_pred_std: 0.0423 - binary_accuracy: 0.6915\n",
      "Epoch 175/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1430 - projector_loss: 0.0715 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1624 - val_projector_loss: 0.0812 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6785\n",
      "Epoch 176/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1427 - projector_loss: 0.0714 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1646 - val_projector_loss: 0.0823 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.6830\n",
      "Epoch 177/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1439 - projector_loss: 0.0720 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1622 - val_projector_loss: 0.0811 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.6710\n",
      "Epoch 178/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1445 - projector_loss: 0.0722 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1548 - val_projector_loss: 0.0774 - val_proj_std: 0.0424 - val_pred_std: 0.0422 - binary_accuracy: 0.6850\n",
      "Epoch 179/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1411 - projector_loss: 0.0705 - proj_std: 0.0440 - pred_std: 0.0438 - val_loss: 0.1466 - val_projector_loss: 0.0733 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6890\n",
      "Epoch 180/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1427 - projector_loss: 0.0714 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1518 - val_projector_loss: 0.0759 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.6970\n",
      "Epoch 181/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1406 - projector_loss: 0.0703 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1665 - val_projector_loss: 0.0833 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6680\n",
      "Epoch 182/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1435 - projector_loss: 0.0718 - proj_std: 0.0439 - pred_std: 0.0438 - val_loss: 0.1688 - val_projector_loss: 0.0844 - val_proj_std: 0.0429 - val_pred_std: 0.0427 - binary_accuracy: 0.6980\n",
      "Epoch 183/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1435 - projector_loss: 0.0717 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1554 - val_projector_loss: 0.0777 - val_proj_std: 0.0423 - val_pred_std: 0.0421 - binary_accuracy: 0.6755\n",
      "Epoch 184/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1396 - projector_loss: 0.0698 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1600 - val_projector_loss: 0.0800 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.7090\n",
      "Epoch 185/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1412 - projector_loss: 0.0706 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1645 - val_projector_loss: 0.0822 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.6975\n",
      "Epoch 186/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1417 - projector_loss: 0.0709 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1660 - val_projector_loss: 0.0830 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6765\n",
      "Epoch 187/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1408 - projector_loss: 0.0704 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1563 - val_projector_loss: 0.0781 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6960\n",
      "Epoch 188/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1406 - projector_loss: 0.0703 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1613 - val_projector_loss: 0.0807 - val_proj_std: 0.0427 - val_pred_std: 0.0428 - binary_accuracy: 0.6955\n",
      "Epoch 189/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1412 - projector_loss: 0.0706 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1644 - val_projector_loss: 0.0822 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.6930\n",
      "Epoch 190/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1420 - projector_loss: 0.0710 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1546 - val_projector_loss: 0.0773 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6975\n",
      "Epoch 191/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1414 - projector_loss: 0.0707 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1548 - val_projector_loss: 0.0774 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.6665\n",
      "Epoch 192/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1413 - projector_loss: 0.0706 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1411 - val_projector_loss: 0.0706 - val_proj_std: 0.0415 - val_pred_std: 0.0416 - binary_accuracy: 0.6875\n",
      "Epoch 193/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1400 - projector_loss: 0.0700 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1546 - val_projector_loss: 0.0773 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.7240\n",
      "Epoch 194/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1407 - projector_loss: 0.0704 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1565 - val_projector_loss: 0.0782 - val_proj_std: 0.0421 - val_pred_std: 0.0421 - binary_accuracy: 0.6720\n",
      "Epoch 195/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1423 - projector_loss: 0.0711 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1510 - val_projector_loss: 0.0755 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7185\n",
      "Epoch 196/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1408 - projector_loss: 0.0704 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1536 - val_projector_loss: 0.0768 - val_proj_std: 0.0419 - val_pred_std: 0.0419 - binary_accuracy: 0.7135\n",
      "Epoch 197/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1408 - projector_loss: 0.0704 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1519 - val_projector_loss: 0.0759 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7105\n",
      "Epoch 198/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1420 - projector_loss: 0.0710 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1678 - val_projector_loss: 0.0839 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7180\n",
      "Epoch 199/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1421 - projector_loss: 0.0711 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1511 - val_projector_loss: 0.0756 - val_proj_std: 0.0424 - val_pred_std: 0.0425 - binary_accuracy: 0.6945\n",
      "Epoch 200/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1395 - projector_loss: 0.0697 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1535 - val_projector_loss: 0.0768 - val_proj_std: 0.0425 - val_pred_std: 0.0425 - binary_accuracy: 0.6925\n",
      "Epoch 201/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1401 - projector_loss: 0.0700 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1514 - val_projector_loss: 0.0757 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.7085\n",
      "Epoch 202/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1408 - projector_loss: 0.0704 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1501 - val_projector_loss: 0.0750 - val_proj_std: 0.0420 - val_pred_std: 0.0424 - binary_accuracy: 0.6925\n",
      "Epoch 203/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1423 - projector_loss: 0.0711 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1710 - val_projector_loss: 0.0855 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6985\n",
      "Epoch 204/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1421 - projector_loss: 0.0710 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1535 - val_projector_loss: 0.0767 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.6890\n",
      "Epoch 205/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1415 - projector_loss: 0.0708 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1541 - val_projector_loss: 0.0771 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7000\n",
      "Epoch 206/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1400 - projector_loss: 0.0700 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1534 - val_projector_loss: 0.0767 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.6920\n",
      "Epoch 207/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1380 - projector_loss: 0.0690 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1466 - val_projector_loss: 0.0733 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.6925\n",
      "Epoch 208/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1406 - projector_loss: 0.0703 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1546 - val_projector_loss: 0.0773 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7090\n",
      "Epoch 209/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1405 - projector_loss: 0.0702 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1550 - val_projector_loss: 0.0775 - val_proj_std: 0.0425 - val_pred_std: 0.0425 - binary_accuracy: 0.6890\n",
      "Epoch 210/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1391 - projector_loss: 0.0695 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1593 - val_projector_loss: 0.0797 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.6930\n",
      "Epoch 211/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1392 - projector_loss: 0.0696 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1672 - val_projector_loss: 0.0836 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.6900\n",
      "Epoch 212/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1400 - projector_loss: 0.0700 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1550 - val_projector_loss: 0.0775 - val_proj_std: 0.0424 - val_pred_std: 0.0425 - binary_accuracy: 0.7005\n",
      "Epoch 213/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1374 - projector_loss: 0.0687 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1504 - val_projector_loss: 0.0752 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6900\n",
      "Epoch 214/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1392 - projector_loss: 0.0696 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1575 - val_projector_loss: 0.0787 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7140\n",
      "Epoch 215/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1396 - projector_loss: 0.0698 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1519 - val_projector_loss: 0.0760 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6940\n",
      "Epoch 216/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1411 - projector_loss: 0.0706 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1511 - val_projector_loss: 0.0755 - val_proj_std: 0.0418 - val_pred_std: 0.0418 - binary_accuracy: 0.6880\n",
      "Epoch 217/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1384 - projector_loss: 0.0692 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1605 - val_projector_loss: 0.0803 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.6750\n",
      "Epoch 218/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1385 - projector_loss: 0.0693 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1557 - val_projector_loss: 0.0778 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7030\n",
      "Epoch 219/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1389 - projector_loss: 0.0694 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1491 - val_projector_loss: 0.0745 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.6965\n",
      "Epoch 220/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1396 - projector_loss: 0.0698 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1493 - val_projector_loss: 0.0746 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7065\n",
      "Epoch 221/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1401 - projector_loss: 0.0701 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1500 - val_projector_loss: 0.0750 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7215\n",
      "Epoch 222/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1411 - projector_loss: 0.0705 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1544 - val_projector_loss: 0.0772 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7080\n",
      "Epoch 223/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1388 - projector_loss: 0.0694 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1553 - val_projector_loss: 0.0776 - val_proj_std: 0.0421 - val_pred_std: 0.0420 - binary_accuracy: 0.6775\n",
      "Epoch 224/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1383 - projector_loss: 0.0691 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1469 - val_projector_loss: 0.0735 - val_proj_std: 0.0420 - val_pred_std: 0.0421 - binary_accuracy: 0.6985\n",
      "Epoch 225/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1392 - projector_loss: 0.0696 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1521 - val_projector_loss: 0.0761 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.6825\n",
      "Epoch 226/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1407 - projector_loss: 0.0704 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1589 - val_projector_loss: 0.0795 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7210\n",
      "Epoch 227/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1401 - projector_loss: 0.0701 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1764 - val_projector_loss: 0.0882 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7055\n",
      "Epoch 228/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1389 - projector_loss: 0.0695 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1558 - val_projector_loss: 0.0779 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7195\n",
      "Epoch 229/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1400 - projector_loss: 0.0700 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1790 - val_projector_loss: 0.0895 - val_proj_std: 0.0421 - val_pred_std: 0.0420 - binary_accuracy: 0.7055\n",
      "Epoch 230/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1399 - projector_loss: 0.0699 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1618 - val_projector_loss: 0.0809 - val_proj_std: 0.0425 - val_pred_std: 0.0425 - binary_accuracy: 0.7165\n",
      "Epoch 231/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1401 - projector_loss: 0.0700 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1530 - val_projector_loss: 0.0765 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7095\n",
      "Epoch 232/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1379 - projector_loss: 0.0690 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1436 - val_projector_loss: 0.0718 - val_proj_std: 0.0424 - val_pred_std: 0.0426 - binary_accuracy: 0.7030\n",
      "Epoch 233/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1381 - projector_loss: 0.0691 - proj_std: 0.0439 - pred_std: 0.0437 - val_loss: 0.1560 - val_projector_loss: 0.0780 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7090\n",
      "Epoch 234/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1346 - projector_loss: 0.0673 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1524 - val_projector_loss: 0.0762 - val_proj_std: 0.0423 - val_pred_std: 0.0424 - binary_accuracy: 0.7095\n",
      "Epoch 235/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1364 - projector_loss: 0.0682 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1541 - val_projector_loss: 0.0770 - val_proj_std: 0.0417 - val_pred_std: 0.0418 - binary_accuracy: 0.6860\n",
      "Epoch 236/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1388 - projector_loss: 0.0694 - proj_std: 0.0438 - pred_std: 0.0437 - val_loss: 0.1528 - val_projector_loss: 0.0764 - val_proj_std: 0.0420 - val_pred_std: 0.0419 - binary_accuracy: 0.7080\n",
      "Epoch 237/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1385 - projector_loss: 0.0692 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1440 - val_projector_loss: 0.0720 - val_proj_std: 0.0416 - val_pred_std: 0.0418 - binary_accuracy: 0.7020\n",
      "Epoch 238/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1390 - projector_loss: 0.0695 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1467 - val_projector_loss: 0.0734 - val_proj_std: 0.0416 - val_pred_std: 0.0417 - binary_accuracy: 0.6720\n",
      "Epoch 239/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1396 - projector_loss: 0.0698 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1621 - val_projector_loss: 0.0811 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7030\n",
      "Epoch 240/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1387 - projector_loss: 0.0693 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1601 - val_projector_loss: 0.0800 - val_proj_std: 0.0425 - val_pred_std: 0.0423 - binary_accuracy: 0.6790\n",
      "Epoch 241/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1353 - projector_loss: 0.0677 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1528 - val_projector_loss: 0.0764 - val_proj_std: 0.0411 - val_pred_std: 0.0413 - binary_accuracy: 0.6875\n",
      "Epoch 242/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1376 - projector_loss: 0.0688 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1568 - val_projector_loss: 0.0784 - val_proj_std: 0.0423 - val_pred_std: 0.0422 - binary_accuracy: 0.6805\n",
      "Epoch 243/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1378 - projector_loss: 0.0689 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1573 - val_projector_loss: 0.0786 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.6980\n",
      "Epoch 244/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1379 - projector_loss: 0.0690 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1476 - val_projector_loss: 0.0738 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7155\n",
      "Epoch 245/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1352 - projector_loss: 0.0676 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1577 - val_projector_loss: 0.0789 - val_proj_std: 0.0421 - val_pred_std: 0.0417 - binary_accuracy: 0.6730\n",
      "Epoch 246/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1370 - projector_loss: 0.0685 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1523 - val_projector_loss: 0.0761 - val_proj_std: 0.0423 - val_pred_std: 0.0422 - binary_accuracy: 0.6855\n",
      "Epoch 247/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1381 - projector_loss: 0.0690 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1546 - val_projector_loss: 0.0773 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.7100\n",
      "Epoch 248/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1367 - projector_loss: 0.0684 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1639 - val_projector_loss: 0.0819 - val_proj_std: 0.0418 - val_pred_std: 0.0414 - binary_accuracy: 0.7015\n",
      "Epoch 249/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1375 - projector_loss: 0.0687 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1554 - val_projector_loss: 0.0777 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.6905\n",
      "Epoch 250/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1392 - projector_loss: 0.0696 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1635 - val_projector_loss: 0.0817 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.6975\n",
      "Epoch 251/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1336 - projector_loss: 0.0668 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1468 - val_projector_loss: 0.0734 - val_proj_std: 0.0424 - val_pred_std: 0.0421 - binary_accuracy: 0.7065\n",
      "Epoch 252/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1351 - projector_loss: 0.0676 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1525 - val_projector_loss: 0.0762 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7150\n",
      "Epoch 253/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1358 - projector_loss: 0.0679 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1503 - val_projector_loss: 0.0751 - val_proj_std: 0.0424 - val_pred_std: 0.0422 - binary_accuracy: 0.7285\n",
      "Epoch 254/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1354 - projector_loss: 0.0677 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1505 - val_projector_loss: 0.0753 - val_proj_std: 0.0410 - val_pred_std: 0.0409 - binary_accuracy: 0.6850\n",
      "Epoch 255/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1330 - projector_loss: 0.0665 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1361 - val_projector_loss: 0.0680 - val_proj_std: 0.0417 - val_pred_std: 0.0417 - binary_accuracy: 0.7115\n",
      "Epoch 256/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1376 - projector_loss: 0.0688 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1585 - val_projector_loss: 0.0793 - val_proj_std: 0.0423 - val_pred_std: 0.0424 - binary_accuracy: 0.7245\n",
      "Epoch 257/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1376 - projector_loss: 0.0688 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1609 - val_projector_loss: 0.0804 - val_proj_std: 0.0422 - val_pred_std: 0.0422 - binary_accuracy: 0.7020\n",
      "Epoch 258/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1363 - projector_loss: 0.0682 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1534 - val_projector_loss: 0.0767 - val_proj_std: 0.0420 - val_pred_std: 0.0418 - binary_accuracy: 0.7200\n",
      "Epoch 259/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1358 - projector_loss: 0.0679 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1636 - val_projector_loss: 0.0818 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7195\n",
      "Epoch 260/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1355 - projector_loss: 0.0678 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1476 - val_projector_loss: 0.0738 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7350\n",
      "Epoch 261/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1368 - projector_loss: 0.0684 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1475 - val_projector_loss: 0.0738 - val_proj_std: 0.0421 - val_pred_std: 0.0420 - binary_accuracy: 0.7140\n",
      "Epoch 262/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1345 - projector_loss: 0.0673 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1571 - val_projector_loss: 0.0786 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.6890\n",
      "Epoch 263/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1344 - projector_loss: 0.0672 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1525 - val_projector_loss: 0.0763 - val_proj_std: 0.0426 - val_pred_std: 0.0424 - binary_accuracy: 0.7205\n",
      "Epoch 264/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1324 - projector_loss: 0.0662 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1607 - val_projector_loss: 0.0803 - val_proj_std: 0.0422 - val_pred_std: 0.0422 - binary_accuracy: 0.6875\n",
      "Epoch 265/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1342 - projector_loss: 0.0671 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1469 - val_projector_loss: 0.0735 - val_proj_std: 0.0416 - val_pred_std: 0.0418 - binary_accuracy: 0.7310\n",
      "Epoch 266/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1365 - projector_loss: 0.0683 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1531 - val_projector_loss: 0.0765 - val_proj_std: 0.0426 - val_pred_std: 0.0427 - binary_accuracy: 0.6895\n",
      "Epoch 267/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1361 - projector_loss: 0.0681 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1546 - val_projector_loss: 0.0773 - val_proj_std: 0.0426 - val_pred_std: 0.0424 - binary_accuracy: 0.7120\n",
      "Epoch 268/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1363 - projector_loss: 0.0682 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1529 - val_projector_loss: 0.0764 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7270\n",
      "Epoch 269/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1350 - projector_loss: 0.0675 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1652 - val_projector_loss: 0.0826 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7040\n",
      "Epoch 270/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1352 - projector_loss: 0.0676 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1416 - val_projector_loss: 0.0708 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7340\n",
      "Epoch 271/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1362 - projector_loss: 0.0681 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1523 - val_projector_loss: 0.0762 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7260\n",
      "Epoch 272/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1351 - projector_loss: 0.0675 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1556 - val_projector_loss: 0.0778 - val_proj_std: 0.0425 - val_pred_std: 0.0425 - binary_accuracy: 0.7045\n",
      "Epoch 273/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1341 - projector_loss: 0.0671 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1521 - val_projector_loss: 0.0761 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.7170\n",
      "Epoch 274/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1347 - projector_loss: 0.0674 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1583 - val_projector_loss: 0.0792 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7015\n",
      "Epoch 275/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1363 - projector_loss: 0.0682 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1411 - val_projector_loss: 0.0705 - val_proj_std: 0.0405 - val_pred_std: 0.0408 - binary_accuracy: 0.6965\n",
      "Epoch 276/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1366 - projector_loss: 0.0683 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1525 - val_projector_loss: 0.0763 - val_proj_std: 0.0419 - val_pred_std: 0.0419 - binary_accuracy: 0.7095\n",
      "Epoch 277/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1347 - projector_loss: 0.0673 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1618 - val_projector_loss: 0.0809 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.7045\n",
      "Epoch 278/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1350 - projector_loss: 0.0675 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1468 - val_projector_loss: 0.0734 - val_proj_std: 0.0414 - val_pred_std: 0.0417 - binary_accuracy: 0.6980\n",
      "Epoch 279/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1357 - projector_loss: 0.0679 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1532 - val_projector_loss: 0.0766 - val_proj_std: 0.0427 - val_pred_std: 0.0428 - binary_accuracy: 0.7260\n",
      "Epoch 280/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1348 - projector_loss: 0.0674 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1424 - val_projector_loss: 0.0712 - val_proj_std: 0.0417 - val_pred_std: 0.0416 - binary_accuracy: 0.6865\n",
      "Epoch 281/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1340 - projector_loss: 0.0670 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1434 - val_projector_loss: 0.0717 - val_proj_std: 0.0413 - val_pred_std: 0.0409 - binary_accuracy: 0.7275\n",
      "Epoch 282/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1349 - projector_loss: 0.0674 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1492 - val_projector_loss: 0.0746 - val_proj_std: 0.0421 - val_pred_std: 0.0421 - binary_accuracy: 0.7080\n",
      "Epoch 283/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1347 - projector_loss: 0.0673 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1485 - val_projector_loss: 0.0743 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7185\n",
      "Epoch 284/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1358 - projector_loss: 0.0679 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1485 - val_projector_loss: 0.0742 - val_proj_std: 0.0420 - val_pred_std: 0.0418 - binary_accuracy: 0.7030\n",
      "Epoch 285/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1367 - projector_loss: 0.0683 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1540 - val_projector_loss: 0.0770 - val_proj_std: 0.0413 - val_pred_std: 0.0415 - binary_accuracy: 0.6990\n",
      "Epoch 286/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1334 - projector_loss: 0.0667 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1477 - val_projector_loss: 0.0739 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7240\n",
      "Epoch 287/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1351 - projector_loss: 0.0676 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1504 - val_projector_loss: 0.0752 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7205\n",
      "Epoch 288/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1335 - projector_loss: 0.0668 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1604 - val_projector_loss: 0.0802 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7265\n",
      "Epoch 289/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1368 - projector_loss: 0.0684 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1564 - val_projector_loss: 0.0782 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7320\n",
      "Epoch 290/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1342 - projector_loss: 0.0671 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1601 - val_projector_loss: 0.0800 - val_proj_std: 0.0430 - val_pred_std: 0.0431 - binary_accuracy: 0.7260\n",
      "Epoch 291/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1340 - projector_loss: 0.0670 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1574 - val_projector_loss: 0.0787 - val_proj_std: 0.0419 - val_pred_std: 0.0419 - binary_accuracy: 0.7185\n",
      "Epoch 292/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1324 - projector_loss: 0.0662 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1616 - val_projector_loss: 0.0808 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.7360\n",
      "Epoch 293/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1340 - projector_loss: 0.0670 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1500 - val_projector_loss: 0.0750 - val_proj_std: 0.0422 - val_pred_std: 0.0423 - binary_accuracy: 0.7440\n",
      "Epoch 294/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1316 - projector_loss: 0.0658 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1524 - val_projector_loss: 0.0762 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7100\n",
      "Epoch 295/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1318 - projector_loss: 0.0659 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1623 - val_projector_loss: 0.0812 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7470\n",
      "Epoch 296/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1349 - projector_loss: 0.0674 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1524 - val_projector_loss: 0.0762 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7445\n",
      "Epoch 297/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1341 - projector_loss: 0.0671 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1461 - val_projector_loss: 0.0731 - val_proj_std: 0.0425 - val_pred_std: 0.0423 - binary_accuracy: 0.7330\n",
      "Epoch 298/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1344 - projector_loss: 0.0672 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1568 - val_projector_loss: 0.0784 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7095\n",
      "Epoch 299/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1328 - projector_loss: 0.0664 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1486 - val_projector_loss: 0.0743 - val_proj_std: 0.0417 - val_pred_std: 0.0416 - binary_accuracy: 0.7125\n",
      "Epoch 300/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1339 - projector_loss: 0.0669 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1576 - val_projector_loss: 0.0788 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7475\n",
      "Epoch 301/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1335 - projector_loss: 0.0667 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1471 - val_projector_loss: 0.0736 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7090\n",
      "Epoch 302/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1323 - projector_loss: 0.0661 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1609 - val_projector_loss: 0.0805 - val_proj_std: 0.0428 - val_pred_std: 0.0429 - binary_accuracy: 0.7170\n",
      "Epoch 303/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1333 - projector_loss: 0.0666 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1523 - val_projector_loss: 0.0762 - val_proj_std: 0.0421 - val_pred_std: 0.0421 - binary_accuracy: 0.7400\n",
      "Epoch 304/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1320 - projector_loss: 0.0660 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1543 - val_projector_loss: 0.0771 - val_proj_std: 0.0414 - val_pred_std: 0.0414 - binary_accuracy: 0.7290\n",
      "Epoch 305/800\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 0.1330 - projector_loss: 0.0665 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1537 - val_projector_loss: 0.0769 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7360\n",
      "Epoch 306/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1356 - projector_loss: 0.0678 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1485 - val_projector_loss: 0.0743 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7405\n",
      "Epoch 307/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1322 - projector_loss: 0.0661 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1511 - val_projector_loss: 0.0755 - val_proj_std: 0.0421 - val_pred_std: 0.0421 - binary_accuracy: 0.7260\n",
      "Epoch 308/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1323 - projector_loss: 0.0662 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1523 - val_projector_loss: 0.0761 - val_proj_std: 0.0421 - val_pred_std: 0.0421 - binary_accuracy: 0.7185\n",
      "Epoch 309/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1303 - projector_loss: 0.0652 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1492 - val_projector_loss: 0.0746 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7390\n",
      "Epoch 310/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1324 - projector_loss: 0.0662 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1478 - val_projector_loss: 0.0739 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.7250\n",
      "Epoch 311/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1301 - projector_loss: 0.0650 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1330 - val_projector_loss: 0.0665 - val_proj_std: 0.0423 - val_pred_std: 0.0423 - binary_accuracy: 0.7210\n",
      "Epoch 312/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1314 - projector_loss: 0.0657 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1507 - val_projector_loss: 0.0754 - val_proj_std: 0.0416 - val_pred_std: 0.0417 - binary_accuracy: 0.7405\n",
      "Epoch 313/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1335 - projector_loss: 0.0667 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1527 - val_projector_loss: 0.0763 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.7050\n",
      "Epoch 314/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1324 - projector_loss: 0.0662 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1429 - val_projector_loss: 0.0715 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7475\n",
      "Epoch 315/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1303 - projector_loss: 0.0652 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1500 - val_projector_loss: 0.0750 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7435\n",
      "Epoch 316/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1327 - projector_loss: 0.0664 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1482 - val_projector_loss: 0.0741 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7290\n",
      "Epoch 317/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1327 - projector_loss: 0.0663 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1543 - val_projector_loss: 0.0772 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7415\n",
      "Epoch 318/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1334 - projector_loss: 0.0667 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1486 - val_projector_loss: 0.0743 - val_proj_std: 0.0413 - val_pred_std: 0.0413 - binary_accuracy: 0.7065\n",
      "Epoch 319/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1323 - projector_loss: 0.0662 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1586 - val_projector_loss: 0.0793 - val_proj_std: 0.0423 - val_pred_std: 0.0423 - binary_accuracy: 0.7450\n",
      "Epoch 320/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1321 - projector_loss: 0.0661 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1468 - val_projector_loss: 0.0734 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7195\n",
      "Epoch 321/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1314 - projector_loss: 0.0657 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1543 - val_projector_loss: 0.0771 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7235\n",
      "Epoch 322/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1299 - projector_loss: 0.0649 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1400 - val_projector_loss: 0.0700 - val_proj_std: 0.0422 - val_pred_std: 0.0421 - binary_accuracy: 0.7445\n",
      "Epoch 323/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1312 - projector_loss: 0.0656 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1463 - val_projector_loss: 0.0732 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.7110\n",
      "Epoch 324/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1297 - projector_loss: 0.0648 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1580 - val_projector_loss: 0.0790 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7355\n",
      "Epoch 325/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1324 - projector_loss: 0.0662 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1506 - val_projector_loss: 0.0753 - val_proj_std: 0.0422 - val_pred_std: 0.0421 - binary_accuracy: 0.7455\n",
      "Epoch 326/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1298 - projector_loss: 0.0649 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1473 - val_projector_loss: 0.0736 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.7530\n",
      "Epoch 327/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1327 - projector_loss: 0.0663 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1548 - val_projector_loss: 0.0774 - val_proj_std: 0.0421 - val_pred_std: 0.0420 - binary_accuracy: 0.7215\n",
      "Epoch 328/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1298 - projector_loss: 0.0649 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1517 - val_projector_loss: 0.0758 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7520\n",
      "Epoch 329/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1308 - projector_loss: 0.0654 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1560 - val_projector_loss: 0.0780 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7175\n",
      "Epoch 330/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1289 - projector_loss: 0.0644 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1513 - val_projector_loss: 0.0757 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7270\n",
      "Epoch 331/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1308 - projector_loss: 0.0654 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1459 - val_projector_loss: 0.0729 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7405\n",
      "Epoch 332/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1315 - projector_loss: 0.0658 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1602 - val_projector_loss: 0.0801 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7675\n",
      "Epoch 333/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1316 - projector_loss: 0.0658 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1512 - val_projector_loss: 0.0756 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7340\n",
      "Epoch 334/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1308 - projector_loss: 0.0654 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1486 - val_projector_loss: 0.0743 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7380\n",
      "Epoch 335/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1330 - projector_loss: 0.0665 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1621 - val_projector_loss: 0.0811 - val_proj_std: 0.0429 - val_pred_std: 0.0427 - binary_accuracy: 0.7425\n",
      "Epoch 336/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1295 - projector_loss: 0.0648 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1550 - val_projector_loss: 0.0775 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7375\n",
      "Epoch 337/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1290 - projector_loss: 0.0645 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1623 - val_projector_loss: 0.0811 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7495\n",
      "Epoch 338/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1304 - projector_loss: 0.0652 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1432 - val_projector_loss: 0.0716 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7345\n",
      "Epoch 339/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1321 - projector_loss: 0.0661 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1583 - val_projector_loss: 0.0791 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7265\n",
      "Epoch 340/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1290 - projector_loss: 0.0645 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1453 - val_projector_loss: 0.0726 - val_proj_std: 0.0420 - val_pred_std: 0.0420 - binary_accuracy: 0.7245\n",
      "Epoch 341/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1312 - projector_loss: 0.0656 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1587 - val_projector_loss: 0.0794 - val_proj_std: 0.0423 - val_pred_std: 0.0423 - binary_accuracy: 0.7355\n",
      "Epoch 342/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1330 - projector_loss: 0.0665 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1458 - val_projector_loss: 0.0729 - val_proj_std: 0.0421 - val_pred_std: 0.0421 - binary_accuracy: 0.7300\n",
      "Epoch 343/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1314 - projector_loss: 0.0657 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1378 - val_projector_loss: 0.0689 - val_proj_std: 0.0408 - val_pred_std: 0.0406 - binary_accuracy: 0.7375\n",
      "Epoch 344/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1301 - projector_loss: 0.0650 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1562 - val_projector_loss: 0.0781 - val_proj_std: 0.0429 - val_pred_std: 0.0427 - binary_accuracy: 0.7260\n",
      "Epoch 345/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1303 - projector_loss: 0.0652 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1623 - val_projector_loss: 0.0811 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7350\n",
      "Epoch 346/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1298 - projector_loss: 0.0649 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1513 - val_projector_loss: 0.0756 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7580\n",
      "Epoch 347/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1298 - projector_loss: 0.0649 - proj_std: 0.0438 - pred_std: 0.0436 - val_loss: 0.1524 - val_projector_loss: 0.0762 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7445\n",
      "Epoch 348/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1296 - projector_loss: 0.0648 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1565 - val_projector_loss: 0.0782 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.7480\n",
      "Epoch 349/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1287 - projector_loss: 0.0644 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1458 - val_projector_loss: 0.0729 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7450\n",
      "Epoch 350/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1286 - projector_loss: 0.0643 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1671 - val_projector_loss: 0.0836 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7430\n",
      "Epoch 351/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1313 - projector_loss: 0.0656 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1590 - val_projector_loss: 0.0795 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7600\n",
      "Epoch 352/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1295 - projector_loss: 0.0648 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1519 - val_projector_loss: 0.0759 - val_proj_std: 0.0424 - val_pred_std: 0.0422 - binary_accuracy: 0.7430\n",
      "Epoch 353/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1286 - projector_loss: 0.0643 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1566 - val_projector_loss: 0.0783 - val_proj_std: 0.0425 - val_pred_std: 0.0423 - binary_accuracy: 0.7575\n",
      "Epoch 354/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1298 - projector_loss: 0.0649 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1483 - val_projector_loss: 0.0742 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7780\n",
      "Epoch 355/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1296 - projector_loss: 0.0648 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1517 - val_projector_loss: 0.0758 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7670\n",
      "Epoch 356/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1285 - projector_loss: 0.0642 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1439 - val_projector_loss: 0.0720 - val_proj_std: 0.0421 - val_pred_std: 0.0420 - binary_accuracy: 0.7380\n",
      "Epoch 357/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1277 - projector_loss: 0.0638 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1503 - val_projector_loss: 0.0751 - val_proj_std: 0.0422 - val_pred_std: 0.0422 - binary_accuracy: 0.7275\n",
      "Epoch 358/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1284 - projector_loss: 0.0642 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1611 - val_projector_loss: 0.0805 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7455\n",
      "Epoch 359/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1297 - projector_loss: 0.0648 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1421 - val_projector_loss: 0.0711 - val_proj_std: 0.0422 - val_pred_std: 0.0421 - binary_accuracy: 0.7365\n",
      "Epoch 360/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1281 - projector_loss: 0.0641 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1536 - val_projector_loss: 0.0768 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7585\n",
      "Epoch 361/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1283 - projector_loss: 0.0641 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1542 - val_projector_loss: 0.0771 - val_proj_std: 0.0425 - val_pred_std: 0.0423 - binary_accuracy: 0.7275\n",
      "Epoch 362/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1291 - projector_loss: 0.0646 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1521 - val_projector_loss: 0.0760 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7720\n",
      "Epoch 363/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1280 - projector_loss: 0.0640 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1648 - val_projector_loss: 0.0824 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7420\n",
      "Epoch 364/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1286 - projector_loss: 0.0643 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1551 - val_projector_loss: 0.0775 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7370\n",
      "Epoch 365/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1287 - projector_loss: 0.0643 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1577 - val_projector_loss: 0.0789 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7420\n",
      "Epoch 366/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1278 - projector_loss: 0.0639 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1612 - val_projector_loss: 0.0806 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7580\n",
      "Epoch 367/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1278 - projector_loss: 0.0639 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1487 - val_projector_loss: 0.0744 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7445\n",
      "Epoch 368/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1266 - projector_loss: 0.0633 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1434 - val_projector_loss: 0.0717 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7570\n",
      "Epoch 369/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1265 - projector_loss: 0.0632 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1562 - val_projector_loss: 0.0781 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7655\n",
      "Epoch 370/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1274 - projector_loss: 0.0637 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1445 - val_projector_loss: 0.0722 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7400\n",
      "Epoch 371/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1260 - projector_loss: 0.0630 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1504 - val_projector_loss: 0.0752 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7520\n",
      "Epoch 372/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1267 - projector_loss: 0.0633 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1560 - val_projector_loss: 0.0780 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7510\n",
      "Epoch 373/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1286 - projector_loss: 0.0643 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1435 - val_projector_loss: 0.0717 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7415\n",
      "Epoch 374/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1272 - projector_loss: 0.0636 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1519 - val_projector_loss: 0.0759 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7750\n",
      "Epoch 375/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1273 - projector_loss: 0.0636 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1501 - val_projector_loss: 0.0750 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7570\n",
      "Epoch 376/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1275 - projector_loss: 0.0638 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1530 - val_projector_loss: 0.0765 - val_proj_std: 0.0423 - val_pred_std: 0.0424 - binary_accuracy: 0.7285\n",
      "Epoch 377/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1280 - projector_loss: 0.0640 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1535 - val_projector_loss: 0.0767 - val_proj_std: 0.0430 - val_pred_std: 0.0428 - binary_accuracy: 0.7445\n",
      "Epoch 378/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1259 - projector_loss: 0.0629 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1574 - val_projector_loss: 0.0787 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7540\n",
      "Epoch 379/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1271 - projector_loss: 0.0635 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1574 - val_projector_loss: 0.0787 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7515\n",
      "Epoch 380/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1256 - projector_loss: 0.0628 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1551 - val_projector_loss: 0.0775 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7430\n",
      "Epoch 381/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1287 - projector_loss: 0.0643 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1577 - val_projector_loss: 0.0788 - val_proj_std: 0.0427 - val_pred_std: 0.0428 - binary_accuracy: 0.7215\n",
      "Epoch 382/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1254 - projector_loss: 0.0627 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1425 - val_projector_loss: 0.0713 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7550\n",
      "Epoch 383/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1251 - projector_loss: 0.0626 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1450 - val_projector_loss: 0.0725 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7630\n",
      "Epoch 384/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1265 - projector_loss: 0.0632 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1520 - val_projector_loss: 0.0760 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7395\n",
      "Epoch 385/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1274 - projector_loss: 0.0637 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1503 - val_projector_loss: 0.0751 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7390\n",
      "Epoch 386/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1252 - projector_loss: 0.0626 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1513 - val_projector_loss: 0.0756 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7660\n",
      "Epoch 387/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1259 - projector_loss: 0.0629 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1505 - val_projector_loss: 0.0752 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.7735\n",
      "Epoch 388/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1271 - projector_loss: 0.0636 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1423 - val_projector_loss: 0.0711 - val_proj_std: 0.0422 - val_pred_std: 0.0422 - binary_accuracy: 0.7625\n",
      "Epoch 389/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1268 - projector_loss: 0.0634 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1508 - val_projector_loss: 0.0754 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7515\n",
      "Epoch 390/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1263 - projector_loss: 0.0631 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1518 - val_projector_loss: 0.0759 - val_proj_std: 0.0431 - val_pred_std: 0.0429 - binary_accuracy: 0.7465\n",
      "Epoch 391/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1261 - projector_loss: 0.0630 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1432 - val_projector_loss: 0.0716 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7675\n",
      "Epoch 392/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1265 - projector_loss: 0.0632 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1442 - val_projector_loss: 0.0721 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7885\n",
      "Epoch 393/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1249 - projector_loss: 0.0624 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1550 - val_projector_loss: 0.0775 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7675\n",
      "Epoch 394/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1258 - projector_loss: 0.0629 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1491 - val_projector_loss: 0.0746 - val_proj_std: 0.0425 - val_pred_std: 0.0425 - binary_accuracy: 0.7615\n",
      "Epoch 395/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1242 - projector_loss: 0.0621 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1404 - val_projector_loss: 0.0702 - val_proj_std: 0.0421 - val_pred_std: 0.0421 - binary_accuracy: 0.7405\n",
      "Epoch 396/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1236 - projector_loss: 0.0618 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1429 - val_projector_loss: 0.0715 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7950\n",
      "Epoch 397/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1269 - projector_loss: 0.0635 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1459 - val_projector_loss: 0.0730 - val_proj_std: 0.0427 - val_pred_std: 0.0425 - binary_accuracy: 0.7630\n",
      "Epoch 398/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1244 - projector_loss: 0.0622 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1456 - val_projector_loss: 0.0728 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7830\n",
      "Epoch 399/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1247 - projector_loss: 0.0624 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1479 - val_projector_loss: 0.0739 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7715\n",
      "Epoch 400/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1257 - projector_loss: 0.0628 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1603 - val_projector_loss: 0.0802 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.7480\n",
      "Epoch 401/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1260 - projector_loss: 0.0630 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1466 - val_projector_loss: 0.0733 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7500\n",
      "Epoch 402/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1240 - projector_loss: 0.0620 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1482 - val_projector_loss: 0.0741 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7710\n",
      "Epoch 403/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1231 - projector_loss: 0.0615 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1460 - val_projector_loss: 0.0730 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7635\n",
      "Epoch 404/800\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 0.1250 - projector_loss: 0.0625 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1491 - val_projector_loss: 0.0745 - val_proj_std: 0.0422 - val_pred_std: 0.0421 - binary_accuracy: 0.7645\n",
      "Epoch 405/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1260 - projector_loss: 0.0630 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1407 - val_projector_loss: 0.0703 - val_proj_std: 0.0424 - val_pred_std: 0.0423 - binary_accuracy: 0.7565\n",
      "Epoch 406/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1246 - projector_loss: 0.0623 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1488 - val_projector_loss: 0.0744 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7495\n",
      "Epoch 407/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1254 - projector_loss: 0.0627 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1486 - val_projector_loss: 0.0743 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7465\n",
      "Epoch 408/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1246 - projector_loss: 0.0623 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1510 - val_projector_loss: 0.0755 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7565\n",
      "Epoch 409/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1250 - projector_loss: 0.0625 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1454 - val_projector_loss: 0.0727 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7830\n",
      "Epoch 410/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1238 - projector_loss: 0.0619 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1455 - val_projector_loss: 0.0728 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7600\n",
      "Epoch 411/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1254 - projector_loss: 0.0627 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1503 - val_projector_loss: 0.0751 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7680\n",
      "Epoch 412/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1249 - projector_loss: 0.0624 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1528 - val_projector_loss: 0.0764 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7580\n",
      "Epoch 413/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1229 - projector_loss: 0.0615 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1481 - val_projector_loss: 0.0740 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7680\n",
      "Epoch 414/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1241 - projector_loss: 0.0621 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1427 - val_projector_loss: 0.0713 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7780\n",
      "Epoch 415/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1232 - projector_loss: 0.0616 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1511 - val_projector_loss: 0.0755 - val_proj_std: 0.0425 - val_pred_std: 0.0426 - binary_accuracy: 0.7645\n",
      "Epoch 416/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1223 - projector_loss: 0.0611 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1413 - val_projector_loss: 0.0707 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7755\n",
      "Epoch 417/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1222 - projector_loss: 0.0611 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1436 - val_projector_loss: 0.0718 - val_proj_std: 0.0423 - val_pred_std: 0.0420 - binary_accuracy: 0.7475\n",
      "Epoch 418/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1243 - projector_loss: 0.0622 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1462 - val_projector_loss: 0.0731 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7680\n",
      "Epoch 419/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1228 - projector_loss: 0.0614 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1490 - val_projector_loss: 0.0745 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7645\n",
      "Epoch 420/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1226 - projector_loss: 0.0613 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1476 - val_projector_loss: 0.0738 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7680\n",
      "Epoch 421/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1211 - projector_loss: 0.0606 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1570 - val_projector_loss: 0.0785 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7735\n",
      "Epoch 422/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1233 - projector_loss: 0.0616 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1451 - val_projector_loss: 0.0725 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7790\n",
      "Epoch 423/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1215 - projector_loss: 0.0608 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1486 - val_projector_loss: 0.0743 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7520\n",
      "Epoch 424/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1209 - projector_loss: 0.0604 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1472 - val_projector_loss: 0.0736 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7775\n",
      "Epoch 425/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1225 - projector_loss: 0.0612 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1517 - val_projector_loss: 0.0759 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7600\n",
      "Epoch 426/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1234 - projector_loss: 0.0617 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1578 - val_projector_loss: 0.0789 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7610\n",
      "Epoch 427/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1239 - projector_loss: 0.0620 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1586 - val_projector_loss: 0.0793 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7475\n",
      "Epoch 428/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1237 - projector_loss: 0.0618 - proj_std: 0.0437 - pred_std: 0.0436 - val_loss: 0.1539 - val_projector_loss: 0.0769 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7745\n",
      "Epoch 429/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1223 - projector_loss: 0.0611 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1512 - val_projector_loss: 0.0756 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7500\n",
      "Epoch 430/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1191 - projector_loss: 0.0596 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1397 - val_projector_loss: 0.0699 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7615\n",
      "Epoch 431/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1195 - projector_loss: 0.0597 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1467 - val_projector_loss: 0.0734 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7710\n",
      "Epoch 432/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1221 - projector_loss: 0.0611 - proj_std: 0.0437 - pred_std: 0.0435 - val_loss: 0.1450 - val_projector_loss: 0.0725 - val_proj_std: 0.0427 - val_pred_std: 0.0425 - binary_accuracy: 0.7795\n",
      "Epoch 433/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1229 - projector_loss: 0.0614 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1509 - val_projector_loss: 0.0754 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7470\n",
      "Epoch 434/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1215 - projector_loss: 0.0607 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1552 - val_projector_loss: 0.0776 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7675\n",
      "Epoch 435/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1200 - projector_loss: 0.0600 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1483 - val_projector_loss: 0.0742 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7705\n",
      "Epoch 436/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1209 - projector_loss: 0.0604 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1418 - val_projector_loss: 0.0709 - val_proj_std: 0.0424 - val_pred_std: 0.0423 - binary_accuracy: 0.7550\n",
      "Epoch 437/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1203 - projector_loss: 0.0601 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1525 - val_projector_loss: 0.0763 - val_proj_std: 0.0421 - val_pred_std: 0.0422 - binary_accuracy: 0.7600\n",
      "Epoch 438/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1219 - projector_loss: 0.0609 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1515 - val_projector_loss: 0.0758 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7920\n",
      "Epoch 439/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1232 - projector_loss: 0.0616 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1571 - val_projector_loss: 0.0785 - val_proj_std: 0.0427 - val_pred_std: 0.0425 - binary_accuracy: 0.7410\n",
      "Epoch 440/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1205 - projector_loss: 0.0603 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1461 - val_projector_loss: 0.0730 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7755\n",
      "Epoch 441/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1205 - projector_loss: 0.0603 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1528 - val_projector_loss: 0.0764 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7505\n",
      "Epoch 442/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1196 - projector_loss: 0.0598 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1472 - val_projector_loss: 0.0736 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7605\n",
      "Epoch 443/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1207 - projector_loss: 0.0604 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1498 - val_projector_loss: 0.0749 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7590\n",
      "Epoch 444/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1211 - projector_loss: 0.0606 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1472 - val_projector_loss: 0.0736 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.7550\n",
      "Epoch 445/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1199 - projector_loss: 0.0600 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1508 - val_projector_loss: 0.0754 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7720\n",
      "Epoch 446/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1189 - projector_loss: 0.0594 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1520 - val_projector_loss: 0.0760 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7825\n",
      "Epoch 447/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1188 - projector_loss: 0.0594 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1520 - val_projector_loss: 0.0760 - val_proj_std: 0.0423 - val_pred_std: 0.0423 - binary_accuracy: 0.7390\n",
      "Epoch 448/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1194 - projector_loss: 0.0597 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1479 - val_projector_loss: 0.0740 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7700\n",
      "Epoch 449/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1175 - projector_loss: 0.0588 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1539 - val_projector_loss: 0.0769 - val_proj_std: 0.0425 - val_pred_std: 0.0426 - binary_accuracy: 0.7725\n",
      "Epoch 450/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1189 - projector_loss: 0.0594 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1590 - val_projector_loss: 0.0795 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7770\n",
      "Epoch 451/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1196 - projector_loss: 0.0598 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1491 - val_projector_loss: 0.0745 - val_proj_std: 0.0430 - val_pred_std: 0.0428 - binary_accuracy: 0.7700\n",
      "Epoch 452/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1192 - projector_loss: 0.0596 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1417 - val_projector_loss: 0.0708 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7850\n",
      "Epoch 453/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1194 - projector_loss: 0.0597 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1425 - val_projector_loss: 0.0713 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7735\n",
      "Epoch 454/800\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 0.1177 - projector_loss: 0.0589 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1504 - val_projector_loss: 0.0752 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7885\n",
      "Epoch 455/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1194 - projector_loss: 0.0597 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1482 - val_projector_loss: 0.0741 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7825\n",
      "Epoch 456/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1185 - projector_loss: 0.0592 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1497 - val_projector_loss: 0.0748 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7635\n",
      "Epoch 457/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1175 - projector_loss: 0.0587 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1403 - val_projector_loss: 0.0702 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7995\n",
      "Epoch 458/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1178 - projector_loss: 0.0589 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1417 - val_projector_loss: 0.0708 - val_proj_std: 0.0424 - val_pred_std: 0.0425 - binary_accuracy: 0.7820\n",
      "Epoch 459/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1168 - projector_loss: 0.0584 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1506 - val_projector_loss: 0.0753 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.7840\n",
      "Epoch 460/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1182 - projector_loss: 0.0591 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1546 - val_projector_loss: 0.0773 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7920\n",
      "Epoch 461/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1153 - projector_loss: 0.0577 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1449 - val_projector_loss: 0.0725 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7960\n",
      "Epoch 462/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1162 - projector_loss: 0.0581 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1463 - val_projector_loss: 0.0732 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7830\n",
      "Epoch 463/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1175 - projector_loss: 0.0588 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1451 - val_projector_loss: 0.0725 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7765\n",
      "Epoch 464/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1182 - projector_loss: 0.0591 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1562 - val_projector_loss: 0.0781 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.7845\n",
      "Epoch 465/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1172 - projector_loss: 0.0586 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1445 - val_projector_loss: 0.0723 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7770\n",
      "Epoch 466/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1171 - projector_loss: 0.0586 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1439 - val_projector_loss: 0.0719 - val_proj_std: 0.0427 - val_pred_std: 0.0424 - binary_accuracy: 0.7595\n",
      "Epoch 467/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1154 - projector_loss: 0.0577 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1507 - val_projector_loss: 0.0754 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7960\n",
      "Epoch 468/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1170 - projector_loss: 0.0585 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1408 - val_projector_loss: 0.0704 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7795\n",
      "Epoch 469/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1159 - projector_loss: 0.0579 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1440 - val_projector_loss: 0.0720 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7740\n",
      "Epoch 470/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1164 - projector_loss: 0.0582 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1507 - val_projector_loss: 0.0753 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.7600\n",
      "Epoch 471/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1166 - projector_loss: 0.0583 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1436 - val_projector_loss: 0.0718 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.7715\n",
      "Epoch 472/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1166 - projector_loss: 0.0583 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1459 - val_projector_loss: 0.0729 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7660\n",
      "Epoch 473/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1162 - projector_loss: 0.0581 - proj_std: 0.0436 - pred_std: 0.0434 - val_loss: 0.1484 - val_projector_loss: 0.0742 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.7725\n",
      "Epoch 474/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1153 - projector_loss: 0.0577 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1476 - val_projector_loss: 0.0738 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7860\n",
      "Epoch 475/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1178 - projector_loss: 0.0589 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0700 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7950\n",
      "Epoch 476/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1168 - projector_loss: 0.0584 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1475 - val_projector_loss: 0.0737 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7640\n",
      "Epoch 477/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1159 - projector_loss: 0.0579 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1396 - val_projector_loss: 0.0698 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7955\n",
      "Epoch 478/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1172 - projector_loss: 0.0586 - proj_std: 0.0436 - pred_std: 0.0434 - val_loss: 0.1421 - val_projector_loss: 0.0710 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7910\n",
      "Epoch 479/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1156 - projector_loss: 0.0578 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1368 - val_projector_loss: 0.0684 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7880\n",
      "Epoch 480/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1148 - projector_loss: 0.0574 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1398 - val_projector_loss: 0.0699 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7895\n",
      "Epoch 481/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1153 - projector_loss: 0.0577 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1505 - val_projector_loss: 0.0752 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7730\n",
      "Epoch 482/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1155 - projector_loss: 0.0577 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1398 - val_projector_loss: 0.0699 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.7725\n",
      "Epoch 483/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1138 - projector_loss: 0.0569 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1402 - val_projector_loss: 0.0701 - val_proj_std: 0.0430 - val_pred_std: 0.0431 - binary_accuracy: 0.7805\n",
      "Epoch 484/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1163 - projector_loss: 0.0581 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1428 - val_projector_loss: 0.0714 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7865\n",
      "Epoch 485/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1160 - projector_loss: 0.0580 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1498 - val_projector_loss: 0.0749 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7835\n",
      "Epoch 486/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1153 - projector_loss: 0.0577 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1482 - val_projector_loss: 0.0741 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.8015\n",
      "Epoch 487/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.1133 - projector_loss: 0.0566 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1477 - val_projector_loss: 0.0738 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7955\n",
      "Epoch 488/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1146 - projector_loss: 0.0573 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1463 - val_projector_loss: 0.0732 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.8040\n",
      "Epoch 489/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1133 - projector_loss: 0.0566 - proj_std: 0.0436 - pred_std: 0.0434 - val_loss: 0.1445 - val_projector_loss: 0.0723 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7870\n",
      "Epoch 490/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1141 - projector_loss: 0.0570 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1441 - val_projector_loss: 0.0721 - val_proj_std: 0.0432 - val_pred_std: 0.0430 - binary_accuracy: 0.8005\n",
      "Epoch 491/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1145 - projector_loss: 0.0572 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1493 - val_projector_loss: 0.0746 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7960\n",
      "Epoch 492/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1165 - projector_loss: 0.0582 - proj_std: 0.0436 - pred_std: 0.0434 - val_loss: 0.1447 - val_projector_loss: 0.0723 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.8030\n",
      "Epoch 493/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1138 - projector_loss: 0.0569 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1477 - val_projector_loss: 0.0738 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7920\n",
      "Epoch 494/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1134 - projector_loss: 0.0567 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1477 - val_projector_loss: 0.0739 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7990\n",
      "Epoch 495/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1134 - projector_loss: 0.0567 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1537 - val_projector_loss: 0.0768 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7965\n",
      "Epoch 496/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1138 - projector_loss: 0.0569 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1403 - val_projector_loss: 0.0702 - val_proj_std: 0.0425 - val_pred_std: 0.0424 - binary_accuracy: 0.7955\n",
      "Epoch 497/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1133 - projector_loss: 0.0567 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1425 - val_projector_loss: 0.0712 - val_proj_std: 0.0427 - val_pred_std: 0.0427 - binary_accuracy: 0.7815\n",
      "Epoch 498/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1104 - projector_loss: 0.0552 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1438 - val_projector_loss: 0.0719 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8040\n",
      "Epoch 499/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1137 - projector_loss: 0.0568 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1361 - val_projector_loss: 0.0681 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7820\n",
      "Epoch 500/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1132 - projector_loss: 0.0566 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1408 - val_projector_loss: 0.0704 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.8165\n",
      "Epoch 501/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1136 - projector_loss: 0.0568 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1455 - val_projector_loss: 0.0728 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7940\n",
      "Epoch 502/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1127 - projector_loss: 0.0563 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1550 - val_projector_loss: 0.0775 - val_proj_std: 0.0430 - val_pred_std: 0.0428 - binary_accuracy: 0.7965\n",
      "Epoch 503/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1117 - projector_loss: 0.0559 - proj_std: 0.0436 - pred_std: 0.0434 - val_loss: 0.1419 - val_projector_loss: 0.0710 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8145\n",
      "Epoch 504/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1103 - projector_loss: 0.0551 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1407 - val_projector_loss: 0.0703 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7880\n",
      "Epoch 505/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1130 - projector_loss: 0.0565 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1431 - val_projector_loss: 0.0715 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.7995\n",
      "Epoch 506/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1117 - projector_loss: 0.0559 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1409 - val_projector_loss: 0.0705 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.8020\n",
      "Epoch 507/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1139 - projector_loss: 0.0570 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1361 - val_projector_loss: 0.0681 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.7770\n",
      "Epoch 508/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1112 - projector_loss: 0.0556 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1436 - val_projector_loss: 0.0718 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8000\n",
      "Epoch 509/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1118 - projector_loss: 0.0559 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1452 - val_projector_loss: 0.0726 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.8020\n",
      "Epoch 510/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1131 - projector_loss: 0.0566 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1413 - val_projector_loss: 0.0706 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7910\n",
      "Epoch 511/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1123 - projector_loss: 0.0561 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1394 - val_projector_loss: 0.0697 - val_proj_std: 0.0426 - val_pred_std: 0.0425 - binary_accuracy: 0.7745\n",
      "Epoch 512/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1124 - projector_loss: 0.0562 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1416 - val_projector_loss: 0.0708 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.7765\n",
      "Epoch 513/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1114 - projector_loss: 0.0557 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1350 - val_projector_loss: 0.0675 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8030\n",
      "Epoch 514/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1095 - projector_loss: 0.0548 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1426 - val_projector_loss: 0.0713 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.8000\n",
      "Epoch 515/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1115 - projector_loss: 0.0557 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1408 - val_projector_loss: 0.0704 - val_proj_std: 0.0429 - val_pred_std: 0.0427 - binary_accuracy: 0.7965\n",
      "Epoch 516/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1113 - projector_loss: 0.0556 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1369 - val_projector_loss: 0.0684 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.7820\n",
      "Epoch 517/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1107 - projector_loss: 0.0554 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1450 - val_projector_loss: 0.0725 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7920\n",
      "Epoch 518/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1099 - projector_loss: 0.0550 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1453 - val_projector_loss: 0.0727 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7970\n",
      "Epoch 519/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1103 - projector_loss: 0.0551 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1428 - val_projector_loss: 0.0714 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8075\n",
      "Epoch 520/800\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 0.1089 - projector_loss: 0.0545 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1464 - val_projector_loss: 0.0732 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8120\n",
      "Epoch 521/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1089 - projector_loss: 0.0544 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1402 - val_projector_loss: 0.0701 - val_proj_std: 0.0432 - val_pred_std: 0.0430 - binary_accuracy: 0.8000\n",
      "Epoch 522/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1095 - projector_loss: 0.0547 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1408 - val_projector_loss: 0.0704 - val_proj_std: 0.0430 - val_pred_std: 0.0428 - binary_accuracy: 0.8060\n",
      "Epoch 523/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1102 - projector_loss: 0.0551 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1450 - val_projector_loss: 0.0725 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8205\n",
      "Epoch 524/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1100 - projector_loss: 0.0550 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1465 - val_projector_loss: 0.0732 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8065\n",
      "Epoch 525/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1107 - projector_loss: 0.0554 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0700 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.7970\n",
      "Epoch 526/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1096 - projector_loss: 0.0548 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1429 - val_projector_loss: 0.0715 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8040\n",
      "Epoch 527/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1069 - projector_loss: 0.0535 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1481 - val_projector_loss: 0.0740 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8115\n",
      "Epoch 528/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1081 - projector_loss: 0.0541 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1474 - val_projector_loss: 0.0737 - val_proj_std: 0.0424 - val_pred_std: 0.0424 - binary_accuracy: 0.7970\n",
      "Epoch 529/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1099 - projector_loss: 0.0550 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1444 - val_projector_loss: 0.0722 - val_proj_std: 0.0429 - val_pred_std: 0.0428 - binary_accuracy: 0.7825\n",
      "Epoch 530/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1094 - projector_loss: 0.0547 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1449 - val_projector_loss: 0.0725 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7945\n",
      "Epoch 531/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1084 - projector_loss: 0.0542 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1455 - val_projector_loss: 0.0727 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8045\n",
      "Epoch 532/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1081 - projector_loss: 0.0540 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1449 - val_projector_loss: 0.0725 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.7930\n",
      "Epoch 533/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1088 - projector_loss: 0.0544 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1439 - val_projector_loss: 0.0720 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.7980\n",
      "Epoch 534/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1087 - projector_loss: 0.0543 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1438 - val_projector_loss: 0.0719 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7955\n",
      "Epoch 535/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1081 - projector_loss: 0.0541 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.8230\n",
      "Epoch 536/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1063 - projector_loss: 0.0531 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1477 - val_projector_loss: 0.0739 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8070\n",
      "Epoch 537/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1085 - projector_loss: 0.0543 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1444 - val_projector_loss: 0.0722 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7925\n",
      "Epoch 538/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1082 - projector_loss: 0.0541 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1395 - val_projector_loss: 0.0697 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.8000\n",
      "Epoch 539/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1069 - projector_loss: 0.0535 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1375 - val_projector_loss: 0.0688 - val_proj_std: 0.0430 - val_pred_std: 0.0428 - binary_accuracy: 0.8050\n",
      "Epoch 540/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1069 - projector_loss: 0.0534 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1409 - val_projector_loss: 0.0705 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.7995\n",
      "Epoch 541/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1066 - projector_loss: 0.0533 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1428 - val_projector_loss: 0.0714 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.8190\n",
      "Epoch 542/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1028 - projector_loss: 0.0514 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1367 - val_projector_loss: 0.0684 - val_proj_std: 0.0429 - val_pred_std: 0.0430 - binary_accuracy: 0.8145\n",
      "Epoch 543/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1050 - projector_loss: 0.0525 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1394 - val_projector_loss: 0.0697 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.7990\n",
      "Epoch 544/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1055 - projector_loss: 0.0528 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1357 - val_projector_loss: 0.0678 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.8140\n",
      "Epoch 545/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1057 - projector_loss: 0.0528 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1431 - val_projector_loss: 0.0716 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.7905\n",
      "Epoch 546/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1068 - projector_loss: 0.0534 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1358 - val_projector_loss: 0.0679 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.8095\n",
      "Epoch 547/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1060 - projector_loss: 0.0530 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1431 - val_projector_loss: 0.0716 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.7920\n",
      "Epoch 548/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1082 - projector_loss: 0.0541 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1452 - val_projector_loss: 0.0726 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8135\n",
      "Epoch 549/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1058 - projector_loss: 0.0529 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1361 - val_projector_loss: 0.0680 - val_proj_std: 0.0426 - val_pred_std: 0.0426 - binary_accuracy: 0.8060\n",
      "Epoch 550/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.1034 - projector_loss: 0.0517 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1407 - val_projector_loss: 0.0703 - val_proj_std: 0.0430 - val_pred_std: 0.0431 - binary_accuracy: 0.8195\n",
      "Epoch 551/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1016 - projector_loss: 0.0508 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0428 - val_pred_std: 0.0426 - binary_accuracy: 0.8015\n",
      "Epoch 552/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1047 - projector_loss: 0.0523 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1459 - val_projector_loss: 0.0729 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8225\n",
      "Epoch 553/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1044 - projector_loss: 0.0522 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1431 - val_projector_loss: 0.0715 - val_proj_std: 0.0428 - val_pred_std: 0.0427 - binary_accuracy: 0.8045\n",
      "Epoch 554/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1009 - projector_loss: 0.0504 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1478 - val_projector_loss: 0.0739 - val_proj_std: 0.0428 - val_pred_std: 0.0428 - binary_accuracy: 0.8185\n",
      "Epoch 555/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1050 - projector_loss: 0.0525 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1460 - val_projector_loss: 0.0730 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8135\n",
      "Epoch 556/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1027 - projector_loss: 0.0513 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1315 - val_projector_loss: 0.0657 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.8210\n",
      "Epoch 557/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1035 - projector_loss: 0.0518 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1469 - val_projector_loss: 0.0735 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8195\n",
      "Epoch 558/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1030 - projector_loss: 0.0515 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1377 - val_projector_loss: 0.0688 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8180\n",
      "Epoch 559/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1042 - projector_loss: 0.0521 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1409 - val_projector_loss: 0.0704 - val_proj_std: 0.0427 - val_pred_std: 0.0426 - binary_accuracy: 0.8240\n",
      "Epoch 560/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1021 - projector_loss: 0.0510 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1427 - val_projector_loss: 0.0713 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8160\n",
      "Epoch 561/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1039 - projector_loss: 0.0519 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1415 - val_projector_loss: 0.0707 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8165\n",
      "Epoch 562/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1024 - projector_loss: 0.0512 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1420 - val_projector_loss: 0.0710 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8050\n",
      "Epoch 563/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1030 - projector_loss: 0.0515 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1456 - val_projector_loss: 0.0728 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8195\n",
      "Epoch 564/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1014 - projector_loss: 0.0507 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1480 - val_projector_loss: 0.0740 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8185\n",
      "Epoch 565/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1025 - projector_loss: 0.0512 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1371 - val_projector_loss: 0.0686 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8215\n",
      "Epoch 566/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1041 - projector_loss: 0.0520 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1461 - val_projector_loss: 0.0731 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8220\n",
      "Epoch 567/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1017 - projector_loss: 0.0509 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1463 - val_projector_loss: 0.0732 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8045\n",
      "Epoch 568/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1016 - projector_loss: 0.0508 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1508 - val_projector_loss: 0.0754 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8000\n",
      "Epoch 569/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.1025 - projector_loss: 0.0513 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1435 - val_projector_loss: 0.0718 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8050\n",
      "Epoch 570/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1033 - projector_loss: 0.0516 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1440 - val_projector_loss: 0.0720 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8085\n",
      "Epoch 571/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.1027 - projector_loss: 0.0513 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1415 - val_projector_loss: 0.0707 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8200\n",
      "Epoch 572/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1017 - projector_loss: 0.0508 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1438 - val_projector_loss: 0.0719 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.7910\n",
      "Epoch 573/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0998 - projector_loss: 0.0499 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1392 - val_projector_loss: 0.0696 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8130\n",
      "Epoch 574/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1002 - projector_loss: 0.0501 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1436 - val_projector_loss: 0.0718 - val_proj_std: 0.0431 - val_pred_std: 0.0432 - binary_accuracy: 0.8160\n",
      "Epoch 575/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1001 - projector_loss: 0.0500 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1423 - val_projector_loss: 0.0711 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8345\n",
      "Epoch 576/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1007 - projector_loss: 0.0504 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1393 - val_projector_loss: 0.0696 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8210\n",
      "Epoch 577/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0997 - projector_loss: 0.0499 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1529 - val_projector_loss: 0.0764 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8190\n",
      "Epoch 578/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.1014 - projector_loss: 0.0507 - proj_std: 0.0436 - pred_std: 0.0435 - val_loss: 0.1411 - val_projector_loss: 0.0705 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8190\n",
      "Epoch 579/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0989 - projector_loss: 0.0494 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1450 - val_projector_loss: 0.0725 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.8185\n",
      "Epoch 580/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0997 - projector_loss: 0.0498 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1470 - val_projector_loss: 0.0735 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8125\n",
      "Epoch 581/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0990 - projector_loss: 0.0495 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1411 - val_projector_loss: 0.0705 - val_proj_std: 0.0432 - val_pred_std: 0.0430 - binary_accuracy: 0.8345\n",
      "Epoch 582/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.1004 - projector_loss: 0.0502 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1438 - val_projector_loss: 0.0719 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8250\n",
      "Epoch 583/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0979 - projector_loss: 0.0490 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1342 - val_projector_loss: 0.0671 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8115\n",
      "Epoch 584/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0988 - projector_loss: 0.0494 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1500 - val_projector_loss: 0.0750 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8285\n",
      "Epoch 585/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0995 - projector_loss: 0.0498 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1424 - val_projector_loss: 0.0712 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8210\n",
      "Epoch 586/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.0973 - projector_loss: 0.0487 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1380 - val_projector_loss: 0.0690 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8180\n",
      "Epoch 587/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0990 - projector_loss: 0.0495 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1455 - val_projector_loss: 0.0727 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8280\n",
      "Epoch 588/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0983 - projector_loss: 0.0492 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1381 - val_projector_loss: 0.0691 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8420\n",
      "Epoch 589/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0969 - projector_loss: 0.0485 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1488 - val_projector_loss: 0.0744 - val_proj_std: 0.0430 - val_pred_std: 0.0429 - binary_accuracy: 0.8230\n",
      "Epoch 590/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0961 - projector_loss: 0.0480 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1440 - val_projector_loss: 0.0720 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8265\n",
      "Epoch 591/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0974 - projector_loss: 0.0487 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1422 - val_projector_loss: 0.0711 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8120\n",
      "Epoch 592/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0987 - projector_loss: 0.0494 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1406 - val_projector_loss: 0.0703 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8335\n",
      "Epoch 593/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0977 - projector_loss: 0.0488 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1411 - val_projector_loss: 0.0705 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8330\n",
      "Epoch 594/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0973 - projector_loss: 0.0487 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1461 - val_projector_loss: 0.0730 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.8250\n",
      "Epoch 595/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0968 - projector_loss: 0.0484 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1413 - val_projector_loss: 0.0707 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8305\n",
      "Epoch 596/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0967 - projector_loss: 0.0484 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1383 - val_projector_loss: 0.0691 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8325\n",
      "Epoch 597/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0947 - projector_loss: 0.0473 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1415 - val_projector_loss: 0.0707 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8295\n",
      "Epoch 598/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0952 - projector_loss: 0.0476 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1385 - val_projector_loss: 0.0692 - val_proj_std: 0.0429 - val_pred_std: 0.0429 - binary_accuracy: 0.8130\n",
      "Epoch 599/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0951 - projector_loss: 0.0475 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1337 - val_projector_loss: 0.0668 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8450\n",
      "Epoch 600/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0953 - projector_loss: 0.0476 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1429 - val_projector_loss: 0.0715 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8390\n",
      "Epoch 601/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0942 - projector_loss: 0.0471 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1388 - val_projector_loss: 0.0694 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8445\n",
      "Epoch 602/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.0952 - projector_loss: 0.0476 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1428 - val_projector_loss: 0.0714 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8245\n",
      "Epoch 603/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0934 - projector_loss: 0.0467 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1443 - val_projector_loss: 0.0721 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8290\n",
      "Epoch 604/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0946 - projector_loss: 0.0473 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1445 - val_projector_loss: 0.0722 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8305\n",
      "Epoch 605/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0931 - projector_loss: 0.0465 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1465 - val_projector_loss: 0.0733 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8360\n",
      "Epoch 606/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0946 - projector_loss: 0.0473 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1430 - val_projector_loss: 0.0715 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8390\n",
      "Epoch 607/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0932 - projector_loss: 0.0466 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1386 - val_projector_loss: 0.0693 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8330\n",
      "Epoch 608/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0956 - projector_loss: 0.0478 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1513 - val_projector_loss: 0.0757 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8385\n",
      "Epoch 609/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0926 - projector_loss: 0.0463 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1389 - val_projector_loss: 0.0694 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8295\n",
      "Epoch 610/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0945 - projector_loss: 0.0472 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1376 - val_projector_loss: 0.0688 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8360\n",
      "Epoch 611/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0930 - projector_loss: 0.0465 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1404 - val_projector_loss: 0.0702 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8225\n",
      "Epoch 612/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0939 - projector_loss: 0.0469 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8140\n",
      "Epoch 613/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0933 - projector_loss: 0.0467 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1391 - val_projector_loss: 0.0696 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8400\n",
      "Epoch 614/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0923 - projector_loss: 0.0461 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1420 - val_projector_loss: 0.0710 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8065\n",
      "Epoch 615/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0926 - projector_loss: 0.0463 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1387 - val_projector_loss: 0.0694 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8325\n",
      "Epoch 616/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0925 - projector_loss: 0.0462 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1350 - val_projector_loss: 0.0675 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8180\n",
      "Epoch 617/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0921 - projector_loss: 0.0460 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1410 - val_projector_loss: 0.0705 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8400\n",
      "Epoch 618/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0919 - projector_loss: 0.0459 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1424 - val_projector_loss: 0.0712 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8295\n",
      "Epoch 619/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0917 - projector_loss: 0.0458 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1402 - val_projector_loss: 0.0701 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8320\n",
      "Epoch 620/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0907 - projector_loss: 0.0454 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1397 - val_projector_loss: 0.0698 - val_proj_std: 0.0431 - val_pred_std: 0.0430 - binary_accuracy: 0.8295\n",
      "Epoch 621/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0911 - projector_loss: 0.0455 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1393 - val_projector_loss: 0.0697 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8090\n",
      "Epoch 622/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0899 - projector_loss: 0.0449 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1400 - val_projector_loss: 0.0700 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8160\n",
      "Epoch 623/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0914 - projector_loss: 0.0457 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1453 - val_projector_loss: 0.0726 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8355\n",
      "Epoch 624/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.0918 - projector_loss: 0.0459 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1419 - val_projector_loss: 0.0710 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8480\n",
      "Epoch 625/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0914 - projector_loss: 0.0457 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1463 - val_projector_loss: 0.0732 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8235\n",
      "Epoch 626/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0916 - projector_loss: 0.0458 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1427 - val_projector_loss: 0.0713 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8265\n",
      "Epoch 627/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0895 - projector_loss: 0.0447 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1406 - val_projector_loss: 0.0703 - val_proj_std: 0.0431 - val_pred_std: 0.0431 - binary_accuracy: 0.8095\n",
      "Epoch 628/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0891 - projector_loss: 0.0446 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1509 - val_projector_loss: 0.0754 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8165\n",
      "Epoch 629/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0891 - projector_loss: 0.0446 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1393 - val_projector_loss: 0.0697 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8410\n",
      "Epoch 630/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0895 - projector_loss: 0.0448 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1422 - val_projector_loss: 0.0711 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8165\n",
      "Epoch 631/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.0911 - projector_loss: 0.0456 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1390 - val_projector_loss: 0.0695 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8330\n",
      "Epoch 632/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0870 - projector_loss: 0.0435 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1407 - val_projector_loss: 0.0704 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8260\n",
      "Epoch 633/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0884 - projector_loss: 0.0442 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1478 - val_projector_loss: 0.0739 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8395\n",
      "Epoch 634/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0884 - projector_loss: 0.0442 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1381 - val_projector_loss: 0.0690 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8315\n",
      "Epoch 635/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.0891 - projector_loss: 0.0446 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1387 - val_projector_loss: 0.0693 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8370\n",
      "Epoch 636/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0883 - projector_loss: 0.0441 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1390 - val_projector_loss: 0.0695 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8285\n",
      "Epoch 637/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0880 - projector_loss: 0.0440 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1350 - val_projector_loss: 0.0675 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8325\n",
      "Epoch 638/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0880 - projector_loss: 0.0440 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1401 - val_projector_loss: 0.0701 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8345\n",
      "Epoch 639/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0863 - projector_loss: 0.0432 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1424 - val_projector_loss: 0.0712 - val_proj_std: 0.0431 - val_pred_std: 0.0432 - binary_accuracy: 0.8525\n",
      "Epoch 640/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0875 - projector_loss: 0.0437 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1325 - val_projector_loss: 0.0662 - val_proj_std: 0.0430 - val_pred_std: 0.0430 - binary_accuracy: 0.8295\n",
      "Epoch 641/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0833 - projector_loss: 0.0417 - proj_std: 0.0434 - pred_std: 0.0433 - val_loss: 0.1351 - val_projector_loss: 0.0676 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8320\n",
      "Epoch 642/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0839 - projector_loss: 0.0420 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1422 - val_projector_loss: 0.0711 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8365\n",
      "Epoch 643/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.0852 - projector_loss: 0.0426 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1473 - val_projector_loss: 0.0737 - val_proj_std: 0.0432 - val_pred_std: 0.0431 - binary_accuracy: 0.8380\n",
      "Epoch 644/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0861 - projector_loss: 0.0431 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1391 - val_projector_loss: 0.0696 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8325\n",
      "Epoch 645/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0851 - projector_loss: 0.0425 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1448 - val_projector_loss: 0.0724 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8385\n",
      "Epoch 646/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0848 - projector_loss: 0.0424 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1420 - val_projector_loss: 0.0710 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8480\n",
      "Epoch 647/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0856 - projector_loss: 0.0428 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1400 - val_projector_loss: 0.0700 - val_proj_std: 0.0432 - val_pred_std: 0.0432 - binary_accuracy: 0.8350\n",
      "Epoch 648/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0855 - projector_loss: 0.0428 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1439 - val_projector_loss: 0.0719 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8410\n",
      "Epoch 649/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0835 - projector_loss: 0.0418 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1430 - val_projector_loss: 0.0715 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8360\n",
      "Epoch 650/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0843 - projector_loss: 0.0421 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1404 - val_projector_loss: 0.0702 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8455\n",
      "Epoch 651/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0837 - projector_loss: 0.0418 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1384 - val_projector_loss: 0.0692 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8435\n",
      "Epoch 652/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.0837 - projector_loss: 0.0419 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1381 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8410\n",
      "Epoch 653/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0827 - projector_loss: 0.0414 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1385 - val_projector_loss: 0.0692 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8430\n",
      "Epoch 654/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0841 - projector_loss: 0.0421 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1389 - val_projector_loss: 0.0694 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8445\n",
      "Epoch 655/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0825 - projector_loss: 0.0413 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1394 - val_projector_loss: 0.0697 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8485\n",
      "Epoch 656/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0828 - projector_loss: 0.0414 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8420\n",
      "Epoch 657/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0816 - projector_loss: 0.0408 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1411 - val_projector_loss: 0.0706 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8275\n",
      "Epoch 658/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0824 - projector_loss: 0.0412 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1386 - val_projector_loss: 0.0693 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8465\n",
      "Epoch 659/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0815 - projector_loss: 0.0407 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1389 - val_projector_loss: 0.0695 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8420\n",
      "Epoch 660/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0816 - projector_loss: 0.0408 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1405 - val_projector_loss: 0.0702 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8415\n",
      "Epoch 661/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0811 - projector_loss: 0.0406 - proj_std: 0.0435 - pred_std: 0.0434 - val_loss: 0.1390 - val_projector_loss: 0.0695 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8445\n",
      "Epoch 662/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0809 - projector_loss: 0.0405 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1391 - val_projector_loss: 0.0695 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8285\n",
      "Epoch 663/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0808 - projector_loss: 0.0404 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1347 - val_projector_loss: 0.0674 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8435\n",
      "Epoch 664/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0797 - projector_loss: 0.0398 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1365 - val_projector_loss: 0.0683 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8440\n",
      "Epoch 665/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0807 - projector_loss: 0.0404 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1430 - val_projector_loss: 0.0715 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8500\n",
      "Epoch 666/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0806 - projector_loss: 0.0403 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1434 - val_projector_loss: 0.0717 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8495\n",
      "Epoch 667/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0802 - projector_loss: 0.0401 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1410 - val_projector_loss: 0.0705 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8440\n",
      "Epoch 668/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.0806 - projector_loss: 0.0403 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1428 - val_projector_loss: 0.0714 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8465\n",
      "Epoch 669/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0807 - projector_loss: 0.0404 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1378 - val_projector_loss: 0.0689 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8325\n",
      "Epoch 670/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0786 - projector_loss: 0.0393 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1361 - val_projector_loss: 0.0680 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8510\n",
      "Epoch 671/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0786 - projector_loss: 0.0393 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1412 - val_projector_loss: 0.0706 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8450\n",
      "Epoch 672/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0786 - projector_loss: 0.0393 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1384 - val_projector_loss: 0.0692 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8425\n",
      "Epoch 673/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0780 - projector_loss: 0.0390 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1410 - val_projector_loss: 0.0705 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8405\n",
      "Epoch 674/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0774 - projector_loss: 0.0387 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1367 - val_projector_loss: 0.0683 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8430\n",
      "Epoch 675/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0784 - projector_loss: 0.0392 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1409 - val_projector_loss: 0.0704 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8465\n",
      "Epoch 676/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0776 - projector_loss: 0.0388 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1355 - val_projector_loss: 0.0677 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8415\n",
      "Epoch 677/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0786 - projector_loss: 0.0393 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1383 - val_projector_loss: 0.0692 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8440\n",
      "Epoch 678/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0774 - projector_loss: 0.0387 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0700 - val_proj_std: 0.0433 - val_pred_std: 0.0432 - binary_accuracy: 0.8445\n",
      "Epoch 679/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0768 - projector_loss: 0.0384 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1380 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8500\n",
      "Epoch 680/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0765 - projector_loss: 0.0383 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1382 - val_projector_loss: 0.0691 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8450\n",
      "Epoch 681/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0766 - projector_loss: 0.0383 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1379 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8515\n",
      "Epoch 682/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0759 - projector_loss: 0.0380 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1386 - val_projector_loss: 0.0693 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8550\n",
      "Epoch 683/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0755 - projector_loss: 0.0378 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1380 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8520\n",
      "Epoch 684/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0768 - projector_loss: 0.0384 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1426 - val_projector_loss: 0.0713 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8410\n",
      "Epoch 685/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.0756 - projector_loss: 0.0378 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1423 - val_projector_loss: 0.0711 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8455\n",
      "Epoch 686/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0748 - projector_loss: 0.0374 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0700 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8515\n",
      "Epoch 687/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0747 - projector_loss: 0.0374 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1400 - val_projector_loss: 0.0700 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8540\n",
      "Epoch 688/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0729 - projector_loss: 0.0365 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1433 - val_projector_loss: 0.0717 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8570\n",
      "Epoch 689/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0741 - projector_loss: 0.0371 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1438 - val_projector_loss: 0.0719 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8520\n",
      "Epoch 690/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0735 - projector_loss: 0.0368 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1390 - val_projector_loss: 0.0695 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8470\n",
      "Epoch 691/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0730 - projector_loss: 0.0365 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1358 - val_projector_loss: 0.0679 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8505\n",
      "Epoch 692/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0731 - projector_loss: 0.0366 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1363 - val_projector_loss: 0.0682 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8490\n",
      "Epoch 693/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0722 - projector_loss: 0.0361 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1409 - val_projector_loss: 0.0705 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8425\n",
      "Epoch 694/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0722 - projector_loss: 0.0361 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1397 - val_projector_loss: 0.0699 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8490\n",
      "Epoch 695/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0723 - projector_loss: 0.0362 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1386 - val_projector_loss: 0.0693 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8505\n",
      "Epoch 696/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0707 - projector_loss: 0.0353 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1455 - val_projector_loss: 0.0727 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8475\n",
      "Epoch 697/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0721 - projector_loss: 0.0360 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1417 - val_projector_loss: 0.0708 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8510\n",
      "Epoch 698/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0714 - projector_loss: 0.0357 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1454 - val_projector_loss: 0.0727 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8505\n",
      "Epoch 699/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0704 - projector_loss: 0.0352 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1395 - val_projector_loss: 0.0698 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8540\n",
      "Epoch 700/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0704 - projector_loss: 0.0352 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1421 - val_projector_loss: 0.0710 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8520\n",
      "Epoch 701/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.0701 - projector_loss: 0.0351 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1383 - val_projector_loss: 0.0691 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8520\n",
      "Epoch 702/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0709 - projector_loss: 0.0355 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1399 - val_projector_loss: 0.0699 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8450\n",
      "Epoch 703/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0700 - projector_loss: 0.0350 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1380 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8525\n",
      "Epoch 704/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0695 - projector_loss: 0.0348 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0700 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8440\n",
      "Epoch 705/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0699 - projector_loss: 0.0349 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1382 - val_projector_loss: 0.0691 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8510\n",
      "Epoch 706/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0685 - projector_loss: 0.0342 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1441 - val_projector_loss: 0.0720 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8380\n",
      "Epoch 707/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0699 - projector_loss: 0.0350 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1374 - val_projector_loss: 0.0687 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8455\n",
      "Epoch 708/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0687 - projector_loss: 0.0343 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1381 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8420\n",
      "Epoch 709/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0687 - projector_loss: 0.0344 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1406 - val_projector_loss: 0.0703 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8370\n",
      "Epoch 710/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0677 - projector_loss: 0.0339 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1400 - val_projector_loss: 0.0700 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8505\n",
      "Epoch 711/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0686 - projector_loss: 0.0343 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1417 - val_projector_loss: 0.0709 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8535\n",
      "Epoch 712/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0686 - projector_loss: 0.0343 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1412 - val_projector_loss: 0.0706 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8465\n",
      "Epoch 713/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0674 - projector_loss: 0.0337 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1404 - val_projector_loss: 0.0702 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8485\n",
      "Epoch 714/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0672 - projector_loss: 0.0336 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1438 - val_projector_loss: 0.0719 - val_proj_std: 0.0433 - val_pred_std: 0.0433 - binary_accuracy: 0.8455\n",
      "Epoch 715/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0669 - projector_loss: 0.0335 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1402 - val_projector_loss: 0.0701 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8455\n",
      "Epoch 716/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0669 - projector_loss: 0.0335 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1380 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8480\n",
      "Epoch 717/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0666 - projector_loss: 0.0333 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1393 - val_projector_loss: 0.0697 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8510\n",
      "Epoch 718/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.0652 - projector_loss: 0.0326 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1394 - val_projector_loss: 0.0697 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8500\n",
      "Epoch 719/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0664 - projector_loss: 0.0332 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1382 - val_projector_loss: 0.0691 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8370\n",
      "Epoch 720/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0656 - projector_loss: 0.0328 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1368 - val_projector_loss: 0.0684 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8495\n",
      "Epoch 721/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0651 - projector_loss: 0.0325 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1336 - val_projector_loss: 0.0668 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8500\n",
      "Epoch 722/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0646 - projector_loss: 0.0323 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1360 - val_projector_loss: 0.0680 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8520\n",
      "Epoch 723/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0660 - projector_loss: 0.0330 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1335 - val_projector_loss: 0.0668 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8525\n",
      "Epoch 724/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0660 - projector_loss: 0.0330 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1390 - val_projector_loss: 0.0695 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8560\n",
      "Epoch 725/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0652 - projector_loss: 0.0326 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1349 - val_projector_loss: 0.0674 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8510\n",
      "Epoch 726/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0642 - projector_loss: 0.0321 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1358 - val_projector_loss: 0.0679 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8550\n",
      "Epoch 727/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0645 - projector_loss: 0.0322 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1379 - val_projector_loss: 0.0689 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8535\n",
      "Epoch 728/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0642 - projector_loss: 0.0321 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1357 - val_projector_loss: 0.0678 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8590\n",
      "Epoch 729/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0639 - projector_loss: 0.0319 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1368 - val_projector_loss: 0.0684 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8480\n",
      "Epoch 730/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0649 - projector_loss: 0.0325 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8510\n",
      "Epoch 731/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0642 - projector_loss: 0.0321 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1385 - val_projector_loss: 0.0693 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8480\n",
      "Epoch 732/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0635 - projector_loss: 0.0317 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1431 - val_projector_loss: 0.0715 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8455\n",
      "Epoch 733/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0640 - projector_loss: 0.0320 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1404 - val_projector_loss: 0.0702 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8515\n",
      "Epoch 734/800\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 0.0635 - projector_loss: 0.0318 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1371 - val_projector_loss: 0.0685 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8525\n",
      "Epoch 735/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0633 - projector_loss: 0.0316 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1353 - val_projector_loss: 0.0677 - val_proj_std: 0.0434 - val_pred_std: 0.0433 - binary_accuracy: 0.8555\n",
      "Epoch 736/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0627 - projector_loss: 0.0313 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1394 - val_projector_loss: 0.0697 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8560\n",
      "Epoch 737/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0629 - projector_loss: 0.0315 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1370 - val_projector_loss: 0.0685 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8580\n",
      "Epoch 738/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.0622 - projector_loss: 0.0311 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1392 - val_projector_loss: 0.0696 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8580\n",
      "Epoch 739/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0627 - projector_loss: 0.0314 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8530\n",
      "Epoch 740/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0613 - projector_loss: 0.0307 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1409 - val_projector_loss: 0.0704 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8500\n",
      "Epoch 741/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0614 - projector_loss: 0.0307 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1389 - val_projector_loss: 0.0695 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8570\n",
      "Epoch 742/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0609 - projector_loss: 0.0304 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1388 - val_projector_loss: 0.0694 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8540\n",
      "Epoch 743/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0607 - projector_loss: 0.0303 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1417 - val_projector_loss: 0.0709 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8645\n",
      "Epoch 744/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0610 - projector_loss: 0.0305 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1369 - val_projector_loss: 0.0684 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8545\n",
      "Epoch 745/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0603 - projector_loss: 0.0302 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1375 - val_projector_loss: 0.0688 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8565\n",
      "Epoch 746/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0603 - projector_loss: 0.0302 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1382 - val_projector_loss: 0.0691 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8580\n",
      "Epoch 747/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0596 - projector_loss: 0.0298 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1415 - val_projector_loss: 0.0708 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8565\n",
      "Epoch 748/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0606 - projector_loss: 0.0303 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1375 - val_projector_loss: 0.0688 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8525\n",
      "Epoch 749/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0594 - projector_loss: 0.0297 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1363 - val_projector_loss: 0.0681 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8575\n",
      "Epoch 750/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0600 - projector_loss: 0.0300 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1369 - val_projector_loss: 0.0684 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8605\n",
      "Epoch 751/800\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 0.0599 - projector_loss: 0.0299 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1384 - val_projector_loss: 0.0692 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8590\n",
      "Epoch 752/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0593 - projector_loss: 0.0297 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1393 - val_projector_loss: 0.0697 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8625\n",
      "Epoch 753/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0597 - projector_loss: 0.0299 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1386 - val_projector_loss: 0.0693 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8630\n",
      "Epoch 754/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0595 - projector_loss: 0.0298 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1388 - val_projector_loss: 0.0694 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8495\n",
      "Epoch 755/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0587 - projector_loss: 0.0293 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1385 - val_projector_loss: 0.0692 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8570\n",
      "Epoch 756/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0594 - projector_loss: 0.0297 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1418 - val_projector_loss: 0.0709 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8580\n",
      "Epoch 757/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0594 - projector_loss: 0.0297 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1371 - val_projector_loss: 0.0685 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8610\n",
      "Epoch 758/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0591 - projector_loss: 0.0295 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1351 - val_projector_loss: 0.0675 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8615\n",
      "Epoch 759/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0584 - projector_loss: 0.0292 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1371 - val_projector_loss: 0.0685 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8660\n",
      "Epoch 760/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0594 - projector_loss: 0.0297 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1392 - val_projector_loss: 0.0696 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8580\n",
      "Epoch 761/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0590 - projector_loss: 0.0295 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1336 - val_projector_loss: 0.0668 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8590\n",
      "Epoch 762/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0580 - projector_loss: 0.0290 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0701 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8630\n",
      "Epoch 763/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.0582 - projector_loss: 0.0291 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1414 - val_projector_loss: 0.0707 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8555\n",
      "Epoch 764/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0577 - projector_loss: 0.0289 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1408 - val_projector_loss: 0.0704 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8535\n",
      "Epoch 765/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0586 - projector_loss: 0.0293 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1422 - val_projector_loss: 0.0711 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8610\n",
      "Epoch 766/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0574 - projector_loss: 0.0287 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1432 - val_projector_loss: 0.0716 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8575\n",
      "Epoch 767/800\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 0.0573 - projector_loss: 0.0287 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1397 - val_projector_loss: 0.0699 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8560\n",
      "Epoch 768/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.0578 - projector_loss: 0.0289 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1430 - val_projector_loss: 0.0715 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8545\n",
      "Epoch 769/800\n",
      "87/87 [==============================] - 23s 263ms/step - loss: 0.0584 - projector_loss: 0.0292 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1369 - val_projector_loss: 0.0685 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8590\n",
      "Epoch 770/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0575 - projector_loss: 0.0288 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1393 - val_projector_loss: 0.0697 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8600\n",
      "Epoch 771/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0575 - projector_loss: 0.0287 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1410 - val_projector_loss: 0.0705 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8570\n",
      "Epoch 772/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0565 - projector_loss: 0.0282 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1392 - val_projector_loss: 0.0696 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8595\n",
      "Epoch 773/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0570 - projector_loss: 0.0285 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1398 - val_projector_loss: 0.0699 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8575\n",
      "Epoch 774/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0567 - projector_loss: 0.0284 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1413 - val_projector_loss: 0.0706 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8640\n",
      "Epoch 775/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0571 - projector_loss: 0.0285 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1397 - val_projector_loss: 0.0698 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8580\n",
      "Epoch 776/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0569 - projector_loss: 0.0285 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1362 - val_projector_loss: 0.0681 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8595\n",
      "Epoch 777/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0575 - projector_loss: 0.0287 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1392 - val_projector_loss: 0.0696 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8590\n",
      "Epoch 778/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0568 - projector_loss: 0.0284 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1396 - val_projector_loss: 0.0698 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8670\n",
      "Epoch 779/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0566 - projector_loss: 0.0283 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1385 - val_projector_loss: 0.0693 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8625\n",
      "Epoch 780/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0575 - projector_loss: 0.0288 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1390 - val_projector_loss: 0.0695 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8600\n",
      "Epoch 781/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0564 - projector_loss: 0.0282 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1403 - val_projector_loss: 0.0701 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8605\n",
      "Epoch 782/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0564 - projector_loss: 0.0282 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1426 - val_projector_loss: 0.0713 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8585\n",
      "Epoch 783/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0571 - projector_loss: 0.0286 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1393 - val_projector_loss: 0.0696 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8595\n",
      "Epoch 784/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.0557 - projector_loss: 0.0279 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1380 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8585\n",
      "Epoch 785/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0565 - projector_loss: 0.0283 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1380 - val_projector_loss: 0.0690 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8595\n",
      "Epoch 786/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0568 - projector_loss: 0.0284 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1397 - val_projector_loss: 0.0699 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8585\n",
      "Epoch 787/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0561 - projector_loss: 0.0280 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1373 - val_projector_loss: 0.0687 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8595\n",
      "Epoch 788/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0558 - projector_loss: 0.0279 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1406 - val_projector_loss: 0.0703 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8605\n",
      "Epoch 789/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0567 - projector_loss: 0.0283 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0701 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8600\n",
      "Epoch 790/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0564 - projector_loss: 0.0282 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1418 - val_projector_loss: 0.0709 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8600\n",
      "Epoch 791/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0567 - projector_loss: 0.0283 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1419 - val_projector_loss: 0.0709 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8615\n",
      "Epoch 792/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0568 - projector_loss: 0.0284 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1404 - val_projector_loss: 0.0702 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8605\n",
      "Epoch 793/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0567 - projector_loss: 0.0283 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1394 - val_projector_loss: 0.0697 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8615\n",
      "Epoch 794/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0555 - projector_loss: 0.0277 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1376 - val_projector_loss: 0.0688 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8605\n",
      "Epoch 795/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0567 - projector_loss: 0.0284 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1353 - val_projector_loss: 0.0676 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8610\n",
      "Epoch 796/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0557 - projector_loss: 0.0279 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1378 - val_projector_loss: 0.0689 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8610\n",
      "Epoch 797/800\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 0.0556 - projector_loss: 0.0278 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1389 - val_projector_loss: 0.0694 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8615\n",
      "Epoch 798/800\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 0.0557 - projector_loss: 0.0279 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1401 - val_projector_loss: 0.0700 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8610\n",
      "Epoch 799/800\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 0.0561 - projector_loss: 0.0281 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1407 - val_projector_loss: 0.0704 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8615\n",
      "Epoch 800/800\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 0.0559 - projector_loss: 0.0280 - proj_std: 0.0435 - pred_std: 0.0435 - val_loss: 0.1384 - val_projector_loss: 0.0692 - val_proj_std: 0.0434 - val_pred_std: 0.0434 - binary_accuracy: 0.8610\n"
     ]
    }
   ],
   "source": [
    "history = contrastive_model.fit(\n",
    "    train_ds,\n",
    "    epochs=PRE_TRAIN_EPOCHS,\n",
    "    steps_per_epoch=PRE_TRAIN_STEPS_PER_EPOCH,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "    callbacks=[evb, tbc, mcp],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.grid()\n",
    "plt.title(f\"{loss.name} - loss\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history[\"proj_std\"], label=\"proj\")\n",
    "if \"pred_std\" in history.history:\n",
    "    plt.plot(history.history[\"pred_std\"], label=\"pred\")\n",
    "plt.grid()\n",
    "plt.title(f\"{loss.name} - std metrics\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history[\"binary_accuracy\"], label=\"acc\")\n",
    "plt.grid()\n",
    "plt.title(f\"{loss.name} - match metrics\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Reload\n",
    " \n",
    "The `ContrastiveModel` contains a set of sub-models and custom train and test steps. Consequently, the `ContrastiveModel` implements a custom save function that performs the following:\n",
    "* Saves each of the sub models, including the predictor if one exists.\n",
    "* A JSON file containing the serialized Loss, Metrics, and Optimizer.\n",
    "* The Optimizer weighs as a npy file.\n",
    " \n",
    "We also provide a custom `load_model()` function that restores the `ContrastiveModel` and supports continued training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also load the trained weights from the model checkpoints\n",
    "# contrastive_model.load_weights(DATA_PATH / 'models' / 'checkpoints' / f\"{loss.name}_{CHECKPOINT_TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfsim_contrastive_model/models/trained_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfsim_contrastive_model/models/trained_model/assets\n"
     ]
    }
   ],
   "source": [
    "contrastive_model.save(DATA_PATH / \"models\" / \"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del contrastive_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_model = tf.keras.models.load_model(\n",
    "    DATA_PATH / \"models\" / \"trained_model\",\n",
    "    custom_objects={\n",
    "        \"ContrastiveModel\": tfsim.models.ContrastiveModel,\n",
    "        \"ActivationStdLoggingLayer\": tfsim.layers.ActivationStdLoggingLayer,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    " \n",
    "This final section trains two different classifiers.\n",
    " \n",
    "1. **No Pre-training**: Uses a ResNet18 model and a simple linear layer.\n",
    " \n",
    "2. **Pre-trained** Uses the frozen pre-trained backbone from the ContrastiveModel and only trains the weights in the linear layer.\n",
    " \n",
    "The original train data is partitioned into eval_train and eval_val splits and a simplified augmentation is applied to the training data. \n",
    " \n",
    "The models are then trained for 10 epochs and the classification accuracy is evaluated on the held out test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EPOCHS = 10\n",
    "TEST_STEPS_PER_EPOCH = len(x_train) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_augmenter(img):\n",
    "    # random resize and crop. Increase the size before we crop.\n",
    "    img = tfsim.augmenters.augmentation_utils.cropping.crop_and_resize(\n",
    "        img, CIFAR_IMG_SIZE, CIFAR_IMG_SIZE, area_range=(0.2, 1.0)\n",
    "    )\n",
    "    # random horizontal flip\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.clip_by_value(img, 0.0, 255.0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_train_ds = tf.data.Dataset.from_tensor_slices((x_train, tf.keras.utils.to_categorical(y_train, 10)))\n",
    "eval_train_ds = eval_train_ds.repeat()\n",
    "eval_train_ds = eval_train_ds.shuffle(1024)\n",
    "eval_train_ds = eval_train_ds.map(lambda x, y: (eval_augmenter(x), y), tf.data.AUTOTUNE)\n",
    "eval_train_ds = eval_train_ds.map(lambda x, y: (img_scaling(x), y), tf.data.AUTOTUNE)\n",
    "eval_train_ds = eval_train_ds.batch(BATCH_SIZE)\n",
    "eval_train_ds = eval_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_val_ds = tf.data.Dataset.from_tensor_slices((x_val, tf.keras.utils.to_categorical(y_val, 10)))\n",
    "eval_val_ds = eval_val_ds.repeat()\n",
    "eval_val_ds = eval_val_ds.shuffle(1024)\n",
    "eval_val_ds = eval_val_ds.map(lambda x, y: (img_scaling(tf.cast(x, dtype=tf.float32)), y), tf.data.AUTOTUNE)\n",
    "eval_val_ds = eval_val_ds.batch(BATCH_SIZE)\n",
    "eval_val_ds = eval_val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "eval_test_ds = tf.data.Dataset.from_tensor_slices((x_test, tf.keras.utils.to_categorical(y_test, 10)))\n",
    "eval_test_ds = eval_test_ds.map(lambda x, y: (img_scaling(tf.cast(x, dtype=tf.float32)), y), tf.data.AUTOTUNE)\n",
    "eval_test_ds = eval_test_ds.batch(BATCH_SIZE)\n",
    "eval_test_ds = eval_test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_model(img_size, backbone, total_steps, trainable=True, lr=1.8):\n",
    "    backbone.trainable = trainable\n",
    "    inputs = tf.keras.layers.Input((img_size, img_size, 3), name=\"eval_input\")\n",
    "    x = backbone(inputs, training=trainable)\n",
    "    o = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs, o)\n",
    "    cosine_decayed_lr = tf.keras.experimental.CosineDecay(initial_learning_rate=lr, decay_steps=total_steps)\n",
    "    opt = tf.keras.optimizers.SGD(cosine_decayed_lr, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 16s 123ms/step - loss: 2.0526 - acc: 0.2555 - val_loss: 1.7730 - val_acc: 0.3394\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.7665 - acc: 0.3480 - val_loss: 1.6045 - val_acc: 0.3991\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.6770 - acc: 0.3850 - val_loss: 1.5268 - val_acc: 0.4426\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.6132 - acc: 0.4091 - val_loss: 1.4685 - val_acc: 0.4658\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.5754 - acc: 0.4289 - val_loss: 1.4279 - val_acc: 0.4886\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.5382 - acc: 0.4396 - val_loss: 1.4020 - val_acc: 0.5024\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.5158 - acc: 0.4473 - val_loss: 1.3750 - val_acc: 0.5073\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.5090 - acc: 0.4557 - val_loss: 1.3663 - val_acc: 0.5100\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.4983 - acc: 0.4587 - val_loss: 1.3659 - val_acc: 0.5070\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 1.4957 - acc: 0.4614 - val_loss: 1.3642 - val_acc: 0.5094\n"
     ]
    }
   ],
   "source": [
    "no_pt_eval_model = get_eval_model(\n",
    "    img_size=CIFAR_IMG_SIZE,\n",
    "    backbone=get_backbone(CIFAR_IMG_SIZE, DIM),\n",
    "    total_steps=TEST_EPOCHS * TEST_STEPS_PER_EPOCH,\n",
    "    trainable=True,\n",
    "    lr=1e-3,\n",
    ")\n",
    "no_pt_history = no_pt_eval_model.fit(\n",
    "    eval_train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=TEST_EPOCHS,\n",
    "    steps_per_epoch=TEST_STEPS_PER_EPOCH,\n",
    "    validation_data=eval_val_ds,\n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " eval_input (InputLayer)     [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " resnet18sim (SimilarityMode  (None, 512)              11182784  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,187,914\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 11,182,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pt_eval_model = get_eval_model(\n",
    "    img_size=CIFAR_IMG_SIZE,\n",
    "    backbone=contrastive_model.backbone,\n",
    "    total_steps=TEST_EPOCHS * TEST_STEPS_PER_EPOCH,\n",
    "    trainable=False,\n",
    "    lr=30.0,\n",
    ")\n",
    "pt_eval_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 3s 23ms/step - loss: 38.5378 - acc: 0.1085 - val_loss: 56.9061 - val_acc: 0.0989\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 36.1107 - acc: 0.1248 - val_loss: 28.1277 - val_acc: 0.1794\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 23.9141 - acc: 0.1787 - val_loss: 21.3993 - val_acc: 0.1016\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 12.7231 - acc: 0.2438 - val_loss: 6.7922 - val_acc: 0.3264\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 1.0918 - acc: 0.7673 - val_loss: 0.4003 - val_acc: 0.8764\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.3966 - acc: 0.8765 - val_loss: 0.4157 - val_acc: 0.8660\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.3845 - acc: 0.8775 - val_loss: 0.3876 - val_acc: 0.8854\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.3748 - acc: 0.8809 - val_loss: 0.3911 - val_acc: 0.8804\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.3737 - acc: 0.8811 - val_loss: 0.3874 - val_acc: 0.8824\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.3694 - acc: 0.8825 - val_loss: 0.3859 - val_acc: 0.8859\n"
     ]
    }
   ],
   "source": [
    "pt_history = pt_eval_model.fit(\n",
    "    eval_train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=TEST_EPOCHS,\n",
    "    steps_per_epoch=TEST_STEPS_PER_EPOCH,\n",
    "    validation_data=eval_val_ds,\n",
    "    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 41ms/step - loss: 1.3921 - acc: 0.4961\n",
      "no pretrain [1.3921139240264893, 0.4961000084877014]\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.4024 - acc: 0.8747\n",
      "pretrained [0.40240636467933655, 0.8747000098228455]\n"
     ]
    }
   ],
   "source": [
    "print(\"no pretrain\", no_pt_eval_model.evaluate(eval_test_ds))\n",
    "print(\"pretrained\", pt_eval_model.evaluate(eval_test_ds))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7b3389fe492617a9dd862ce9e69c0dfb3e62254a4be8ff5561f4f9b5c78139c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

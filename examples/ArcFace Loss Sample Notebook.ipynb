{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28956aa1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright 2022 The TensorFlow Similarity Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eda1a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9d025",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TensorFlow Similarity ArcFace Loss Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072628f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A Total Angular Margin Loss (ArcFace) calculates the geodetic distance in the hypersphere instead of the euclidean distance to improve the discriminatory strength of the facial recognition model and stabilize the training process. Rails are used to measure all distances in geodetic space. The geodetic trace is the path taken between two places. It specifies the geodetic distance, which is the shortest distance between two places.\n",
    "\n",
    "ArcFace loss determines the angle between the current feature and the target weight using the arc-cosine function since the dot product between the DCNN feature and the last fully connected layer after feature and weight normalization matches the cosine distance. The target logit is then returned by multiplying the goal angle by an additional angular margin and using the cosine function. After that, we continue as before and rescale all logits to a certain feature norm, just like with softmax loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ac087",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Notebook goal\n",
    "\n",
    "This notebook demonstrates how to use ArcFaceLoss implementation of TensorFlow Similarity with standalone usage and to train a `SimilarityModel()` on a fraction of the MNIST classes.\n",
    "\n",
    "You are going to learn about the main features offered by the `ArcFaceLoss()` and will:\n",
    "\n",
    " 1. Standalone usage of ArcFaceLoss\n",
    "\n",
    " 2. Usage with `model.compile()`\n",
    "\n",
    " 3. 3D-Visualization of ArcFaceLoss \n",
    "\n",
    "### Things to try \n",
    "\n",
    "Along the way you can try the following things to improve the model performance:\n",
    "- Adding more \"seen\" classes at training time.\n",
    "- Use a larger embedding by increasing the size of the output.\n",
    "- Add data augmentation pre-processing layers to the model.\n",
    "- Include more examples in the index to give the models more points to choose from.\n",
    "- Try a more challenging dataset, such as Fashion MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c53c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Notebook goal\n",
    "\n",
    "This notebook demonstrates how to use ArcFaceLoss implementation of TensorFlow Similarity with standalone usage and to train a `SimilarityModel()` on a fraction of the MNIST classes.\n",
    "\n",
    "You are going to learn about the main features offered by the `ArcFaceLoss()` and will:\n",
    "\n",
    " 1. Standalone usage of ArcFaceLoss\n",
    "\n",
    " 2. Usage with `model.compile()`\n",
    "\n",
    " 3. 3D-Visualization of ArcFaceLoss \n",
    "\n",
    "### Things to try \n",
    "\n",
    "Along the way you can try the following things to improve the model performance:\n",
    "- Adding more \"seen\" classes at training time.\n",
    "- Use a larger embedding by increasing the size of the output.\n",
    "- Add data augmentation pre-processing layers to the model.\n",
    "- Include more examples in the index to give the models more points to choose from.\n",
    "- Try a more challenging dataset, such as Fashion MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd63f16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# INFO messages are not printed.\n",
    "# This must be run before loading other modules.\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af5fc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8caf7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# install TF similarity if needed\n",
    "try:\n",
    "    import tensorflow_similarity as tfsim  # main package\n",
    "except ModuleNotFoundError:\n",
    "    !pip install tensorflow_similarity\n",
    "    import tensorflow_similarity as tfsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484bd72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfsim.utils.tf_cap_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0344e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Clear out any old model state.\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9bef9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"TensorFlow Similarity\", tfsim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137afbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d534ad3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Standalone Usage of ArcFaceLoss\n",
    "\n",
    "ArcFace loss alone can be used as follows when it is desired to calculate the additive angular margin loss of the existing data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d526da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize Loss function as ArcFaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf6ef0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = tfsim.losses.ArcFaceLoss(num_classes=8, embedding_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ccfd7d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create own simple random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ec43a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = tf.Variable([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "embeddings = tf.Variable(tf.random.uniform(shape=[8, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0c1c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b3085",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7c30c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(labels, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16745b7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"loss : \" , loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = loss_fn(labels, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"loss : \" , loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation\n",
    "\n",
    "We are going to load the MNIST dataset to showcase how the model is able to find similar examples from classes unseen during training. The model's ability to generalize the matching to unseen classes, without retraining, is one of the main reason you would want to use metric learning.\n",
    "\n",
    "\n",
    "**WARNING**: Tensorflow similarity expects `y_train` to be an IntTensor containing the class ids for each example instead of the standard categorical encoding traditionally used for multi-class classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss : \" , loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef5236",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "We are going to load the MNIST dataset to showcase how the model is able to find similar examples from classes unseen during training. The model's ability to generalize the matching to unseen classes, without retraining, is one of the main reason you would want to use metric learning.\n",
    "\n",
    "\n",
    "**WARNING**: Tensorflow similarity expects `y_train` to be an IntTensor containing the class ids for each example instead of the standard categorical encoding traditionally used for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97152229",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b766d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac2da7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model definition\n",
    "\n",
    "`SimilarityModel()` models extend `tensorflow.keras.model.Model` with additional features and functionality that allow you to index and search for similar looking examples.\n",
    "\n",
    "As visible in the model definition below, similarity models output a 64 dimensional float embedding using the `MetricEmbedding()` layers. This layer is a Dense layer with L2 normalization. Thanks to the loss, the model learns to minimize the distance between similar examples and maximize the distance between dissimilar examples. As a result, the distance between examples in the embedding space is meaningful; the smaller the distance the more similar the examples are. \n",
    "\n",
    "Being able to use a distance as a meaningful proxy for how similar two examples are, is what enables the fast ANN (aproximate nearest neighbor) search. Using a sub-linear ANN search instead of a standard quadratic NN search is what allows deep similarity search to scale to millions of items. The built in memory index used in this notebook scales to a million indexed examples very easily... if you have enough RAM :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003c971",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "    x = tf.keras.layers.experimental.preprocessing.Rescaling(1 / 255)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    # smaller embeddings will have faster lookup times while a larger embedding will improve the accuracy up to a point.\n",
    "    outputs = tfsim.layers.MetricEmbedding(64)(x)\n",
    "    return tfsim.models.SimilarityModel(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2177b12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb3961",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ArcFace Loss definition\n",
    "\n",
    "Overall what makes Metric losses different from tradional losses is that:\n",
    "- **They expect different inputs.** Instead of having the prediction equal the true values, they expect embeddings as `y_preds` and the id (as an int32) of the class as `y_true`. \n",
    "- **They require a distance.** You need to specify which `distance` function to use to compute the distance between embeddings. `cosine` is usually a great starting point and the default.\n",
    "\n",
    "ArcFace Loss takes inputs as number of classes which labels includes, and embedding size which we define in model `MetricEmbedding()` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0d745",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distance = \"cosine\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d10cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = np.unique(y_train).size\n",
    "embedding_size = model.get_layer('metric_embedding').output.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8e426",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = tfsim.losses.ArcFaceLoss(num_classes= num_classes, embedding_size=embedding_size, name=\"ArcFaceLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eaf9c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compilation\n",
    "\n",
    "Tensorflow similarity use an extended `compile()` method that allows you to optionally specify `distance_metrics` (metrics that are computed over the distance between the embeddings), and the distance to use for the indexer.\n",
    "\n",
    "By default the `compile()` method tries to infer what type of distance you are using by looking at the first loss specified. If you use multiple losses, and the distance loss is not the first one, then you need to specify the distance function used as `distance=` parameter in the compile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f986f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR = 0.0005  # @param {type:\"number\"}\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(LR), loss=loss, distance=distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15961601",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "Similarity models are trained like normal models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a6863",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10  # @param {type:\"integer\"}\n",
    "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1ee4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"])\n",
    "plt.title(f\"Loss: {loss.name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5404906",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ad4ba20",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Let's predict some features and visualiza them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1936264",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embedded_features = model.predict(x_test, verbose=1)\n",
    "embedded_features /= np.linalg.norm(embedded_features, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0df63b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3D-Visualization of ArcFace Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac5d98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "for c in range(len(np.unique(y_test))):\n",
    "    ax.plot(embedded_features[y_test==c, 0], embedded_features[y_test==c, 1], embedded_features[y_test==c, 2], '.', alpha=0.1)\n",
    "plt.title('ArcFace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889f840",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef529d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
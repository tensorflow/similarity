{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "cada0c3e68bbe3038c05f3f13c34d05fb5411cc128b62a4a529880c33c3268c3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "metadata": {
      "interpreter": {
        "hash": "beb34c979f53df918eee6ac62e82d9c0beb9e6590c67a50c4f7c01f004ba70dc"
      }
    },
    "colab": {
      "name": "similarity_basic_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iywg9YnWE_E"
      },
      "source": [
        "Copyright 2021 The TensorFlow Similarity Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PalALyuCWE_G"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2KRYzqYWE_H"
      },
      "source": [
        "# Tensorflow Similarity Hello World\n",
        "\n",
        "TensorFlow Similarity is a library for doing metric learning with TensorFlow. This can be used for tasks such as:\n",
        "\n",
        "- finding similar items from within a collection of varied items\n",
        "- semi-supervised or sparsely labeled contrastive learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEvii0oJWE_I"
      },
      "source": [
        "## Few-shot, contrastive learning\n",
        "\n",
        "*Few-shot learning* is training a model based on a limited number of samples, rather than the very large number of well-labeled examples typically needed. In the context of TensorFlow means specifically that the trained model is able to make inferences about classes of examples it has not previously seen.\n",
        "\n",
        "*Contrastive learning* is learning what features tend to make things similar or different. The goal is not to train a model that can identify which predefined class a new example is a member of, but rather a model which can compute the similarity between two new examples. This type of model is called a *similarity model*.\n",
        "\n",
        "For example, a contrastive model trained on pictures of dogs might be able to tell you that a Saint Bernard and a Chihuahua are very different from each other, even if neither type of dog was present in the training set. Alternatively, a contrastive model trained on many different kinds of life (plants, animals, fungi), might find that the Saint Bernard and Chihuahua are much more similar to each than either is to a fern, even if no dogs at all were present in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwz1a9oFWE_J"
      },
      "source": [
        "## In this notebook\n",
        "\n",
        "In this notebook you will:\n",
        "\n",
        "1.  `train()` a similarity model on a sub-set of the 10 fashion MNIST classes that learn how to project images in a cosine space\n",
        "\n",
        "2.  `index()` a small number of examples (10) of each of the classes present in the training dataset\n",
        "\n",
        "3.  `lookup()` some the test data to show how our model is able to match unseen classes while having only a few examples of each in its index\n",
        "\n",
        "4.  `calibrate()` the model to estimate what is the best distance theshold to separate matching elments from elements belonging to different classes\n",
        "\n",
        "5.  `evaluate()` how well our model/index perform\n",
        "\n",
        "6.  `match()` a few examples to test our calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU_ZCtQQWE_J"
      },
      "source": [
        "## Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKumxpUwWE_K"
      },
      "source": [
        " %load_ext autoreload\n",
        " %autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uLEVD7IWE_K"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twEZcUE9WE_L"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfjr17VeWE_M"
      },
      "source": [
        "# Uncomment and run `!pip install...` if needed\n",
        "# !pip install tensorflow_similarity\n",
        "\n",
        "import tensorflow_similarity as tfsim  # main package\n",
        "from tensorflow_similarity.utils import tf_cap_memory\n",
        "from tensorflow_similarity.losses import TripletLoss  # specialized similarity loss\n",
        "from tensorflow_similarity.layers import MetricEmbedding # layer with l2 regularization\n",
        "from tensorflow_similarity.models import SimilarityModel # TF model with additional features\n",
        "from tensorflow_similarity.samplers import MultiShotMemorySampler  # sample data \n",
        "from tensorflow_similarity.samplers import select_examples  # select n example per class\n",
        "from tensorflow_similarity.visualization import viz_neigbors_imgs  # Neigboors vizualisation\n",
        "from tensorflow_similarity.visualization import confusion_matrix  # matching performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhMaPckVWE_N"
      },
      "source": [
        "tf_cap_memory()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIAP83xlWE_N"
      },
      "source": [
        "print('TensorFlow:', tf.__version__)\n",
        "print('TensorFlow Similarity', tfsim.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_OfLmliWE_O"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "We are going to load the MNIST dataset and restrict our training data to only N of the 10 classes (6 by default) to showcase how the model is able to find similar examples from classes unseen during training which is one of the\n",
        "main reason you would want to use metric learning.\n",
        "\n",
        "\n",
        "**Important**: Tensorflow similarity expect `y_train` to be the examples class as integers. Accordingly contrary to a standard classification that do categorical encoding we are leavig `y_train` as is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDUUeJ7kWE_O"
      },
      "source": [
        "NUM_CLASSES = 6  #@param {type: \"slider\", min: 1, max: 10}\n",
        "classes = [2, 3, 1, 7, 9, 6, 8, 5, 0, 4]\n",
        "# note we added a 11th classes for unknown\n",
        "labels = [\"0\", \"1\",  \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"Unknown\"]\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data('/tmp/data/mnist.npz')\n",
        "\n",
        "x_train = tf.constant(x_train / 255.0, dtype='float32')\n",
        "x_test = tf.constant(x_test / 255.0, dtype='float32')\n",
        "\n",
        "x_restricted, y_restricted = select_examples(x_train, y_train, classes[:NUM_CLASSES], 30000)\n",
        "print(x_restricted.shape, y_restricted.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iHvkMTIWE_P"
      },
      "source": [
        "To learn efficiently each batch must contains at least 2 sample of each class. Additionally it is often useful to have multiple examples of each class so we can mine informative triplet using different mining strategies (e.g *semi-hard* mining).\n",
        "\n",
        "To make this easy tf_similarity offers `Samplers()` that allows to control the number of classes and minimal ammount of examples in each class. Here we are going `MultiShotMemorySampler()` which allows to sample a dataset that reside in memory and have muliples examples per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQOYCfIQWE_P"
      },
      "source": [
        "CLASS_PER_BATCH = NUM_CLASSES #@param {type:\"integer\"}\n",
        "EXAMPLE_PER_CLASS = 6 #@param {type:\"integer\"}\n",
        "STEPS_PER_EPOCH = 1000 #@param {type:\"integer\"}\n",
        "sampler = MultiShotMemorySampler(x_restricted, y_restricted, class_per_batch=CLASS_PER_BATCH, example_per_class=EXAMPLE_PER_CLASS, steps_per_epoch=STEPS_PER_EPOCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3_ps73sWE_P"
      },
      "source": [
        "# model setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwzFMj-mWE_Q"
      },
      "source": [
        "## Model definition\n",
        "\n",
        "Triplet loss models are normal `tensorflow.keras` models except their output is a distance embeding. We use `SimilarityModel()` instead of the default `Model()` because this subclass contains additional proprerty that makes indexing and searching embeddings easy once the training is done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oGfFJrvWE_Q"
      },
      "source": [
        "def get_model():\n",
        "    inputs = tf.keras.layers.Input(shape=(28,28))\n",
        "    x = layers.Reshape((28, 28, 1))(inputs)\n",
        "    x = layers.Conv2D(32, 7, activation='relu')(x)\n",
        "    x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(64, 7, activation='relu')(x)\n",
        "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    # dont make the embedding to large - its slow down the lookups\n",
        "    outputs = MetricEmbedding(32)(x)\n",
        "    return SimilarityModel(inputs, outputs)\n",
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X8zn5I5WE_Q"
      },
      "source": [
        "## Loss definition\n",
        "\n",
        "Overall Similarity losses (aka metric losses) are similar to other losses except they expect different inputs.\n",
        "\n",
        "For triplet loss, one of the most popular one, you need to decide what type of triplet mining you want. Usually `hard` mining for positive example and `semi-hard` mining work well and are the default. They are passed explicitly here for reference.\n",
        "\n",
        "The `distance` parameters specify which distance metric to use to compute the distance between embeddings. `cosine` is usually a great starting point and the default.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Uxy_1vcTWE_Q"
      },
      "source": [
        "distance = 'cosine' #@param [\"cosine\"]{allow-input: false}\n",
        "positive_mining_strategy = 'hard' #@param [\"easy\", \"hard\"]{allow-input: false}\n",
        "negative_mining_strategy = 'semi-hard'  #@param [\"easy\", \"semi-hard\", \"hard\"]{allow-input: false}\n",
        "triplet_loss = TripletLoss(distance=distance,\n",
        "    positive_mining_strategy=positive_mining_strategy,\n",
        "    negative_mining_strategy=negative_mining_strategy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY75pIVIWE_R"
      },
      "source": [
        "## Compilation\n",
        "\n",
        "Tensorflow similarity use an extended `compile()` method that allows you to specify distance_metrics (metrics that are computed over the distance between the embedding). \n",
        "\n",
        "By default the `compile()` method try to infers what type of distance you are using by looking at the fist loss specified. If you use multiples losses and the distance loss is not the first, then you need to specify the distance function used as `distance=` parameter in the compile function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Settv4lwWE_R"
      },
      "source": [
        "LR = 0.001  #@param {type:\"float\"}\n",
        "model = get_model()\n",
        "model.compile(optimizer=Adam(LR), loss=triplet_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHGPVtXWWE_R"
      },
      "source": [
        "# Training\n",
        "\n",
        "Similarity are trained like normal model. Don't expect the validation loss to decrease too much because we only use half of the class on the train data but all class in the validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "5UIJrxcKWE_R"
      },
      "source": [
        "EPOCHS = 5 #@param {type:\"integer\"}\n",
        "history = model.fit(sampler, validation_data=(x_test, y_test), epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waCcJzdgWE_R"
      },
      "source": [
        "# expect loss: 0.07 / val_loss: 0.6\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdFZWOtWWE_R"
      },
      "source": [
        "# Indexing\n",
        "\n",
        "Indexing is where things get different from traditional classification models. Because the model learned to output an embedding that represent the example position in a metric space and not a classification, we need a way to find which known example(s) are the closest to determine the class of the incoming data (aka nearest neighboors classication).\n",
        "\n",
        "To do so we need to **create an index of known example from the 10 cloth classes**. We do this by taking **200 examples from the train dataset which amount to 20 examples** for each class and use the `index()` funtion of the model to build the index.\n",
        "\n",
        "we store the images (x_index) as data in the index (`data=x_index`) so we can display them later. Here the images are small so its not an issue but in general, be careful while storing a lot of data in the index to avoid blewing up your memory. You might consider using a different `Table()` backend if you have to store and serve very large indexes.\n",
        "\n",
        "Adding more examples per class, helps increase the accuracy/generalization as you improve the set of known variations that the classifier \"knows\". \n",
        "\n",
        "Reseting the index is not necessary but it ensure we start with a clean index in case of a re-run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUqGZQxlWE_S"
      },
      "source": [
        "x_index, y_index = select_examples(x_train, y_train, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 20)\n",
        "model.reset_index()\n",
        "model.index(x_index, y_index, data=x_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXFLa6HLWE_S"
      },
      "source": [
        "# Querying\n",
        "\n",
        "To \"classify\" our testing data, we need for each testing example to look for its *k* [nearest neighbors](https://scikit-learn.org/stable/modules/neighbors.html) in the index.\n",
        "\n",
        "We query a single random example for each class from the test dataset using  `select_examples()` and then find their nearest neighboors using the `single_lookup()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "zDPMLRZDWE_S"
      },
      "source": [
        "# re-run to test on other examples\n",
        "num_neighboors = 5\n",
        "\n",
        "# select\n",
        "x_display, y_display = select_examples(x_test, y_test, list(range(10)), 1)\n",
        "\n",
        "# lookup\n",
        "nns = model.lookup(x_display, k=num_neighboors)\n",
        "\n",
        "# display\n",
        "for idx in np.argsort(y_display):\n",
        "    viz_neigbors_imgs(x_display[idx], y_display[idx], nns[idx], \n",
        "                      labels=labels, fig_size=(16, 2), cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaKtbDS5WE_S"
      },
      "source": [
        "# matching\n",
        "\n",
        "To be able to tell if an example match a given class, we first need to `calibrate()` the model to know what is the optimal cut point. By default, we only compute an optimal cutpoint that maximizes performance. However you can speficy your own and change the optimization metrics as illustrated in later notebooks/colabs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4RntpwkWE_S"
      },
      "source": [
        "num_calibration_samples = 1000\n",
        "calibration = model.calibrate(x_train[:num_calibration_samples], y_train[:num_calibration_samples], verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7m-z5xpWE_T"
      },
      "source": [
        "Let's look how the performance metrics evolve as the distance between the sample increase. We clearly see the F1 optimial cutpoint where the precision and recall intersect which what the `optimal_cutpoint` represent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VURl8p-OWE_T"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(calibration['thresholds']['accuracy'], label='precision')\n",
        "ax.plot(calibration['thresholds']['recall'], label='recall')\n",
        "ax.plot(calibration['thresholds']['f1_score'], label='f1 score')\n",
        "ax.legend()\n",
        "ax.set_title(\"Metric evolution as distance increase\")\n",
        "ax.set_xlabel('Examples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAyXE7fNWE_T"
      },
      "source": [
        "Ploting the precision/recall curve we can see that for a lot of samples from the unseen classes the model is not doing really well (you see the inflexion past 0.6 recall). This can be improved by indexing more data, using data augmentation, a better model or even changing which classes are trained on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1qpuTauWE_T"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(calibration['thresholds']['recall'], calibration['thresholds']['accuracy'])\n",
        "ax.set_title(\"Precision recall curve\")\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjJc8L8RWE_T"
      },
      "source": [
        "# Evaluation\n",
        "We evaluate our model ability to accurately match new examples using our calibrated threshold by testing how many examples from the test sets are correctly matched. The example which have a distance above the cutoff are excluded and labeled as unknown.\n",
        "\n",
        "The evaluation below reports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp1hR65QWE_T"
      },
      "source": [
        "metrics = model.evaluate_matching(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1jVttE9WE_T"
      },
      "source": [
        "# match\n",
        "\n",
        "Let's now match a 100 examples to see how you can use the `match()` function in practice. `match()` return you what class the example belong to based of the content of the index and allows to use your model to make prediction on an unbounded, added after training, classes!\n",
        "\n",
        "Note: `match()` return -1 by default when the distance between the submited example and any point of the index is above the distance cutpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZstOAiBzWE_T"
      },
      "source": [
        "num_matches = 10\n",
        "\n",
        "matches = model.match(x_test[:num_matches], cutpoint='optimal')\n",
        "rows = []\n",
        "for idx, match in enumerate(matches):\n",
        "    rows.append([match, y_test[idx], match == y_test[idx]])\n",
        "print(tabulate(rows, headers=['Predicted', 'True', 'correct']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPPwMWU9WE_U"
      },
      "source": [
        "## confusion matrix\n",
        "Let's select a few hundreds samples for each class in the test set to plot the confusion matrix for a few\n",
        "\n",
        "**note** `tf.math.confusion_matrix` doesn't support negative class so we are going to use **10 as our unknown class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChFiLlR_WE_U"
      },
      "source": [
        "num_example_per_class = 1000\n",
        "cutpoint = 'optimal'\n",
        "\n",
        "x_confusion, y_confusion = select_examples(x_test, y_test, range(10), num_example_per_class)\n",
        "\n",
        "matches = model.match(x_confusion, cutpoint=cutpoint, no_match_label=10)\n",
        "confusion_matrix(matches, y_confusion, labels=labels, title='Confusin matrix for cutpoint:%s' % cutpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J4sG5mTWE_U"
      },
      "source": [
        "# Index information\n",
        "\n",
        "Following `model.summary()` you can get information about the index configuration and its performance using `index_summary()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S30ozfDWE_U"
      },
      "source": [
        "model.index_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zmX2W19WE_U"
      },
      "source": [
        "# Saving and reloading\n",
        "Saving and reloading the model works as you would expected: \n",
        "- `model.save(path)`: save the model and the index on disk (`save_index=False`). By default the index is compressed - can be disabled by setting `compressed=False`\n",
        "- `model = tf.keras.model.load_model(path)` reload the model. To reload the index you then need to call model.load_index(path)\n",
        "- `model.save_index(path)` and `model.load_index(path)` allows to save/reload an index indenpendly of saving/loading a model if need to be\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHycqWtaWE_U"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw8fr8mUWE_U"
      },
      "source": [
        "# save the model and the index\n",
        "save_path = 'models/hello_world' #@param {type:\"string\"}\n",
        "model.save(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78LjbWWhWE_U"
      },
      "source": [
        "## Reloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKuVSm1hWE_U"
      },
      "source": [
        "# reload the model\n",
        "reloaded_model = load_model(save_path)\n",
        "# reload the index\n",
        "reloaded_model.load_index(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJVmdxFVWE_V"
      },
      "source": [
        "#check the index is back\n",
        "reloaded_model.index_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIar550_WE_V"
      },
      "source": [
        "## Query reloaded model\n",
        "Querying the reloaded model with its reload index works as expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CPQgUg9WE_V"
      },
      "source": [
        "# re-run to test on other examples\n",
        "num_neighboors = 5\n",
        "\n",
        "# select\n",
        "x_display, y_display = select_examples(x_test, y_test, list(range(10)), 1)\n",
        "\n",
        "# lookup\n",
        "nns = model.lookup(x_display, k=num_neighboors)\n",
        "\n",
        "# display\n",
        "for idx in np.argsort(y_display):\n",
        "    viz_neigbors_imgs(x_display[idx], y_display[idx], nns[idx], \n",
        "                      labels=labels, fig_size=(16, 2), cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}